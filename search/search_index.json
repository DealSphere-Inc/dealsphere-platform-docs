{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"DealSphere Platform Documentation","text":"<p>Welcome to the official docs for the DealSphere platform. This documentation is the single source of truth for all architecture decisions, technical implementation details, product requirements, QA/test coverage, and delivery planning.</p>"},{"location":"#documentation-structure","title":"\ud83d\udcda Documentation Structure","text":"<ul> <li>Architecture Decision Records (ADRs)<ul> <li>Trace all critical technology and architecture decisions.</li> <li>Find each ADR and the ADR Master Index for rationale/history.</li> </ul> </li> <li>Planning<ul> <li>Contains weekly epics table (phase1-epics.md), delivery plans, phase breakdowns, and milestone maps.</li> <li>BRD Repository - Business Requirements Documents</li> <li>Tech Spec Repository - Technical Specifications</li> </ul> </li> <li>Product<ul> <li>Contains Product Requirements Documents (PRDs) and feature specs, versioned per release.</li> </ul> </li> <li>QA &amp; Compliance<ul> <li>End-to-end acceptance criteria, functional test cases, traceability matrix, and compliance documentation.</li> </ul> </li> <li>Technical Documentation<ul> <li>Implementation plans, technology landscape overviews, demo/release guides, and the release process.</li> </ul> </li> </ul>"},{"location":"#quick-navigation","title":"\ud83d\udd17 Quick Navigation","text":"<ul> <li>ADR Master Index</li> <li>Phase 1 Epics and Delivery Plan</li> <li>Phase 1 Product Requirements (PRD)</li> <li>Functional Test Cases</li> <li>Tech Landscape (MVP)</li> <li>Release Process</li> <li>Phase 1 Technical Plan</li> </ul> <p>See each subdirectory for additional documentation, internal guides, and implementation notes. When in doubt, start with the README in that folder.</p>"},{"location":"#contributing","title":"\ud83d\udea6 Contributing","text":"<ul> <li>Propose process/architecture changes by adding an ADR or PR and cross-linking related documentation.</li> <li>Follow ADR-0000-template for major decisions, and respect doc/file naming conventions.</li> <li>Keep language concise and always map changes to existing PRD, planning, and QA docs.</li> </ul>"},{"location":"#getting-help","title":"\ud83d\udca1 Getting Help","text":"<ul> <li>If unsure, review ADRs and planning/technical docs for context.</li> <li>For process/feature/test traceability, follow the links above or contact the core platform team listed internally.</li> </ul> <p>Last updated: August 2025 \u2013 All core tech, planning, and QA documentation is actively maintained during MVP delivery.</p>"},{"location":"adr/","title":"Architecture Decision Records (ADRs)","text":"<p>This directory contains Architecture Decision Records for the DealSphere platform. ADRs document important architectural decisions made during platform development. Each ADR should be updated in this index with its number, title, status, tags, and date.</p>"},{"location":"adr/#adr-index","title":"ADR Index","text":"ADR Title Status Tags Date ADR-0001 Java 17 Runtime Accepted runtime, java, backend 2025-XX-XX ADR-0002 R3 Corda 5 DLT Platform Accepted blockchain, dlt, backend 2025-XX-XX ADR-0003 Docker Compose Phase 1 Orchestration Accepted deployment, orchestration 2025-XX-XX ADR-0004 Service Framework Defaults Accepted architecture, tech-stack 2025-XX-XX ADR-000-template ADR Authoring Template - meta, template 2025-XX-XX <p>Replace XX-XX in Date with actual decision dates.</p>"},{"location":"adr/#status-definitions","title":"Status Definitions","text":"<ul> <li>Accepted: Decision finalized and in production use.</li> <li>Open: Still under discussion/trial; current choice and alternatives listed.</li> <li>Deprecated: No longer applies (historical only).</li> <li>Superseded: Explicitly replaced by a newer ADR.</li> </ul>"},{"location":"adr/#adr-process","title":"ADR Process","text":"<p>To create a new ADR: 1. Copy <code>ADR-000-template.md</code> to a new file with next sequential number and short title, e.g. <code>ADR-0005-storage-choice.md</code> 2. Fill all required sections using bolded headings. 3. Reference related ADRs by number and brief title (e.g. <code>[0001](ADR-0001-java-17-runtime.md) Java 17</code>) 4. Update this index table with the new ADR. 5. Submit a pull request for review by the core team.</p> <p>General Guidelines - Chronological numbering (ADR-XXXX). - Use descriptive tags (architecture, api, security, performance, etc). - For \"Open\" ADRs, document deferred alternatives and triggers for revisit. - Keep this README as the authoritative ADR directory for the repo.</p>"},{"location":"adr/#common-tags","title":"Common Tags","text":"<ul> <li><code>architecture</code> \u2013 Platform/system architecture patterns</li> <li><code>database</code> \u2013 Persistence and storage</li> <li><code>api</code> \u2013 API design/standards</li> <li><code>security</code> \u2013 Auth, privacy, encryption</li> <li><code>performance</code> \u2013 Optimization, scalability</li> <li><code>monitoring</code> \u2013 Logging, metrics, alerting</li> <li><code>deployment</code> \u2013 CI/CD, infra, containerization</li> <li><code>integration</code> \u2013 External/partner interfaces</li> </ul> <p>Last updated: August 2025 \u2013 update table and tags as new decisions are finalized.</p>"},{"location":"adr/ADR-0000-template/","title":"ADR-XXXX: [title]","text":"<p>Author: @author Status: [Draft | Proposed | Accepted | Rejected | Deprecated | Superseded by ADR-XXXX] Date: YYYY-MM-DD Deciders: @name1, @name2, @name3 Technical Story: [optional link to ticket/issue] Tags: [tag1, tag2, tag3]</p>"},{"location":"adr/ADR-0000-template/#context","title":"Context","text":"<ul> <li>[Description of the problem space and why a decision needs to be made]</li> <li>[What is the issue that we're seeing that is motivating this decision or change?]</li> </ul>"},{"location":"adr/ADR-0000-template/#decision","title":"Decision","text":"<p>[Description of the solution/approach being chosen or What is the change that we're proposing and/or doing?]</p> <p>For now: - [Placeholder for current implementation approach] - [Placeholder for immediate next steps] - [Placeholder for temporary measures]</p>"},{"location":"adr/ADR-0000-template/#rationale","title":"Rationale","text":"<p>[Why is this the right decision given our architectural pillars?]</p>"},{"location":"adr/ADR-0000-template/#rationale-pillars","title":"Rationale Pillars","text":""},{"location":"adr/ADR-0000-template/#why-title-status","title":"Why [title] ([status])","text":"<ul> <li>Pillar 1 (e.g., Stability and Support)</li> <li>Supporting detail 1</li> <li> <p>Supporting detail 2</p> </li> <li> <p>Pillar 2 (e.g., Ecosystem Readiness)</p> </li> <li>Supporting detail 1</li> <li> <p>Supporting detail 2</p> </li> <li> <p>Pillar 3 (e.g., Team Proficiency and Velocity)</p> </li> <li>Supporting detail 1</li> <li> <p>Supporting detail 2</p> </li> <li> <p>Pillar 4 (e.g., Modern Features without migration burden)</p> </li> <li>Supporting detail 1</li> <li> <p>Supporting detail 2</p> </li> <li> <p>Pillar 5 (e.g., Risk Management)</p> </li> <li>Supporting detail 1</li> <li> <p>Supporting detail 2</p> </li> <li> <p>Pillar 6 (e.g., Upgrade Path Considerations)</p> </li> <li>Supporting detail 1</li> <li>Supporting detail 2</li> </ul>"},{"location":"adr/ADR-0000-template/#deferred-alternatives","title":"Deferred Alternatives","text":"<p>[What alternatives are we deferring for future consideration?]</p> <p>Alternative: [Name] - Trigger: [What condition would make us reconsider this?] - Timeline: [When should we revisit this?] - Reason for deferral: [Why not now?]</p> <p>Alternative: [Name] - Trigger: [What condition would make us reconsider this?] - Timeline: [When should we revisit this?] - Reason for deferral: [Why not now?]</p>"},{"location":"adr/ADR-0000-template/#rejected-alternatives","title":"Rejected Alternatives","text":"<p>[What alternatives are we rejecting?]</p> <ul> <li>Alternative X: Brief description and reason for rejection</li> <li>Alternative Y: Brief description and reason for rejection</li> </ul>"},{"location":"adr/ADR-0000-template/#consequences","title":"Consequences","text":"<p>[What becomes easier or more difficult to do because of this change?]</p> <p>Positive: - Benefit 1 - Benefit 2 - ...</p> <p>Negative: - Risk 1 - Risk 2 - ...</p> <p>Mitigation Strategies: - ... - ...</p>"},{"location":"adr/ADR-0000-template/#revisit-triggers","title":"Revisit Triggers","text":"<ul> <li>Condition 1 (e.g., ecosystem certification, measurable benefit)</li> <li>Condition 2 (e.g., scheduled upgrade window with regression capacity)</li> </ul>"},{"location":"adr/ADR-0000-template/#target-sprint-for-formal-decision","title":"Target Sprint for Formal Decision","text":"<ul> <li>Target Sprint: Sprint N (or timeframe) for adoption/change</li> </ul>"},{"location":"adr/ADR-0000-template/#guardrails","title":"Guardrails","text":""},{"location":"adr/ADR-0000-template/#must","title":"Must","text":"<ul> <li>Critical requirements that cannot be compromised</li> <li>Non-negotiable constraints</li> </ul>"},{"location":"adr/ADR-0000-template/#should","title":"Should","text":"<ul> <li>Important considerations that should be followed unless there's strong justification</li> <li>Best practices and preferred approaches</li> </ul>"},{"location":"adr/ADR-0000-template/#wont","title":"Won't","text":"<ul> <li>Explicit exclusions and out-of-scope items</li> <li>Things we deliberately choose not to do</li> </ul>"},{"location":"adr/ADR-0000-template/#approvals","title":"Approvals","text":"Review Reviewer Date (YYYY-MM-DD) Status Notes Architectural Review Pending Security Review Pending SRE Review Pending"},{"location":"adr/ADR-0000-template/#links","title":"Links","text":"<p>Review Before Deciding: - Performance benchmarks: /docs/benchmarks/api-performance.md - Security guidelines: /docs/security/security-guidelines.md - Architecture principles: /docs/architecture/principles.md - Technology radar: /docs/tech-radar/technology-radar.md - Cost analysis framework: /docs/cost-analysis/framework.md - Scalability patterns: /docs/patterns/scalability-patterns.md - Monitoring standards: /docs/monitoring/standards.md - Compliance requirements: /docs/compliance/requirements.md  </p> <p>Technology Landscape: [Link to relevant technology documentation]  </p> <p>Product/PRD: [Link to product requirements document]  </p> <p>Sprint Plan:[Link to sprint planning documentation]  </p> <p>Related ADRs: - [Link to related ADR] - [Link to related ADR]  </p>"},{"location":"adr/ADR-0001-java-17-runtime/","title":"ADR-0001: Java 17 as Language/Runtime","text":"<p>Author: @MysterTech Status: Accepted Date: 2025-08-13 Deciders: @MysterTech Technical Story: [optional link to ticket/issue] Tags: contracts, protobuf, versioning</p>"},{"location":"adr/ADR-0001-java-17-runtime/#context","title":"Context","text":"<ul> <li>We need a stable, well-supported runtime to deliver Phase 1 reliably; mixed Java versions and ad-hoc JDK choices across services are causing build inconsistencies, flaky CI pipelines, and environment drift between local/dev/prod.</li> <li>Several core frameworks (e.g., Spring Boot 3.x) and observability/tooling baselines are officially validated on Java 17; targeting newer LTS versions prematurely risks dependency incompatibilities and unplanned refactors during critical delivery windows.</li> <li>Teams are losing time troubleshooting version-specific quirks (toolchain, plugins, container images) due to lack of a single runtime standard, slowing onboarding and cross-service collaboration.</li> <li>Security updates and support timelines are harder to manage with heterogeneous runtimes; we need predictable LTS maintenance to meet operational and compliance expectations.</li> <li>Phase 1 emphasizes reliability and maintainability over adopting the newest features, so a proven LTS (Java 17) minimizes delivery risk while keeping a clear path for future upgrades.</li> </ul>"},{"location":"adr/ADR-0001-java-17-runtime/#decision","title":"Decision","text":"<p>Adopt Java 17 as the standard language/runtime for all backend services in Phase 1.</p>"},{"location":"adr/ADR-0001-java-17-runtime/#rationale","title":"Rationale","text":""},{"location":"adr/ADR-0001-java-17-runtime/#why-java-17-accepted","title":"Why Java 17 (Accepted)","text":"<p>Stability and Support (LTS) - Predictable maintenance and security updates aligned with enterprise expectations. - Reduced risk window during Phase 1 due to longer support horizon. - Vendor ecosystem (JDK vendors, container images) provides mature, stable distributions.</p> <p>Ecosystem Readiness - Frameworks   - Spring Boot 3.x and related starters are widely validated on Java 17.   - Strong ecosystem of testing libraries (JUnit 5, Testcontainers) supports Java 17. - Tooling   - Build tools (Gradle/Maven) natively support Java 17 toolchains.   - Observability agents (e.g., OpenTelemetry Java agent) and profilers are Java 17\u2013compatible. - CI/CD   - Cloud runners and base images for Java 17 are standard and maintained.</p> <p>Team Proficiency and Velocity - Familiarity with JVM reduces onboarding and avoids context switching. - Established patterns for debugging, profiling, and tuning on the JVM. - Minimizes polyglot operational overhead in Phase 1.</p> <p>Modern JVM Features (without near-term migration burden) - Language features   - Records for concise immutable data carriers.   - Sealed classes for controlled inheritance and domain modeling. - Runtime improvements   - Mature GC options (e.g., G1/ZGC) for latency-sensitive services.   - JVM performance optimizations benefiting microservices footprints.</p> <p>Risk Management for Phase 1 - Avoids introducing a new LTS upgrade path mid\u2011phase (e.g., Java 21) before dependency readiness. - Minimizes integration churn across multiple services and pipelines. - Keeps focus on delivering PRD-defined core flows rather than platform migrations.</p> <p>Upgrade Path Considerations - Structured path to Java 21 (or newer) when:   - Critical dependencies are certified and performance gains are tangible.   - A test window is scheduled to run regression/performance suites. - Build toolchain configured to ease future LTS bumps (centralized toolchain configuration).</p>"},{"location":"adr/ADR-0001-java-17-runtime/#alternatives-considered","title":"Alternatives Considered","text":"<p>Java 21 LTS - Pros: Newer LTS with incremental JVM improvements. - Cons: Some dependencies/tooling may lag certification; introducing an upgrade during Phase 1 could add risk and testing overhead.</p> <p>Kotlin-first on JVM - Pros: Language ergonomics (null-safety, coroutines, data classes). - Cons: Baseline language shift not required to meet PRD Phase 1 goals; can be introduced selectively later without changing runtime.</p> <p>Node/TypeScript - Pros: Rapid iteration for certain I/O-heavy services. - Cons: Polyglot complexity, diverges from JVM stack and team strengths; not necessary to meet Phase 1 scope.</p>"},{"location":"adr/ADR-0001-java-17-runtime/#consequences","title":"Consequences","text":"<p>Positive: - Consistent build and runtime across services, simplifying CI/CD pipelines and operational practices. - Access to modern JVM features (e.g., records, sealed classes, improved GC), improving code clarity and potential performance. - Strong ecosystem support accelerates development and minimizes integration risks. - Team proficiency with JVM enables faster onboarding and debugging capabilities. - Predictable LTS maintenance window aligns with Phase 1 delivery timelines.</p> <p>Negative: - Future upgrade path to next LTS (e.g., Java 21) will require dependency validation and performance testing. - Potential missed opportunities from newer language features in Java 21. - Larger memory footprint compared to more lightweight runtime alternatives.</p> <p>Mitigation Strategies: - Maintain compatibility matrix for critical libraries to track next LTS readiness. - Configure centralized build toolchains to ease future LTS upgrades. - Schedule regular evaluation of Java 21 adoption benefits and ecosystem readiness. - Implement performance benchmarks to measure upgrade impact.</p>"},{"location":"adr/ADR-0001-java-17-runtime/#revisit-trigger-and-target-sprint","title":"Revisit Trigger and Target Sprint","text":"<ul> <li>Revisit Trigger:</li> <li>All critical dependencies and tooling are certified on the next LTS (e.g., Java 21) and there is a measurable benefit (performance, maintainability, security).</li> <li>A scheduled upgrade window is available with capacity for comprehensive regression testing.</li> <li>Target Sprint:</li> <li>Sprint 1 (adoption finalized in Phase 1 foundations)</li> </ul>"},{"location":"adr/ADR-0001-java-17-runtime/#guardrails","title":"Guardrails","text":""},{"location":"adr/ADR-0001-java-17-runtime/#must","title":"Must","text":"<ul> <li>Use only LTS (Long Term Support) releases for JVM in production; never mix runtimes across services.</li> <li>Centralize all build (Gradle/Maven) configurations and container images; keep them version-locked and reviewed in CI.</li> <li>Track and document LTS readiness of all critical dependencies for upgrade planning.</li> <li>Require performance, regression, and compatibility testing for every runtime upgrade or change.</li> <li>Follow a standardized migration playbook for major Java upgrades, including rollback and validation steps.</li> </ul>"},{"location":"adr/ADR-0001-java-17-runtime/#should","title":"Should","text":"<ul> <li>Review ecosystem and dependency readiness for new Java releases at least quarterly.</li> <li>Document upgrade blockers and mitigation strategies before proposing LTS changes.</li> <li>Maintain uniform JVM and build tooling across environments (local/dev/CI/prod).</li> <li>Periodically benchmark services to assess future upgrade benefits and risks.</li> </ul>"},{"location":"adr/ADR-0001-java-17-runtime/#wont","title":"Won't","text":"<ul> <li>Allow ad-hoc runtime or toolchain changes without ADR-backed review and CI validation.</li> <li>Mix non-LTS Java or alternative JVM languages into the baseline without architectural approval.</li> <li>Perform major upgrades during critical delivery windows or without rollback planning.</li> </ul>"},{"location":"adr/ADR-0001-java-17-runtime/#approvals","title":"Approvals","text":"Review Reviewer Date (YYYY-MM-DD) Status Notes Architectural Review @MysterTech 2025-08-14 Approved Security Review @MysterTech 2025-08-14 Approved SRE Review @MysterTech 2025-08-14 Approved"},{"location":"adr/ADR-0001-java-17-runtime/#links","title":"Links","text":""},{"location":"adr/ADR-0002-r3-corda-5-dlt-platform/","title":"ADR-0002: R3 Corda 5 as DLT Platform","text":"<p>Author: @MysterTech Status: Accepted Date: 2025-08-13 Deciders: @MysterTech Technical Story: [optional link to ticket/issue] Tags: dlt, corda, blockchain</p>"},{"location":"adr/ADR-0002-r3-corda-5-dlt-platform/#context","title":"Context","text":"<ul> <li>DealSphere platform requires a distributed ledger technology (DLT) platform for secure, tamper-proof transaction recording and multi-party business process execution.</li> <li>R3 Corda 5 provides enterprise-grade DLT capabilities specifically designed for regulated financial services and complex business networks.</li> <li>Team expertise includes blockchain development experience, and Corda's JVM-based architecture aligns with existing Java 17 runtime decisions.</li> <li>PRD alignment: Security requirements and regulatory compliance for financial transactions are prioritized for Phase 1 core flows.</li> </ul>"},{"location":"adr/ADR-0002-r3-corda-5-dlt-platform/#decision","title":"Decision","text":"<p>Adopt R3 Corda 5 as the distributed ledger technology platform for DealSphere Phase 1.</p>"},{"location":"adr/ADR-0002-r3-corda-5-dlt-platform/#rationale","title":"Rationale","text":""},{"location":"adr/ADR-0002-r3-corda-5-dlt-platform/#why-r3-corda-5-as-dlt-platform","title":"Why R3 Corda 5 as DLT Platform?","text":"<p>Enterprise-Grade Security and Compliance: - Built-in privacy features with need-to-know data sharing principles. - Strong cryptographic foundations and secure communication protocols. - Regulatory compliance features aligned with financial services requirements. - Mature audit trails and transaction history capabilities.</p> <p>Technical Architecture Alignment: - JVM-based platform compatible with Java 17 runtime decision. - Spring Boot integration capabilities for microservices architecture. - REST and gRPC API support for seamless service integration. - Familiar development patterns reducing team onboarding overhead.</p> <p>Business Network Capabilities: - Multi-party transaction support essential for deal syndication workflows. - Smart contract (CorDapp) development for complex business logic. - Identity and certificate management for trusted counterparty networks. - Pluggable consensus mechanisms for different transaction types.</p> <p>Operational Maturity: - Production-ready platform with enterprise support options. - Comprehensive monitoring and observability tools integration. - Docker containerization support for Phase 1 orchestration strategy. - Established backup and disaster recovery patterns.</p> <p>Risk Management for Phase 1: - Proven track record in financial services implementations. - Active community and R3 support for issue resolution. - Clear upgrade paths and version compatibility strategies. - Minimizes experimental technology risk during initial platform delivery.</p> <p>Performance Characteristics: - Optimized for financial transaction throughput requirements. - Deterministic finality for transaction settlement scenarios. - Scalable node architecture supporting network growth. - Efficient resource utilization in containerized environments.</p>"},{"location":"adr/ADR-0002-r3-corda-5-dlt-platform/#alternatives-considered","title":"Alternatives Considered","text":"<p>Hyperledger Fabric - Pros: Open-source platform with strong enterprise adoption. - Cons: More complex operational overhead; Go/Node.js ecosystem diverges from JVM stack; less financial services specific features. - Rejected: Does not align with JVM-based technology stack and financial services focus.</p> <p>Ethereum (Enterprise) - Pros: Large ecosystem and developer community. - Cons: Significant development and maintenance overhead; security risks from custom cryptography; delays Phase 1 delivery timeline. - Rejected: Too high risk and development overhead for Phase 1 timeline.</p>"},{"location":"adr/ADR-0002-r3-corda-5-dlt-platform/#consequences","title":"Consequences","text":"<p>Positive: - DLT integration enables secure multi-party deal processing with cryptographic transaction integrity. - Corda's privacy model ensures sensitive deal information is only shared with relevant counterparties. - JVM-based development stack maintains consistency with Java 17 and microservices architecture decisions. - Enterprise-grade security and compliance features align with financial services requirements. - Established development patterns reduce team onboarding overhead.</p> <p>Negative: - Requires team training on Corda-specific concepts (states, flows, contracts) but leverages existing JVM skills. - Platform lock-in to R3 ecosystem and potential licensing costs. - Performance limitations compared to traditional databases for non-DLT operations. - Additional operational complexity for node management and network coordination.</p> <p>Mitigation Strategies: - Maintain abstraction layer between business logic and Corda-specific implementations. - Establish comprehensive training program for Corda development patterns. - Implement performance benchmarks and monitoring for transaction throughput. - Document all CorDapp development patterns and maintain code review standards.</p>"},{"location":"adr/ADR-0002-r3-corda-5-dlt-platform/#revisit-trigger-and-target-sprint","title":"Revisit Trigger and Target Sprint","text":"<ul> <li> <p>Revisit Triggers:  </p> </li> <li> <p>Performance bottlenecks emerge that cannot be resolved through configuration or infrastructure scaling.  </p> </li> <li> <p>Regulatory requirements change significantly requiring features not available in Corda 5.  </p> </li> <li> <p>Major security vulnerabilities discovered that cannot be patched within acceptable timeframes.</p> </li> <li> <p>Target Sprint:  </p> </li> <li> <p>Sprint 1 (DLT platform foundation established in Phase 1)</p> </li> </ul>"},{"location":"adr/ADR-0002-r3-corda-5-dlt-platform/#guardrails","title":"Guardrails","text":""},{"location":"adr/ADR-0002-r3-corda-5-dlt-platform/#must","title":"Must","text":"<ul> <li>Maintain abstraction layer between business logic and Corda-specific implementations to enable future platform migration if needed.</li> <li>Establish performance benchmarks and monitoring for transaction throughput and latency.</li> <li>Keep Corda version compatibility matrix updated and plan regular security updates.</li> </ul>"},{"location":"adr/ADR-0002-r3-corda-5-dlt-platform/#should","title":"Should","text":"<ul> <li>Document all CorDapp development patterns and maintain code review standards for smart contract logic.</li> <li>Implement comprehensive testing strategies for Corda flows and contracts.</li> </ul>"},{"location":"adr/ADR-0002-r3-corda-5-dlt-platform/#wont","title":"Won't","text":"<ul> <li>Allow direct database access bypassing Corda's data model.</li> <li>Implement custom cryptographic solutions without R3 approval.</li> <li>Deploy CorDapps without proper code review and security assessment.</li> </ul>"},{"location":"adr/ADR-0002-r3-corda-5-dlt-platform/#approvals","title":"Approvals","text":"Review Reviewer Date (YYYY-MM-DD) Status Notes Architectural Review @MysterTech 2025-08-14 Approved Security Review @MysterTech 2025-08-14 Approved SRE Review @MysterTech 2025-08-14 Approved"},{"location":"adr/ADR-0002-r3-corda-5-dlt-platform/#links","title":"Links","text":"<p>Technology Landscape: [DLT Platform] Sprint Plan: [Sprint 1 \u2013 Core Platform Foundation] PRD: Security requirements and regulatory compliance </p> <p>Related ADRs: - ADR-0001: Java 17 as Language/Runtime </p>"},{"location":"adr/ADR-0003-docker-compose-phase1-orchestration/","title":"ADR-0003: Docker Compose for Phase 1 Orchestration","text":"<p>Author: @MysterTech    Status: Accepted     Date: 2025-08-13     Deciders: @MysterTech   Technical Story: Tags: orchestration, docker, compose    </p>"},{"location":"adr/ADR-0003-docker-compose-phase1-orchestration/#context","title":"Context","text":"<ul> <li>DealSphere Phase 1 requires local development and integration testing environments that closely mirror production service topology.</li> <li>Docker Compose provides container orchestration capabilities suitable for multi-service development environments and CI/CD workflows.</li> <li>Team familiarity with containerization patterns and Docker ecosystem tools supports rapid adoption and troubleshooting.</li> <li>PRD alignment: Development workflow and deployment strategy are prioritized for Phase 1 delivery timelines.</li> </ul>"},{"location":"adr/ADR-0003-docker-compose-phase1-orchestration/#decision","title":"Decision","text":"<p>Adopt Docker Compose as the container orchestration platform for DealSphere Phase 1 local development, testing, and CI/CD environments.</p>"},{"location":"adr/ADR-0003-docker-compose-phase1-orchestration/#rationale","title":"Rationale","text":""},{"location":"adr/ADR-0003-docker-compose-phase1-orchestration/#why-docker-compose-for-phase-1-orchestration","title":"Why Docker Compose for Phase 1 Orchestration?","text":"<p>Development Environment Consistency     - Standardized service configuration across all developer workstations.     - Reproducible dependency management for databases, message brokers, and external service mocks.     - Version-controlled environment definitions ensuring team alignment.     - Simple service lifecycle management (start/stop/restart) for rapid iteration.</p> <p>Integration Testing Support     - Multi-container test suites with predictable service startup ordering.     - Network isolation and service-to-service communication testing.     - Database and external service state management for test scenarios.     - CI/CD pipeline integration with consistent environment provisioning.</p> <p>Operational Simplicity     - Single-file service definitions (<code>docker-compose.yml</code>) for easy maintenance.     - Built-in service discovery and DNS resolution between containers.     - Volume mounting for development hot-reloading and persistent data.     - Log aggregation and debugging tools compatible with Docker ecosystem.</p> <p>Resource Management     - Efficient resource utilization on developer machines compared to VM-based alternatives.     - Fine-grained resource allocation per service (CPU/memory limits).     - Automatic cleanup and container lifecycle management.     - Minimal infrastructure overhead for local development workflows.</p> <p>Technology Stack Alignment     - Native Docker image support for Java 17 services and Spring Boot applications.     - PostgreSQL, Redis, and other backing service containers readily available.     - Corda node containerization patterns established in community.     - GraphQL and gRPC service containerization well-documented.</p> <p>CI/CD Integration     - GitHub Actions and other CI systems provide built-in Docker Compose support.     - Consistent environment definitions between local development and automated testing.     - Parallel service builds and testing capabilities.     - Easy integration with container registries for artifact management.</p>"},{"location":"adr/ADR-0003-docker-compose-phase1-orchestration/#deferred-alternatives","title":"Deferred Alternatives","text":"<p>Kubernetes (Minikube/Kind)     - Pros: Production-like orchestration capabilities and advanced networking features.     - Cons: Significantly higher complexity for Phase 1 scope; resource overhead; learning curve.</p>"},{"location":"adr/ADR-0003-docker-compose-phase1-orchestration/#rejected-alternatives","title":"Rejected Alternatives","text":"<p>VM-based Development     - Pros: Complete isolation and familiar virtualization patterns.     - Cons: Higher resource consumption; slower startup; complex dependency management.</p> <p>Manual Service Management     - Pros: Direct control over configuration and debugging.     - Cons: Inconsistent environments; complex coordination; difficult integration testing.</p>"},{"location":"adr/ADR-0003-docker-compose-phase1-orchestration/#consequences","title":"Consequences","text":"<ul> <li>Positive:<ul> <li>Standardized environments reduce \"works on my machine\" issues and improve team productivity.</li> <li>Multi-service integration testing is reliable and reproducible.</li> <li>Container-based architecture provides a foundation for future Kubernetes migration.</li> </ul> </li> <li>Negative:<ul> <li>Requires all team members to have Docker knowledge.</li> </ul> </li> <li>Mitigation Strategies:<ul> <li>Provide comprehensive Docker/containerization training.</li> <li>Create detailed documentation for common workflows/troubleshooting.</li> <li>Establish service configuration/resource allocation guidelines.</li> </ul> </li> </ul>"},{"location":"adr/ADR-0003-docker-compose-phase1-orchestration/#revisit-trigger-and-target-sprint","title":"Revisit Trigger and Target Sprint","text":"<ul> <li>Revisit Trigger:<ul> <li>Service scaling needs exceed single-machine capabilities.</li> <li>Production needs require advanced orchestration (service mesh, networking, etc.).</li> <li>Team size growth complicates coordination.</li> </ul> </li> <li>Target Sprint:<ul> <li>Sprint 1 (orchestration foundation established for Phase 1).</li> </ul> </li> </ul>"},{"location":"adr/ADR-0003-docker-compose-phase1-orchestration/#guardrails","title":"Guardrails","text":""},{"location":"adr/ADR-0003-docker-compose-phase1-orchestration/#must","title":"Must","text":"<ul> <li>Maintain environment parity between Docker Compose configurations and production deployments.</li> <li>Document service interdependencies and startup ordering in compose files.</li> <li>Set resource limits and health checks for all services.</li> <li>Keep configurations version-controlled and synchronized.</li> </ul>"},{"location":"adr/ADR-0003-docker-compose-phase1-orchestration/#should","title":"Should","text":"<ul> <li>Review Docker Compose and service dependency documentation quarterly.</li> <li>Automate health checks and resource limit validation in CI workflows.</li> <li>Peer-review all configuration changes before merging to main branch.</li> </ul>"},{"location":"adr/ADR-0003-docker-compose-phase1-orchestration/#wont","title":"Won't","text":"<ul> <li>Allow undocumented ad-hoc configuration changes.</li> <li>Permit divergence between development and production orchestration files without explicit architectural review.</li> <li>Support container versions/services that lack defined health checks or resource limits.</li> </ul>"},{"location":"adr/ADR-0003-docker-compose-phase1-orchestration/#approvals","title":"Approvals","text":"Review Reviewer Date (YYYY-MM-DD) Status Notes Architectural Review @MysterTech 2025-08-14 Approved Security Review @MysterTech 2025-08-14 Approved SRE Review @MysterTech 2025-08-14 Approved"},{"location":"adr/ADR-0003-docker-compose-phase1-orchestration/#links","title":"Links","text":"<ul> <li>Technology Landscape: [Orchestration Platform]</li> <li>Sprint Plan: [Sprint 1 \u2013 Development Environment Setup]</li> <li>Related ADRs:<ul> <li>ADR-0001: Java 17 as Language/Runtime</li> </ul> </li> </ul>"},{"location":"adr/ADR-0004-service-framework-defaults/","title":"ADR-0004: Service Framework Default Selection","text":"<p>Author: @MysterTech Status: Accepted Date: 2025-08-13 Deciders: @MysterTech Technical Story: [optional link to ticket/issue] Tags: framework, dgs, graphql, services  </p>"},{"location":"adr/ADR-0004-service-framework-defaults/#context","title":"Context","text":"<ul> <li>Services are being bootstrapped with divergent patterns (project structure, configuration, security, telemetry), leading to inconsistent realization of core Phase 1 capabilities (permissions, documents, capital calls, waterfalls, workflows, analytics, accounting, portfolio, AI), and increasing integration risk.</li> <li>Cross-cutting functional needs mandated by the PRD\u2014strict role/class-based access, encrypted storage with hash verification, workflow SLAs and escalations, deterministic financial calculations, auditability, and API-first integrations are re-implemented differently across services, causing uneven behavior and slowing end-to-end validation.</li> <li>Inconsistent build/run conventions impede CI/CD policy enforcement required to meet PRD acceptance criteria (e.g., schema governance, security scans, performance/SLO checks, deterministic outputs for waterfalls, class segregation in AI and analytics).</li> <li>Developer onboarding and delivery velocity suffer because contributors must relearn patterns per service, delaying PRD milestones and increasing review/defect cycles.</li> <li>Phase 1 requires predictable, testable, and operable services across multiple domains and sprints; without shared defaults and guardrails, class-segregated flows (RBAC, documents, capital calls, waterfalls, workflows) and their acceptance criteria are harder to deliver reliably.</li> </ul> <p>Therefore, this ADR proposes establishing minimal, opinionated defaults and starter templates focused on PRD needs:</p> <ul> <li>Security &amp; Access: uniform authentication/authorization with strict class-level segregation and auditability.</li> <li>Data &amp; Documents: standardized configuration for encrypted storage, on-ledger metadata, content hash verification, and versioning/audit logs.</li> <li>Observability: consistent logs/metrics/traces with baseline dashboards/alerts to validate SLAs, workflow latencies, and compliance signals.</li> <li>Resiliency: timeouts, retries, circuit breakers, backoff, idempotency patterns to support workflow reliability and external integrations.</li> <li>Deterministic Calculations: conventions for numeric precision and validation harnesses to meet waterfall test vectors and accounting accuracy.</li> <li>CI/CD &amp; Quality: consistent build/test conventions, static analysis, coverage, schema checks, supply-chain security, and performance gates aligned to acceptance criteria.</li> <li>Interfaces &amp; Contracts: API/schema standards and error contracts to support API-first integrations and PRD traceability.</li> <li>Developer Workflow: coherent local dev, testing, and documentation to reduce time-to-first-commit and hit sprint timelines.</li> </ul>"},{"location":"adr/ADR-0004-service-framework-defaults/#decision","title":"Decision","text":"<p>Adopt Netflix DGS (GraphQL Java with DGS) as the default service framework for Phase 1 services, with standardized starter configurations and common patterns.</p>"},{"location":"adr/ADR-0004-service-framework-defaults/#rationale","title":"Rationale","text":""},{"location":"adr/ADR-0004-service-framework-defaults/#why-netflix-dgs-service-framework-default-selection","title":"Why Netflix DGS (Service Framework Default Selection)","text":"<p>Stability and Support</p> <ul> <li>GraphQL-first schema-driven development reduces boilerplate and accelerates service scaffolding</li> <li>Rich ecosystem of DGS features covers common requirements (code generation, schema registry, federation)</li> <li>Built-in observability (GraphQL instrumentation, metrics, health checks, logging)</li> <li>Native GraphQL federation support enables distributed schema composition and seamless gateway integration</li> </ul> <p>Ecosystem Readiness</p> <ul> <li>Consistent GraphQL patterns across services reduce context switching and onboarding time</li> <li>Mature tooling integration (schema linting, breaking-change detection, IDE support)</li> <li>Performance optimizations through data loader patterns and query cost analysis</li> </ul> <p>Team Proficiency and Velocity</p> <ul> <li>Standardized GraphQL development patterns across all microservices</li> <li>Reduced configuration drift through DGS code generation and schema registry integration</li> <li>Clear upgrade paths and long-term support from Netflix</li> </ul> <p>Modern Features without migration burden</p> <ul> <li>Security at GraphQL layer through authorization directives and middlewares</li> <li>Established patterns for query/mutation/subscription handling and federation/gateway compatibility</li> <li>Strong community support and comprehensive documentation</li> </ul> <p>Risk Management</p> <ul> <li>Accelerated development velocity for Phase 1 delivery</li> <li>GraphQL query cost limits and depth/complexity analysis for performance tuning</li> <li>Proven track record in similar microservices architectures at Netflix scale</li> </ul>"},{"location":"adr/ADR-0004-service-framework-defaults/#rejected-alternatives","title":"Rejected Alternatives","text":"<ul> <li>Spring Boot</li> <li>Reason for rejection: Rich ecosystem and team expertise, but adopting DGS focuses service delivery on GraphQL-first architecture, federation, and schema-driven contracts without additional REST overhead.</li> <li> <p>Reconsider if: REST-centric needs or gaps in DGS ecosystem for critical features arise after Phase 1.</p> </li> <li> <p>Quarkus</p> </li> <li>Reason for rejection: Fast startup and native compilation attractive, but extra learning curve and ecosystem risk during initial delivery; DGS better aligns with immediate GraphQL federation priorities.</li> <li> <p>Reconsider if: Post-Phase 1, performance profiling shows that native compilation or Quarkus features bring clear, material benefits.</p> </li> <li> <p>Micronaut</p> </li> <li>Reason for rejection: Lightweight and fast but adds framework diversity without decisive advantages for GraphQL and federation over DGS, reducing standardization.</li> <li>Reconsider if: Team expertise or service requirements shift in Micronaut's favor, or unique features are required later.</li> </ul>"},{"location":"adr/ADR-0004-service-framework-defaults/#consequences","title":"Consequences","text":"<p>Positive:</p> <ul> <li>Standardized GraphQL development patterns across all microservices</li> <li>Reduced configuration drift through DGS code generation and schema registry integration</li> <li>Leveraged GraphQL ecosystem for query/mutation/subscription patterns and federation compatibility</li> <li>Accelerated development velocity for Phase 1 delivery through schema-driven development</li> <li>Consistent GraphQL instrumentation and observability across services</li> <li>Enhanced API contracts through GraphQL schema-first approach</li> <li>Improved pagination and caching patterns through GraphQL best practices</li> <li>Performance tuning capabilities with query cost limits and depth/complexity analysis</li> </ul> <p>Negative:</p> <ul> <li>Potential vendor lock-in to Netflix DGS ecosystem</li> <li>May not be optimal for non-GraphQL or high-throughput REST use cases</li> <li>Framework upgrade dependencies across multiple services</li> <li>Learning curve for teams unfamiliar with GraphQL patterns</li> </ul> <p>Mitigation Strategies:</p> <ul> <li>Maintain service interface contracts independent of framework implementation</li> <li>Use GraphQL schema-first approaches to reduce coupling to specific implementations</li> <li>Document migration patterns for future framework transitions</li> <li>Implement CI checks for schema linting and breaking-change detection</li> <li>Establish federation/gateway compatibility for gradual framework updates</li> </ul>"},{"location":"adr/ADR-0004-service-framework-defaults/#revisit-triggers","title":"Revisit Triggers","text":"<ul> <li>Performance bottlenecks identified in Phase 1 services</li> <li>Team expertise shifts significantly toward alternative frameworks</li> <li>Major Netflix DGS security vulnerabilities or end-of-life announcements</li> <li>GraphQL ecosystem shifts requiring different tooling approaches</li> </ul>"},{"location":"adr/ADR-0004-service-framework-defaults/#target-sprint-for-formal-decision","title":"Target Sprint for Formal Decision","text":"<p>Target Sprint: Sprint 1</p>"},{"location":"adr/ADR-0004-service-framework-defaults/#guardrails","title":"Guardrails","text":""},{"location":"adr/ADR-0004-service-framework-defaults/#must","title":"Must","text":"<ul> <li>All new services must use approved Netflix DGS starter templates</li> <li>Framework deviations require architecture review and explicit approval</li> <li>GraphQL schema contracts must follow federation/gateway compatibility standards</li> <li>Performance benchmarks must meet Phase 1 SLA requirements with query cost limits</li> <li>CI checks must include schema linting and breaking-change detection</li> </ul>"},{"location":"adr/ADR-0004-service-framework-defaults/#should","title":"Should","text":"<ul> <li>Follow Netflix DGS best practices for GraphQL schema design and code generation</li> <li>Implement standardized GraphQL instrumentation and observability patterns</li> <li>Use authorization directives and middlewares for security at GraphQL layer</li> <li>Apply data loader patterns for efficient data fetching</li> <li>Implement proper pagination and caching patterns</li> </ul>"},{"location":"adr/ADR-0004-service-framework-defaults/#wont","title":"Won't","text":"<ul> <li>Custom GraphQL implementations without architectural approval</li> <li>Framework mixing within individual services</li> <li>Bypassing established Netflix DGS patterns without justification</li> <li>Schema changes without proper versioning and breaking-change analysis</li> </ul>"},{"location":"adr/ADR-0004-service-framework-defaults/#approvals","title":"Approvals","text":"Review Reviewer Date (YYYY-MM-DD) Status Notes Architectural Review @MysterTech 2025-08-14 Approved Security Review @MysterTech 2025-08-14 Approved SRE Review @MysterTech 2025-08-14 Approved"},{"location":"adr/ADR-0004-service-framework-defaults/#links","title":"Links","text":"<p>Review Before Deciding: - Netflix DGS Documentation: Developer docs</p> <p>Technology Landscape: [Tech Landscape Document]</p> <p>Product/PRD: Phase 1 PRD - Service Framework</p> <p>Sprint Plan: [Link to sprint planning documentation]</p> <p>Related ADRs: - ADR-0001: Microservices Architecture - Establishes distributed system foundation</p>"},{"location":"deployment/","title":"Deployment Documentation","text":"<p>This section provides comprehensive guidance for deploying, operating, and securing the DealSphere platform across different environments.</p>"},{"location":"deployment/#documentation-overview","title":"\ud83d\udcd1 Documentation Overview","text":""},{"location":"deployment/#production-deployment","title":"Production Deployment","text":"<p>Complete guide for deploying DealSphere to production environments, covering: - Server preparation and requirements - Docker Compose deployment strategy - Kubernetes deployment with Helm charts - Environment configuration and optimization - SSL/TLS setup and security hardening - Database setup and migration procedures - Scaling and high availability configuration - Disaster recovery and backup strategies - Troubleshooting common deployment issues</p>"},{"location":"deployment/#cloud-infrastructure","title":"Cloud Infrastructure","text":"<p>Infrastructure-as-Code setup for major cloud providers: - AWS: ECS, RDS, ElastiCache, Application Load Balancer - Google Cloud: GKE, Cloud SQL, Redis, Load Balancer - Azure: AKS, PostgreSQL, Redis Cache, Application Gateway - Digital Ocean: Kubernetes, Managed Database, Load Balancer - Complete Terraform configurations for each platform - Cost optimization and resource management - Multi-region deployment strategies</p>"},{"location":"deployment/#environment-management","title":"Environment Management","text":"<p>Environment configuration and deployment pipeline management: - Environment variable structure and management - Development, staging, and production configurations - Secrets management with cloud-native solutions - CI/CD pipeline configuration with GitHub Actions - Environment validation and health checks - Configuration templates and best practices - Rolling deployment strategies - Smoke testing and deployment verification</p>"},{"location":"deployment/#observability-monitoring","title":"Observability &amp; Monitoring","text":"<p>Comprehensive monitoring, logging, and alerting setup: - Metrics Collection: Prometheus, Grafana, application metrics - Logging: Loki, Promtail, structured logging - Distributed Tracing: Jaeger, OpenTelemetry integration - Alerting: AlertManager, PagerDuty integration - Dashboards: Pre-configured Grafana dashboards - Infrastructure and application monitoring - Performance optimization and capacity planning - SLA/SLO tracking and compliance reporting</p>"},{"location":"deployment/#security-secrets-management","title":"Security &amp; Secrets Management","text":"<p>Security best practices and secrets management: - Data Encryption: At rest and in transit encryption - Secrets Management: AWS Secrets Manager, Kubernetes secrets - Access Control: JWT security, multi-factor authentication - Network Security: VPC, security groups, WAF configuration - Compliance: GDPR, SOC 2, audit logging - Security Monitoring: Real-time threat detection - Key Management: Rotation, backup, and recovery procedures</p>"},{"location":"deployment/#quick-start-deployment","title":"\ud83d\ude80 Quick Start Deployment","text":""},{"location":"deployment/#local-development","title":"Local Development","text":"<pre><code># Clone and start the development environment\ngit clone https://github.com/DealSphere-Inc/dealsphere-platform.git\ncd dealsphere-platform\ndocker-compose up -d\n</code></pre>"},{"location":"deployment/#production-deployment_1","title":"Production Deployment","text":"<pre><code># Using Docker Compose\ndocker-compose -f docker-compose.prod.yml up -d\n\n# Using Kubernetes\nhelm install dealsphere ./charts/dealsphere -f values.prod.yaml\n</code></pre>"},{"location":"deployment/#monitoring-stack","title":"Monitoring Stack","text":"<pre><code># Start comprehensive monitoring\ncd monitoring\ndocker-compose -f docker-compose.monitoring.yml up -d\n\n# Access dashboards\nopen http://localhost:3000  # Grafana (admin/admin123)\nopen http://localhost:9090  # Prometheus\nopen http://localhost:16686 # Jaeger\n</code></pre>"},{"location":"deployment/#deployment-checklist","title":"\ud83d\udccb Deployment Checklist","text":""},{"location":"deployment/#pre-deployment","title":"Pre-Deployment","text":"<ul> <li>[ ] Infrastructure provisioned and configured</li> <li>[ ] Secrets and environment variables configured</li> <li>[ ] SSL certificates obtained and configured</li> <li>[ ] Database migrations tested and ready</li> <li>[ ] Monitoring and alerting configured</li> <li>[ ] Backup and disaster recovery procedures tested</li> </ul>"},{"location":"deployment/#deployment","title":"Deployment","text":"<ul> <li>[ ] Deploy application with rolling update strategy</li> <li>[ ] Verify all services are healthy and responding</li> <li>[ ] Run smoke tests and integration tests</li> <li>[ ] Validate monitoring and alerting</li> <li>[ ] Test backup and recovery procedures</li> <li>[ ] Document any deployment-specific configurations</li> </ul>"},{"location":"deployment/#post-deployment","title":"Post-Deployment","text":"<ul> <li>[ ] Monitor application performance and errors</li> <li>[ ] Verify all integrations are working correctly</li> <li>[ ] Update documentation with any changes</li> <li>[ ] Conduct security review and vulnerability assessment</li> <li>[ ] Schedule regular health checks and maintenance</li> </ul>"},{"location":"deployment/#operations-and-maintenance","title":"\ud83d\udd27 Operations and Maintenance","text":""},{"location":"deployment/#regular-tasks","title":"Regular Tasks","text":"<ul> <li>Daily: Monitor dashboards, check alerts, review logs</li> <li>Weekly: Review performance metrics, capacity planning</li> <li>Monthly: Security patches, dependency updates, backup testing</li> <li>Quarterly: Disaster recovery testing, security audits</li> </ul>"},{"location":"deployment/#emergency-procedures","title":"Emergency Procedures","text":"<ul> <li>Service Outage: Follow runbook in production-deployment.md</li> <li>Security Incident: Escalate per security-secrets.md procedures</li> <li>Data Loss: Execute disaster recovery plan</li> <li>Performance Issues: Scale resources and investigate bottlenecks</li> </ul>"},{"location":"deployment/#support-and-escalation","title":"\ud83d\udcde Support and Escalation","text":""},{"location":"deployment/#internal-team","title":"Internal Team","text":"<ul> <li>DevOps Lead: Infrastructure and deployment issues</li> <li>Security Team: Security incidents and compliance</li> <li>Development Team: Application bugs and feature issues</li> <li>Product Team: Business logic and user experience</li> </ul>"},{"location":"deployment/#external-support","title":"External Support","text":"<ul> <li>Cloud Provider: Infrastructure and platform issues</li> <li>Third-party Services: Payment processing, email delivery</li> <li>Security Consultants: Incident response and forensics</li> </ul>"},{"location":"deployment/#additional-resources","title":"\ud83d\udcda Additional Resources","text":"<ul> <li>Architecture Decision Records</li> <li>Development Setup</li> <li>Technical Documentation</li> <li>QA and Testing</li> </ul> <p>This deployment documentation ensures reliable, secure, and scalable operations of the DealSphere platform across all environments.</p>"},{"location":"deployment/authentication-deployment/","title":"Authentication System Deployment Guide","text":""},{"location":"deployment/authentication-deployment/#overview","title":"Overview","text":"<p>This guide provides comprehensive deployment instructions for the DealSphere authentication system, covering production deployment, security configuration, and operational procedures.</p>"},{"location":"deployment/authentication-deployment/#prerequisites","title":"Prerequisites","text":""},{"location":"deployment/authentication-deployment/#system-requirements","title":"System Requirements","text":"<ul> <li>Java Runtime: OpenJDK 17+</li> <li>Node.js: v18+ with pnpm</li> <li>Database: PostgreSQL 14+</li> <li>Web Server: nginx 1.20+</li> <li>Container Runtime: Docker 20+ or Kubernetes 1.24+</li> </ul>"},{"location":"deployment/authentication-deployment/#external-services","title":"External Services","text":"<ul> <li>SMTP Service: For sending invitation and password reset emails</li> <li>Observability Stack: For security event logging (ELK, Datadog, etc.)</li> <li>SSL Certificates: Valid TLS certificates for HTTPS</li> </ul>"},{"location":"deployment/authentication-deployment/#environment-configuration","title":"Environment Configuration","text":""},{"location":"deployment/authentication-deployment/#production-environment-variables","title":"Production Environment Variables","text":"<p>Create a <code>.env.production</code> file with the following variables:</p> <pre><code># Application Configuration\nNODE_ENV=production\nSERVER_PORT=8080\nCLIENT_URL=https://app.dealsphere.com\n\n# Database Configuration\nDATABASE_URL=postgresql://username:password@db-host:5432/dealsphere_prod\nDATABASE_SSL=true\nDATABASE_POOL_SIZE=20\nDATABASE_CONNECTION_TIMEOUT=30000\n\n# JWT Configuration\nJWT_SECRET=your-super-secure-256-bit-secret-key-here\nJWT_EXPIRATION_MS=3600000  # 1 hour for production\nJWT_REFRESH_EXPIRATION_MS=604800000  # 7 days\n\n# Email Configuration\nSMTP_HOST=smtp.mailgun.com\nSMTP_PORT=587\nSMTP_USERNAME=postmaster@mg.dealsphere.com\nSMTP_PASSWORD=secure-smtp-password\nSMTP_FROM_ADDRESS=noreply@dealsphere.com\nSMTP_FROM_NAME=\"DealSphere Platform\"\nSMTP_USE_TLS=true\n\n# Security Configuration\nBCRYPT_ROUNDS=12\nRATE_LIMIT_ENABLED=true\nRATE_LIMIT_LOGIN_MAX=5\nRATE_LIMIT_LOGIN_WINDOW_MS=900000  # 15 minutes\nRATE_LIMIT_RESET_MAX=3\nRATE_LIMIT_RESET_WINDOW_MS=3600000  # 1 hour\n\n# Password Policy\nPASSWORD_MIN_LENGTH=8\nPASSWORD_RESET_EXPIRY_MINUTES=15\nINVITATION_EXPIRY_HOURS=48\n\n# CORS Configuration\nCORS_ALLOWED_ORIGINS=https://app.dealsphere.com,https://admin.dealsphere.com\nCORS_ALLOWED_METHODS=GET,POST,PUT,DELETE,OPTIONS\nCORS_ALLOWED_HEADERS=Origin,Content-Type,Accept,Authorization\nCORS_ALLOW_CREDENTIALS=true\n\n# External Observability\nOBSERVABILITY_ENDPOINT=https://api.observability-provider.com\nOBSERVABILITY_API_KEY=your-observability-api-key\nLOG_LEVEL=INFO\nSTRUCTURED_LOGGING=true\n\n# Feature Flags\nFEATURE_INVITATION_SYSTEM=true\nFEATURE_PASSWORD_RESET=true\nFEATURE_SECURITY_AUDITING=true\nFEATURE_RATE_LIMITING=true\n</code></pre>"},{"location":"deployment/authentication-deployment/#docker-compose-production","title":"Docker Compose Production","text":"<p>File: <code>docker-compose.prod.yml</code></p> <pre><code>version: '3.8'\n\nservices:\n  nginx:\n    image: nginx:alpine\n    ports:\n      - \"443:443\"\n      - \"80:80\"\n    volumes:\n      - ./nginx/nginx.prod.conf:/etc/nginx/nginx.conf:ro\n      - ./ssl:/etc/nginx/ssl:ro\n      - ./nginx/logs:/var/log/nginx\n    depends_on:\n      - backend\n      - frontend\n    restart: unless-stopped\n    networks:\n      - dealsphere-network\n\n  backend:\n    image: dealsphere/backend:${VERSION:-latest}\n    environment:\n      - SPRING_PROFILES_ACTIVE=production\n      - DATABASE_URL=${DATABASE_URL}\n      - JWT_SECRET=${JWT_SECRET}\n      - SMTP_HOST=${SMTP_HOST}\n      - SMTP_USERNAME=${SMTP_USERNAME}\n      - SMTP_PASSWORD=${SMTP_PASSWORD}\n    volumes:\n      - ./logs/backend:/app/logs\n    secrets:\n      - jwt_secret\n      - db_password\n      - smtp_password\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8080/actuator/health\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n      start_period: 40s\n    restart: unless-stopped\n    networks:\n      - dealsphere-network\n    depends_on:\n      - database\n\n  frontend:\n    image: dealsphere/frontend:${VERSION:-latest}\n    environment:\n      - NODE_ENV=production\n      - VITE_API_URL=https://api.dealsphere.com\n      - VITE_GRAPHQL_URL=https://api.dealsphere.com/graphql\n    volumes:\n      - ./logs/frontend:/app/logs\n    restart: unless-stopped\n    networks:\n      - dealsphere-network\n\n  database:\n    image: postgres:14-alpine\n    environment:\n      - POSTGRES_DB=dealsphere_prod\n      - POSTGRES_USER=dealsphere\n      - POSTGRES_PASSWORD_FILE=/run/secrets/db_password\n    volumes:\n      - postgres_data:/var/lib/postgresql/data\n      - ./database/backups:/backups\n    secrets:\n      - db_password\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -U dealsphere -d dealsphere_prod\"]\n      interval: 30s\n      timeout: 10s\n      retries: 5\n    restart: unless-stopped\n    networks:\n      - dealsphere-network\n\n  redis:\n    image: redis:7-alpine\n    command: redis-server --requirepass ${REDIS_PASSWORD}\n    volumes:\n      - redis_data:/data\n    healthcheck:\n      test: [\"CMD\", \"redis-cli\", \"ping\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n    restart: unless-stopped\n    networks:\n      - dealsphere-network\n\nvolumes:\n  postgres_data:\n  redis_data:\n\nsecrets:\n  jwt_secret:\n    external: true\n  db_password:\n    external: true\n  smtp_password:\n    external: true\n\nnetworks:\n  dealsphere-network:\n    driver: bridge\n</code></pre>"},{"location":"deployment/authentication-deployment/#kubernetes-deployment","title":"Kubernetes Deployment","text":"<p>File: <code>k8s/auth-deployment.yaml</code></p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: dealsphere-backend\n  labels:\n    app: dealsphere-backend\n    component: authentication\nspec:\n  replicas: 3\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n  selector:\n    matchLabels:\n      app: dealsphere-backend\n  template:\n    metadata:\n      labels:\n        app: dealsphere-backend\n        component: authentication\n    spec:\n      containers:\n      - name: backend\n        image: dealsphere/backend:latest\n        ports:\n        - containerPort: 8080\n          name: http\n        env:\n        - name: SPRING_PROFILES_ACTIVE\n          value: \"production\"\n        - name: DATABASE_URL\n          valueFrom:\n            secretKeyRef:\n              name: database-secret\n              key: url\n        - name: JWT_SECRET\n          valueFrom:\n            secretKeyRef:\n              name: jwt-secret\n              key: secret\n        - name: SMTP_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: smtp-secret\n              key: password\n        resources:\n          requests:\n            memory: \"512Mi\"\n            cpu: \"250m\"\n          limits:\n            memory: \"1Gi\"\n            cpu: \"500m\"\n        livenessProbe:\n          httpGet:\n            path: /actuator/health/liveness\n            port: 8080\n          initialDelaySeconds: 60\n          periodSeconds: 30\n          timeoutSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /actuator/health/readiness\n            port: 8080\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          timeoutSeconds: 5\n        securityContext:\n          runAsNonRoot: true\n          runAsUser: 1000\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: tmp\n          mountPath: /tmp\n        - name: logs\n          mountPath: /app/logs\n      volumes:\n      - name: tmp\n        emptyDir: {}\n      - name: logs\n        emptyDir: {}\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: dealsphere-backend-service\nspec:\n  selector:\n    app: dealsphere-backend\n  ports:\n  - name: http\n    port: 8080\n    targetPort: 8080\n  type: ClusterIP\n</code></pre>"},{"location":"deployment/authentication-deployment/#nginx-security-configuration","title":"nginx Security Configuration","text":""},{"location":"deployment/authentication-deployment/#production-nginx-configuration","title":"Production nginx Configuration","text":"<p>File: <code>nginx/nginx.prod.conf</code></p> <pre><code>user nginx;\nworker_processes auto;\nerror_log /var/log/nginx/error.log warn;\npid /var/run/nginx.pid;\n\nevents {\n    worker_connections 1024;\n    use epoll;\n    multi_accept on;\n}\n\nhttp {\n    include /etc/nginx/mime.types;\n    default_type application/octet-stream;\n\n    # Security headers\n    add_header X-Frame-Options \"SAMEORIGIN\" always;\n    add_header X-Content-Type-Options \"nosniff\" always;\n    add_header X-XSS-Protection \"1; mode=block\" always;\n    add_header Referrer-Policy \"strict-origin-when-cross-origin\" always;\n    add_header Strict-Transport-Security \"max-age=31536000; includeSubDomains\" always;\n    add_header Permissions-Policy \"geolocation=(), microphone=(), camera=()\" always;\n\n    # Content Security Policy\n    add_header Content-Security-Policy \"\n        default-src 'self';\n        script-src 'self' 'unsafe-inline' 'unsafe-eval' https://cdnjs.cloudflare.com https://unpkg.com;\n        style-src 'self' 'unsafe-inline' https://fonts.googleapis.com https://cdnjs.cloudflare.com;\n        font-src 'self' https://fonts.gstatic.com https://cdnjs.cloudflare.com;\n        img-src 'self' data: https: blob:;\n        connect-src 'self' wss: https://api.dealsphere.com;\n        media-src 'self';\n        object-src 'none';\n        child-src 'self';\n        frame-ancestors 'none';\n        base-uri 'self';\n        form-action 'self';\n        upgrade-insecure-requests;\n    \" always;\n\n    # Rate limiting zones\n    limit_req_zone $binary_remote_addr zone=auth:10m rate=5r/m;\n    limit_req_zone $binary_remote_addr zone=api:10m rate=30r/m;\n    limit_req_zone $binary_remote_addr zone=reset:10m rate=1r/m;\n    limit_req_zone $binary_remote_addr zone=static:10m rate=50r/m;\n\n    # Connection limiting\n    limit_conn_zone $binary_remote_addr zone=conn_limit_per_ip:10m;\n\n    # CORS origin mapping\n    map $http_origin $allowed_origin {\n        default \"\";\n        \"https://app.dealsphere.com\" $http_origin;\n        \"https://admin.dealsphere.com\" $http_origin;\n    }\n\n    # Upstream backend\n    upstream backend {\n        server dealsphere-backend:8080 max_fails=3 fail_timeout=30s;\n        keepalive 32;\n    }\n\n    # SSL Configuration\n    ssl_protocols TLSv1.2 TLSv1.3;\n    ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512:ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-GCM-SHA384;\n    ssl_prefer_server_ciphers on;\n    ssl_session_cache shared:SSL:10m;\n    ssl_session_timeout 10m;\n    ssl_stapling on;\n    ssl_stapling_verify on;\n\n    # Main server block\n    server {\n        listen 443 ssl http2;\n        server_name api.dealsphere.com;\n\n        ssl_certificate /etc/nginx/ssl/api.dealsphere.com.crt;\n        ssl_certificate_key /etc/nginx/ssl/api.dealsphere.com.key;\n\n        # Security\n        limit_conn conn_limit_per_ip 20;\n\n        # Authentication endpoints - strict rate limiting\n        location /api/auth/login {\n            limit_req zone=auth burst=10 nodelay;\n            limit_req_status 429;\n\n            # CORS\n            add_header 'Access-Control-Allow-Origin' '$allowed_origin' always;\n            add_header 'Access-Control-Allow-Methods' 'POST, OPTIONS' always;\n            add_header 'Access-Control-Allow-Headers' 'Origin, Content-Type, Accept, Authorization' always;\n            add_header 'Access-Control-Allow-Credentials' 'true' always;\n            add_header 'Access-Control-Max-Age' '86400' always;\n\n            if ($request_method = OPTIONS) {\n                return 204;\n            }\n\n            proxy_pass http://backend;\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_set_header X-Forwarded-Proto $scheme;\n            proxy_connect_timeout 30s;\n            proxy_send_timeout 30s;\n            proxy_read_timeout 30s;\n        }\n\n        # Password reset - very strict rate limiting\n        location /api/auth/request-password-reset {\n            limit_req zone=reset burst=2 nodelay;\n            limit_req_status 429;\n\n            # CORS\n            add_header 'Access-Control-Allow-Origin' '$allowed_origin' always;\n            add_header 'Access-Control-Allow-Methods' 'POST, OPTIONS' always;\n            add_header 'Access-Control-Allow-Headers' 'Origin, Content-Type, Accept' always;\n            add_header 'Access-Control-Allow-Credentials' 'true' always;\n\n            if ($request_method = OPTIONS) {\n                return 204;\n            }\n\n            proxy_pass http://backend;\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_set_header X-Forwarded-Proto $scheme;\n        }\n\n        # General API endpoints\n        location /api/ {\n            limit_req zone=api burst=50 nodelay;\n            limit_req_status 429;\n\n            # CORS\n            add_header 'Access-Control-Allow-Origin' '$allowed_origin' always;\n            add_header 'Access-Control-Allow-Methods' 'GET, POST, PUT, DELETE, OPTIONS' always;\n            add_header 'Access-Control-Allow-Headers' 'Origin, Content-Type, Accept, Authorization' always;\n            add_header 'Access-Control-Allow-Credentials' 'true' always;\n            add_header 'Access-Control-Max-Age' '86400' always;\n\n            if ($request_method = OPTIONS) {\n                return 204;\n            }\n\n            proxy_pass http://backend;\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_set_header X-Forwarded-Proto $scheme;\n            proxy_connect_timeout 30s;\n            proxy_send_timeout 60s;\n            proxy_read_timeout 60s;\n            proxy_buffering on;\n            proxy_buffer_size 4k;\n            proxy_buffers 8 4k;\n        }\n\n        # Health checks\n        location /health {\n            access_log off;\n            return 200 \"healthy\\n\";\n            add_header Content-Type text/plain;\n        }\n    }\n\n    # Frontend server\n    server {\n        listen 443 ssl http2;\n        server_name app.dealsphere.com;\n\n        ssl_certificate /etc/nginx/ssl/app.dealsphere.com.crt;\n        ssl_certificate_key /etc/nginx/ssl/app.dealsphere.com.key;\n\n        root /var/www/html;\n        index index.html;\n\n        # Static files with caching\n        location /static/ {\n            limit_req zone=static burst=100 nodelay;\n            expires 1y;\n            add_header Cache-Control \"public, immutable\";\n            add_header X-Content-Type-Options \"nosniff\";\n        }\n\n        # SPA routing\n        location / {\n            try_files $uri $uri/ /index.html;\n            expires 1h;\n            add_header Cache-Control \"public, no-cache, must-revalidate\";\n        }\n    }\n\n    # HTTP to HTTPS redirect\n    server {\n        listen 80;\n        server_name api.dealsphere.com app.dealsphere.com;\n        return 301 https://$server_name$request_uri;\n    }\n}\n</code></pre>"},{"location":"deployment/authentication-deployment/#database-setup","title":"Database Setup","text":""},{"location":"deployment/authentication-deployment/#postgresql-production-configuration","title":"PostgreSQL Production Configuration","text":"<p>File: <code>database/postgresql.prod.conf</code></p> <pre><code># PostgreSQL production configuration for authentication system\n\n# Connection settings\nlisten_addresses = '*'\nport = 5432\nmax_connections = 100\nshared_buffers = 256MB\neffective_cache_size = 1GB\nwork_mem = 4MB\nmaintenance_work_mem = 64MB\n\n# WAL settings\nwal_level = replica\nmax_wal_senders = 3\ncheckpoint_completion_target = 0.9\nwal_buffers = 16MB\ncheckpoint_segments = 32\n\n# Logging\nlog_destination = 'stderr'\nlog_line_prefix = '%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h '\nlog_statement = 'ddl'\nlog_min_duration_statement = 1000\nlog_connections = on\nlog_disconnections = on\n\n# Security\nssl = on\nssl_cert_file = '/etc/ssl/certs/server.crt'\nssl_key_file = '/etc/ssl/private/server.key'\npassword_encryption = scram-sha-256\n\n# Performance\nrandom_page_cost = 1.1\nseq_page_cost = 1.0\ndefault_statistics_target = 100\n</code></pre>"},{"location":"deployment/authentication-deployment/#database-migration-script","title":"Database Migration Script","text":"<p>File: <code>database/migrate.sh</code></p> <pre><code>#!/bin/bash\nset -e\n\n# Database migration script for production deployment\n\n# Configuration\nDB_HOST=${DB_HOST:-localhost}\nDB_PORT=${DB_PORT:-5432}\nDB_NAME=${DB_NAME:-dealsphere_prod}\nDB_USER=${DB_USER:-dealsphere}\nDB_PASSWORD=${DB_PASSWORD}\n\n# Check if database exists\necho \"Checking database connection...\"\nPGPASSWORD=$DB_PASSWORD psql -h $DB_HOST -p $DB_PORT -U $DB_USER -d postgres -c \"SELECT 1\" &gt; /dev/null\n\n# Create database if it doesn't exist\nPGPASSWORD=$DB_PASSWORD psql -h $DB_HOST -p $DB_PORT -U $DB_USER -d postgres -tc \"SELECT 1 FROM pg_database WHERE datname = '$DB_NAME'\" | grep -q 1 || {\n    echo \"Creating database $DB_NAME...\"\n    PGPASSWORD=$DB_PASSWORD psql -h $DB_HOST -p $DB_PORT -U $DB_USER -d postgres -c \"CREATE DATABASE $DB_NAME\"\n}\n\n# Run migrations\necho \"Running Flyway migrations...\"\nflyway -url=jdbc:postgresql://$DB_HOST:$DB_PORT/$DB_NAME \\\n       -user=$DB_USER \\\n       -password=$DB_PASSWORD \\\n       -locations=filesystem:./migrations \\\n       migrate\n\n# Verify migration\necho \"Verifying database structure...\"\nPGPASSWORD=$DB_PASSWORD psql -h $DB_HOST -p $DB_PORT -U $DB_USER -d $DB_NAME -c \"\nSELECT\n    schemaname,\n    tablename,\n    tableowner\nFROM pg_tables\nWHERE schemaname = 'public'\nORDER BY tablename;\n\"\n\necho \"Database migration completed successfully!\"\n</code></pre>"},{"location":"deployment/authentication-deployment/#security-configuration","title":"Security Configuration","text":""},{"location":"deployment/authentication-deployment/#ssl-certificate-setup","title":"SSL Certificate Setup","text":"<pre><code>#!/bin/bash\n# SSL certificate setup script\n\n# Create SSL directory\nmkdir -p /etc/nginx/ssl\n\n# Generate certificates using certbot (Let's Encrypt)\ncertbot certonly \\\n  --nginx \\\n  --email admin@dealsphere.com \\\n  --agree-tos \\\n  --no-eff-email \\\n  -d api.dealsphere.com \\\n  -d app.dealsphere.com \\\n  -d admin.dealsphere.com\n\n# Set proper permissions\nchown -R nginx:nginx /etc/nginx/ssl\nchmod 600 /etc/nginx/ssl/*.key\nchmod 644 /etc/nginx/ssl/*.crt\n\n# Setup auto-renewal\necho \"0 2 * * * /usr/bin/certbot renew --quiet &amp;&amp; systemctl reload nginx\" | crontab -\n</code></pre>"},{"location":"deployment/authentication-deployment/#jwt-security-configuration","title":"JWT Security Configuration","text":"<p>File: <code>security/jwt-setup.sh</code></p> <pre><code>#!/bin/bash\n# JWT security setup\n\n# Generate secure JWT secret (256-bit)\nJWT_SECRET=$(openssl rand -base64 64 | tr -d '\\n')\necho \"Generated JWT secret: $JWT_SECRET\"\n\n# Store in Docker secrets\necho $JWT_SECRET | docker secret create jwt_secret -\n\n# Store in Kubernetes secret\nkubectl create secret generic jwt-secret \\\n  --from-literal=secret=$JWT_SECRET \\\n  --namespace=dealsphere\n\n# Verify secret creation\necho \"JWT secret created successfully!\"\n</code></pre>"},{"location":"deployment/authentication-deployment/#database-security-setup","title":"Database Security Setup","text":"<pre><code>#!/bin/bash\n# Database security setup\n\n# Create database user with limited privileges\nPGPASSWORD=$POSTGRES_PASSWORD psql -U postgres -c \"\nCREATE USER dealsphere WITH PASSWORD '$DB_PASSWORD';\nCREATE DATABASE dealsphere_prod OWNER dealsphere;\nGRANT CONNECT ON DATABASE dealsphere_prod TO dealsphere;\nGRANT USAGE ON SCHEMA public TO dealsphere;\nGRANT CREATE ON SCHEMA public TO dealsphere;\nGRANT SELECT, INSERT, UPDATE, DELETE ON ALL TABLES IN SCHEMA public TO dealsphere;\nGRANT USAGE, SELECT ON ALL SEQUENCES IN SCHEMA public TO dealsphere;\nALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT SELECT, INSERT, UPDATE, DELETE ON TABLES TO dealsphere;\nALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT USAGE, SELECT ON SEQUENCES TO dealsphere;\n\"\n\n# Enable audit logging\necho \"shared_preload_libraries = 'pgaudit'\" &gt;&gt; /var/lib/postgresql/data/postgresql.conf\necho \"pgaudit.log = 'all'\" &gt;&gt; /var/lib/postgresql/data/postgresql.conf\necho \"pgaudit.log_catalog = off\" &gt;&gt; /var/lib/postgresql/data/postgresql.conf\n\necho \"Database security configuration completed!\"\n</code></pre>"},{"location":"deployment/authentication-deployment/#deployment-process","title":"Deployment Process","text":""},{"location":"deployment/authentication-deployment/#automated-deployment-script","title":"Automated Deployment Script","text":"<p>File: <code>deploy/deploy.sh</code></p> <pre><code>#!/bin/bash\nset -e\n\n# Deployment script for DealSphere authentication system\n\n# Configuration\nENVIRONMENT=${1:-production}\nVERSION=${2:-latest}\nHEALTH_CHECK_RETRIES=30\nHEALTH_CHECK_INTERVAL=10\n\n# Colors for output\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nNC='\\033[0m' # No Color\n\nlog() {\n    echo -e \"${GREEN}[$(date +'%Y-%m-%d %H:%M:%S')] $1${NC}\"\n}\n\nwarn() {\n    echo -e \"${YELLOW}[$(date +'%Y-%m-%d %H:%M:%S')] WARNING: $1${NC}\"\n}\n\nerror() {\n    echo -e \"${RED}[$(date +'%Y-%m-%d %H:%M:%S')] ERROR: $1${NC}\"\n    exit 1\n}\n\n# Pre-deployment checks\nlog \"Starting pre-deployment checks...\"\n\n# Check Docker is running\ndocker info &gt;/dev/null 2&gt;&amp;1 || error \"Docker is not running\"\n\n# Check required environment variables\nrequired_vars=(\"DATABASE_URL\" \"JWT_SECRET\" \"SMTP_PASSWORD\")\nfor var in \"${required_vars[@]}\"; do\n    if [[ -z \"${!var}\" ]]; then\n        error \"Required environment variable $var is not set\"\n    fi\ndone\n\n# Check SSL certificates\nif [[ ! -f \"/etc/nginx/ssl/api.dealsphere.com.crt\" ]]; then\n    warn \"SSL certificate not found, generating self-signed certificate\"\n    # Generate self-signed certificate for testing\n    openssl req -x509 -nodes -days 365 -newkey rsa:2048 \\\n        -keyout /etc/nginx/ssl/api.dealsphere.com.key \\\n        -out /etc/nginx/ssl/api.dealsphere.com.crt \\\n        -subj \"/C=US/ST=State/L=City/O=DealSphere/CN=api.dealsphere.com\"\nfi\n\nlog \"Pre-deployment checks completed successfully\"\n\n# Database migration\nlog \"Running database migrations...\"\n./database/migrate.sh || error \"Database migration failed\"\n\n# Pull latest images\nlog \"Pulling latest Docker images...\"\ndocker-compose -f docker-compose.${ENVIRONMENT}.yml pull\n\n# Deploy with rolling update\nlog \"Starting deployment...\"\n\n# Backend deployment\nlog \"Deploying backend service...\"\ndocker-compose -f docker-compose.${ENVIRONMENT}.yml up -d --no-deps backend\n\n# Wait for backend health check\nlog \"Waiting for backend to be healthy...\"\nfor i in $(seq 1 $HEALTH_CHECK_RETRIES); do\n    if curl -f http://localhost:8080/actuator/health &gt;/dev/null 2&gt;&amp;1; then\n        log \"Backend is healthy\"\n        break\n    fi\n    if [[ $i -eq $HEALTH_CHECK_RETRIES ]]; then\n        error \"Backend health check failed after $HEALTH_CHECK_RETRIES attempts\"\n    fi\n    warn \"Backend not ready yet, attempt $i/$HEALTH_CHECK_RETRIES\"\n    sleep $HEALTH_CHECK_INTERVAL\ndone\n\n# Frontend deployment\nlog \"Deploying frontend service...\"\ndocker-compose -f docker-compose.${ENVIRONMENT}.yml up -d --no-deps frontend\n\n# Nginx deployment\nlog \"Deploying nginx service...\"\ndocker-compose -f docker-compose.${ENVIRONMENT}.yml up -d --no-deps nginx\n\n# Final health checks\nlog \"Running post-deployment health checks...\"\n\n# Test authentication endpoint\ntest_auth_endpoint() {\n    local response=$(curl -s -o /dev/null -w \"%{http_code}\" \\\n        -X POST \\\n        -H \"Content-Type: application/json\" \\\n        -d '{\"query\":\"query { __schema { types { name } } }\"}' \\\n        https://api.dealsphere.com/graphql)\n\n    if [[ \"$response\" == \"200\" ]]; then\n        log \"GraphQL endpoint is responding correctly\"\n        return 0\n    else\n        error \"GraphQL endpoint health check failed (HTTP $response)\"\n    fi\n}\n\ntest_auth_endpoint\n\n# Test frontend\ntest_frontend() {\n    local response=$(curl -s -o /dev/null -w \"%{http_code}\" https://app.dealsphere.com)\n    if [[ \"$response\" == \"200\" ]]; then\n        log \"Frontend is responding correctly\"\n        return 0\n    else\n        error \"Frontend health check failed (HTTP $response)\"\n    fi\n}\n\ntest_frontend\n\n# Cleanup old containers\nlog \"Cleaning up old containers...\"\ndocker system prune -f\n\nlog \"Deployment completed successfully!\"\nlog \"Services are available at:\"\nlog \"  - Frontend: https://app.dealsphere.com\"\nlog \"  - API: https://api.dealsphere.com\"\nlog \"  - GraphQL: https://api.dealsphere.com/graphql\"\n\n# Store deployment metadata\ncat &gt; deployment-info.json &lt;&lt; EOF\n{\n  \"deployment_time\": \"$(date -Iseconds)\",\n  \"environment\": \"$ENVIRONMENT\",\n  \"version\": \"$VERSION\",\n  \"services\": {\n    \"backend\": \"healthy\",\n    \"frontend\": \"healthy\",\n    \"nginx\": \"healthy\",\n    \"database\": \"healthy\"\n  }\n}\nEOF\n\nlog \"Deployment metadata saved to deployment-info.json\"\n</code></pre>"},{"location":"deployment/authentication-deployment/#rollback-script","title":"Rollback Script","text":"<p>File: <code>deploy/rollback.sh</code></p> <pre><code>#!/bin/bash\nset -e\n\n# Rollback script for DealSphere authentication system\n\nPREVIOUS_VERSION=${1}\nif [[ -z \"$PREVIOUS_VERSION\" ]]; then\n    echo \"Usage: $0 &lt;previous_version&gt;\"\n    echo \"Example: $0 v1.2.3\"\n    exit 1\nfi\n\nlog() {\n    echo \"[$(date +'%Y-%m-%d %H:%M:%S')] $1\"\n}\n\nerror() {\n    echo \"[$(date +'%Y-%m-%d %H:%M:%S')] ERROR: $1\"\n    exit 1\n}\n\nlog \"Starting rollback to version $PREVIOUS_VERSION\"\n\n# Stop current services\nlog \"Stopping current services...\"\ndocker-compose -f docker-compose.production.yml down\n\n# Deploy previous version\nlog \"Deploying previous version...\"\nVERSION=$PREVIOUS_VERSION docker-compose -f docker-compose.production.yml up -d\n\n# Wait for services to be healthy\nlog \"Waiting for services to be healthy...\"\nsleep 30\n\n# Health check\ncurl -f http://localhost:8080/actuator/health || error \"Rollback health check failed\"\n\nlog \"Rollback to version $PREVIOUS_VERSION completed successfully\"\n</code></pre>"},{"location":"deployment/authentication-deployment/#monitoring-observability","title":"Monitoring &amp; Observability","text":""},{"location":"deployment/authentication-deployment/#application-health-checks","title":"Application Health Checks","text":"<p>File: <code>monitoring/health-checks.yaml</code></p> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: health-checks\ndata:\n  health-check.sh: |\n    #!/bin/bash\n\n    # Authentication service health checks\n\n    # Check backend health\n    if ! curl -f http://backend:8080/actuator/health &gt;/dev/null 2&gt;&amp;1; then\n        echo \"CRITICAL: Backend service is down\"\n        exit 2\n    fi\n\n    # Check database connectivity\n    if ! PGPASSWORD=$DB_PASSWORD psql -h database -U dealsphere -d dealsphere_prod -c \"SELECT 1\" &gt;/dev/null 2&gt;&amp;1; then\n        echo \"CRITICAL: Database is unreachable\"\n        exit 2\n    fi\n\n    # Check authentication functionality\n    auth_response=$(curl -s -X POST \\\n        -H \"Content-Type: application/json\" \\\n        -d '{\"query\":\"query { __schema { types { name } } }\"}' \\\n        http://backend:8080/graphql)\n\n    if [[ $? -ne 0 ]]; then\n        echo \"WARNING: Authentication endpoint not responding\"\n        exit 1\n    fi\n\n    # Check email service connectivity\n    if ! nc -z $SMTP_HOST $SMTP_PORT; then\n        echo \"WARNING: SMTP service unreachable\"\n        exit 1\n    fi\n\n    echo \"OK: All authentication services are healthy\"\n    exit 0\n</code></pre>"},{"location":"deployment/authentication-deployment/#security-monitoring","title":"Security Monitoring","text":"<p>File: <code>monitoring/security-alerts.yaml</code></p> <pre><code>apiVersion: monitoring.coreos.com/v1\nkind: PrometheusRule\nmetadata:\n  name: dealsphere-security-alerts\nspec:\n  groups:\n  - name: dealsphere.security\n    rules:\n    - alert: HighFailedLoginRate\n      expr: rate(security_events_total{event_type=\"LOGIN_FAILURE\"}[5m]) &gt; 10\n      for: 5m\n      labels:\n        severity: warning\n        service: authentication\n      annotations:\n        summary: \"High failed login rate detected\"\n        description: \"{{ $value }} failed login attempts per second in the last 5 minutes\"\n\n    - alert: SQLInjectionAttempt\n      expr: increase(security_events_total{event_type=\"SQL_INJECTION_ATTEMPT\"}[1m]) &gt; 0\n      for: 0s\n      labels:\n        severity: critical\n        service: authentication\n      annotations:\n        summary: \"SQL injection attempt detected\"\n        description: \"SQL injection attempt from {{ $labels.ip_address }}\"\n\n    - alert: BruteForceAttack\n      expr: rate(security_events_total{event_type=\"BRUTE_FORCE_ATTEMPT\"}[1m]) &gt; 1\n      for: 2m\n      labels:\n        severity: critical\n        service: authentication\n      annotations:\n        summary: \"Brute force attack detected\"\n        description: \"Brute force attack from {{ $labels.ip_address }}\"\n\n    - alert: UnauthorizedAccess\n      expr: rate(security_events_total{event_type=\"ACCESS_DENIED\"}[5m]) &gt; 5\n      for: 5m\n      labels:\n        severity: warning\n        service: authentication\n      annotations:\n        summary: \"High unauthorized access attempts\"\n        description: \"{{ $value }} unauthorized access attempts per second\"\n</code></pre>"},{"location":"deployment/authentication-deployment/#backup-recovery","title":"Backup &amp; Recovery","text":""},{"location":"deployment/authentication-deployment/#database-backup-script","title":"Database Backup Script","text":"<p>File: <code>backup/db-backup.sh</code></p> <pre><code>#!/bin/bash\nset -e\n\n# Database backup script for production\n\nBACKUP_DIR=\"/backups/database\"\nDATE=$(date +%Y%m%d_%H%M%S)\nBACKUP_FILE=\"dealsphere_prod_$DATE.sql\"\nRETENTION_DAYS=30\n\n# Create backup directory\nmkdir -p $BACKUP_DIR\n\n# Create full database backup\nlog \"Creating database backup...\"\nPGPASSWORD=$DB_PASSWORD pg_dump \\\n    -h $DB_HOST \\\n    -p $DB_PORT \\\n    -U $DB_USER \\\n    -d $DB_NAME \\\n    --no-password \\\n    --verbose \\\n    --format=custom \\\n    --compress=9 \\\n    &gt; $BACKUP_DIR/$BACKUP_FILE\n\n# Verify backup\nif [[ -f \"$BACKUP_DIR/$BACKUP_FILE\" &amp;&amp; -s \"$BACKUP_DIR/$BACKUP_FILE\" ]]; then\n    log \"Database backup created successfully: $BACKUP_FILE\"\nelse\n    error \"Database backup failed\"\nfi\n\n# Upload to cloud storage (AWS S3 example)\nif [[ -n \"$AWS_S3_BUCKET\" ]]; then\n    aws s3 cp $BACKUP_DIR/$BACKUP_FILE s3://$AWS_S3_BUCKET/database-backups/\n    log \"Backup uploaded to S3\"\nfi\n\n# Cleanup old backups\nfind $BACKUP_DIR -name \"dealsphere_prod_*.sql\" -mtime +$RETENTION_DAYS -delete\nlog \"Old backups cleaned up (older than $RETENTION_DAYS days)\"\n</code></pre>"},{"location":"deployment/authentication-deployment/#disaster-recovery-plan","title":"Disaster Recovery Plan","text":"<p>File: <code>disaster-recovery/recovery-plan.md</code></p> <pre><code># Authentication System Disaster Recovery Plan\n\n## Recovery Time Objectives (RTO)\n- **Critical**: 15 minutes (authentication down)\n- **High**: 1 hour (degraded performance)\n- **Medium**: 4 hours (non-critical features)\n\n## Recovery Point Objectives (RPO)\n- **Database**: 15 minutes (continuous backup)\n- **Application**: 1 hour (latest deployment)\n- **Configuration**: 5 minutes (version controlled)\n\n## Recovery Procedures\n\n### Complete System Failure\n1. **Assess Impact**: Determine scope of failure\n2. **Activate DR Site**: Switch to backup infrastructure\n3. **Restore Database**: From latest backup\n4. **Deploy Services**: Using stored configuration\n5. **Verify Functionality**: Run health checks\n6. **Update DNS**: Point to DR infrastructure\n\n### Database Failure\n1. **Stop Application**: Prevent data corruption\n2. **Restore from Backup**: Latest full backup\n3. **Apply Transaction Logs**: If available\n4. **Restart Services**: In correct order\n5. **Verify Data Integrity**: Run consistency checks\n\n### Security Incident\n1. **Isolate Systems**: Prevent further damage\n2. **Assess Damage**: Determine what was compromised\n3. **Reset Credentials**: All JWT secrets, passwords\n4. **Audit Logs**: Review security events\n5. **Restore Clean State**: From known good backup\n6. **Implement Fixes**: Address vulnerabilities\n</code></pre>"},{"location":"deployment/authentication-deployment/#operation-procedures","title":"Operation Procedures","text":""},{"location":"deployment/authentication-deployment/#daily-operations-checklist","title":"Daily Operations Checklist","text":"<pre><code>#!/bin/bash\n# Daily operations checklist for authentication system\n\necho \"DealSphere Authentication System - Daily Operations Checklist\"\necho \"Date: $(date)\"\necho\n\n# Check service health\necho \"1. Service Health Check\"\ncurl -f https://api.dealsphere.com/health &amp;&amp; echo \"\u2713 API Health OK\" || echo \"\u2717 API Health FAILED\"\ncurl -f https://app.dealsphere.com &amp;&amp; echo \"\u2713 Frontend OK\" || echo \"\u2717 Frontend FAILED\"\n\n# Check database\necho \"2. Database Health\"\nPGPASSWORD=$DB_PASSWORD psql -h $DB_HOST -U $DB_USER -d $DB_NAME -c \"SELECT COUNT(*) FROM user_profiles;\" &amp;&amp; echo \"\u2713 Database OK\" || echo \"\u2717 Database FAILED\"\n\n# Check disk space\necho \"3. Disk Space Check\"\ndf -h | grep -E \"(8[0-9]|9[0-9])%\" &amp;&amp; echo \"\u26a0 High disk usage detected\" || echo \"\u2713 Disk space OK\"\n\n# Check logs for errors\necho \"4. Error Log Check\"\nerror_count=$(docker logs dealsphere-backend 2&gt;&amp;1 | grep -c ERROR || true)\nif [[ $error_count -gt 10 ]]; then\n    echo \"\u26a0 High error count: $error_count errors in backend logs\"\nelse\n    echo \"\u2713 Error logs within normal range ($error_count errors)\"\nfi\n\n# Check SSL certificates\necho \"5. SSL Certificate Check\"\nexpiry=$(openssl x509 -in /etc/nginx/ssl/api.dealsphere.com.crt -noout -enddate | cut -d= -f2)\nexpiry_epoch=$(date -d \"$expiry\" +%s)\ncurrent_epoch=$(date +%s)\ndays_until_expiry=$(( ($expiry_epoch - $current_epoch) / 86400 ))\n\nif [[ $days_until_expiry -lt 30 ]]; then\n    echo \"\u26a0 SSL certificate expires in $days_until_expiry days\"\nelse\n    echo \"\u2713 SSL certificate valid for $days_until_expiry days\"\nfi\n\n# Check backup status\necho \"6. Backup Status Check\"\nlatest_backup=$(ls -t /backups/database/dealsphere_prod_*.sql | head -1)\nif [[ -f \"$latest_backup\" ]]; then\n    backup_age=$(( ($(date +%s) - $(stat -c %Y \"$latest_backup\")) / 3600 ))\n    if [[ $backup_age -lt 24 ]]; then\n        echo \"\u2713 Latest backup is $backup_age hours old\"\n    else\n        echo \"\u26a0 Latest backup is $backup_age hours old (&gt;24h)\"\n    fi\nelse\n    echo \"\u2717 No backup found\"\nfi\n\necho\necho \"Daily operations checklist completed\"\n</code></pre> <p>This comprehensive deployment guide ensures secure, reliable, and scalable deployment of the DealSphere authentication system in production environments.</p>"},{"location":"deployment/cloud-infrastructure/","title":"Cloud Infrastructure Setup Guide","text":"<p>This guide provides comprehensive instructions for setting up cloud infrastructure for the DealSphere platform across major cloud providers.</p>"},{"location":"deployment/cloud-infrastructure/#overview","title":"Overview","text":"<p>The DealSphere platform can be deployed on multiple cloud providers with Infrastructure as Code (IaC) for consistent, reproducible deployments.</p> <p>Supported Cloud Providers: - Amazon Web Services (AWS) - Google Cloud Platform (GCP) - Microsoft Azure - Digital Ocean (simplified setup)</p>"},{"location":"deployment/cloud-infrastructure/#architecture-overview","title":"Architecture Overview","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Load Balancer \u2502\u2500\u2500\u2500\u2500\u2502  Frontend (CDN) \u2502\u2500\u2500\u2500\u2500\u2502   Static Assets \u2502\n\u2502   (ALB/CLB)     \u2502    \u2502    (Nginx)      \u2502    \u2502      (S3)       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502                       \u2502\n         \u2502              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u2502              \u2502   Backend API   \u2502\n         \u2502              \u2502 (ECS/GKE/AKS)   \u2502\n         \u2502              \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502                       \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Monitoring    \u2502    \u2502    Database     \u2502    \u2502 Secrets Manager \u2502\n\u2502 (Prometheus/    \u2502    \u2502 (RDS/CloudSQL/  \u2502    \u2502  (Vault/KMS/    \u2502\n\u2502  Grafana)       \u2502    \u2502  Azure DB)      \u2502    \u2502   Key Vault)    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"deployment/cloud-infrastructure/#amazon-web-services-aws","title":"Amazon Web Services (AWS)","text":""},{"location":"deployment/cloud-infrastructure/#prerequisites","title":"Prerequisites","text":"<p>Required AWS CLI and Tools:</p> <pre><code># Install AWS CLI\ncurl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\"\nunzip awscliv2.zip\nsudo ./aws/install\n\n# Install Terraform\nwget https://releases.hashicorp.com/terraform/1.6.0/terraform_1.6.0_linux_amd64.zip\nunzip terraform_1.6.0_linux_amd64.zip\nsudo mv terraform /usr/local/bin/\n\n# Configure AWS credentials\naws configure\n</code></pre>"},{"location":"deployment/cloud-infrastructure/#terraform-infrastructure","title":"Terraform Infrastructure","text":""},{"location":"deployment/cloud-infrastructure/#main-infrastructure-maintf","title":"Main Infrastructure (main.tf)","text":"<pre><code>terraform {\n  required_version = \"&gt;= 1.0\"\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~&gt; 5.0\"\n    }\n  }\n\n  backend \"s3\" {\n    bucket = \"dealsphere-terraform-state\"\n    key    = \"production/terraform.tfstate\"\n    region = \"us-west-2\"\n  }\n}\n\nprovider \"aws\" {\n  region = var.aws_region\n\n  default_tags {\n    tags = {\n      Project     = \"DealSphere\"\n      Environment = var.environment\n      ManagedBy   = \"Terraform\"\n    }\n  }\n}\n\n# Variables\nvariable \"aws_region\" {\n  description = \"AWS region\"\n  type        = string\n  default     = \"us-west-2\"\n}\n\nvariable \"environment\" {\n  description = \"Environment (staging/production)\"\n  type        = string\n  default     = \"production\"\n}\n\nvariable \"domain_name\" {\n  description = \"Domain name for the application\"\n  type        = string\n}\n\n# Data sources\ndata \"aws_availability_zones\" \"available\" {\n  state = \"available\"\n}\n\n# VPC and Networking\nresource \"aws_vpc\" \"main\" {\n  cidr_block           = \"10.0.0.0/16\"\n  enable_dns_hostnames = true\n  enable_dns_support   = true\n\n  tags = {\n    Name = \"dealsphere-${var.environment}-vpc\"\n  }\n}\n\nresource \"aws_internet_gateway\" \"main\" {\n  vpc_id = aws_vpc.main.id\n\n  tags = {\n    Name = \"dealsphere-${var.environment}-igw\"\n  }\n}\n\nresource \"aws_subnet\" \"public\" {\n  count = 2\n\n  vpc_id                  = aws_vpc.main.id\n  cidr_block              = \"10.0.${count.index + 1}.0/24\"\n  availability_zone       = data.aws_availability_zones.available.names[count.index]\n  map_public_ip_on_launch = true\n\n  tags = {\n    Name = \"dealsphere-${var.environment}-public-${count.index + 1}\"\n    Type = \"Public\"\n  }\n}\n\nresource \"aws_subnet\" \"private\" {\n  count = 2\n\n  vpc_id            = aws_vpc.main.id\n  cidr_block        = \"10.0.${count.index + 10}.0/24\"\n  availability_zone = data.aws_availability_zones.available.names[count.index]\n\n  tags = {\n    Name = \"dealsphere-${var.environment}-private-${count.index + 1}\"\n    Type = \"Private\"\n  }\n}\n\nresource \"aws_route_table\" \"public\" {\n  vpc_id = aws_vpc.main.id\n\n  route {\n    cidr_block = \"0.0.0.0/0\"\n    gateway_id = aws_internet_gateway.main.id\n  }\n\n  tags = {\n    Name = \"dealsphere-${var.environment}-public-rt\"\n  }\n}\n\nresource \"aws_route_table_association\" \"public\" {\n  count = length(aws_subnet.public)\n\n  subnet_id      = aws_subnet.public[count.index].id\n  route_table_id = aws_route_table.public.id\n}\n\n# NAT Gateway for private subnets\nresource \"aws_eip\" \"nat\" {\n  domain = \"vpc\"\n\n  tags = {\n    Name = \"dealsphere-${var.environment}-nat-eip\"\n  }\n}\n\nresource \"aws_nat_gateway\" \"main\" {\n  allocation_id = aws_eip.nat.id\n  subnet_id     = aws_subnet.public[0].id\n\n  tags = {\n    Name = \"dealsphere-${var.environment}-nat-gw\"\n  }\n}\n\nresource \"aws_route_table\" \"private\" {\n  vpc_id = aws_vpc.main.id\n\n  route {\n    cidr_block     = \"0.0.0.0/0\"\n    nat_gateway_id = aws_nat_gateway.main.id\n  }\n\n  tags = {\n    Name = \"dealsphere-${var.environment}-private-rt\"\n  }\n}\n\nresource \"aws_route_table_association\" \"private\" {\n  count = length(aws_subnet.private)\n\n  subnet_id      = aws_subnet.private[count.index].id\n  route_table_id = aws_route_table.private.id\n}\n</code></pre>"},{"location":"deployment/cloud-infrastructure/#database-rdstf","title":"Database (rds.tf)","text":"<pre><code># RDS Subnet Group\nresource \"aws_db_subnet_group\" \"main\" {\n  name       = \"dealsphere-${var.environment}-db-subnet-group\"\n  subnet_ids = aws_subnet.private[*].id\n\n  tags = {\n    Name = \"dealsphere-${var.environment}-db-subnet-group\"\n  }\n}\n\n# Database Security Group\nresource \"aws_security_group\" \"database\" {\n  name_prefix = \"dealsphere-${var.environment}-db-\"\n  vpc_id      = aws_vpc.main.id\n\n  ingress {\n    description     = \"PostgreSQL from application\"\n    from_port       = 5432\n    to_port         = 5432\n    protocol        = \"tcp\"\n    security_groups = [aws_security_group.backend.id]\n  }\n\n  egress {\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  tags = {\n    Name = \"dealsphere-${var.environment}-db-sg\"\n  }\n}\n\n# RDS Instance\nresource \"aws_db_instance\" \"main\" {\n  identifier = \"dealsphere-${var.environment}-db\"\n\n  engine         = \"postgres\"\n  engine_version = \"16.1\"\n  instance_class = var.environment == \"production\" ? \"db.t3.medium\" : \"db.t3.micro\"\n\n  allocated_storage     = var.environment == \"production\" ? 100 : 20\n  max_allocated_storage = var.environment == \"production\" ? 1000 : 100\n  storage_type          = \"gp3\"\n  storage_encrypted     = true\n\n  db_name  = \"dealsphere\"\n  username = \"dealsphere\"\n  password = random_password.db_password.result\n\n  vpc_security_group_ids = [aws_security_group.database.id]\n  db_subnet_group_name   = aws_db_subnet_group.main.name\n\n  backup_retention_period = var.environment == \"production\" ? 30 : 7\n  backup_window          = \"03:00-04:00\"\n  maintenance_window     = \"sun:04:00-sun:05:00\"\n\n  skip_final_snapshot = var.environment != \"production\"\n  deletion_protection = var.environment == \"production\"\n\n  performance_insights_enabled = true\n  monitoring_interval         = 60\n  monitoring_role_arn        = aws_iam_role.rds_monitoring.arn\n\n  tags = {\n    Name = \"dealsphere-${var.environment}-db\"\n  }\n}\n\n# Random password for database\nresource \"random_password\" \"db_password\" {\n  length  = 32\n  special = true\n}\n\n# Store database password in Secrets Manager\nresource \"aws_secretsmanager_secret\" \"db_password\" {\n  name = \"dealsphere/${var.environment}/db-password\"\n}\n\nresource \"aws_secretsmanager_secret_version\" \"db_password\" {\n  secret_id     = aws_secretsmanager_secret.db_password.id\n  secret_string = random_password.db_password.result\n}\n\n# RDS Monitoring Role\nresource \"aws_iam_role\" \"rds_monitoring\" {\n  name = \"dealsphere-${var.environment}-rds-monitoring-role\"\n\n  assume_role_policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Action = \"sts:AssumeRole\"\n        Effect = \"Allow\"\n        Principal = {\n          Service = \"monitoring.rds.amazonaws.com\"\n        }\n      }\n    ]\n  })\n}\n\nresource \"aws_iam_role_policy_attachment\" \"rds_monitoring\" {\n  role       = aws_iam_role.rds_monitoring.name\n  policy_arn = \"arn:aws:iam::aws:policy/service-role/AmazonRDSEnhancedMonitoringRole\"\n}\n</code></pre>"},{"location":"deployment/cloud-infrastructure/#ecs-cluster-ecstf","title":"ECS Cluster (ecs.tf)","text":"<pre><code># ECS Cluster\nresource \"aws_ecs_cluster\" \"main\" {\n  name = \"dealsphere-${var.environment}\"\n\n  configuration {\n    execute_command_configuration {\n      logging = \"OVERRIDE\"\n      log_configuration {\n        cloud_watch_log_group_name = aws_cloudwatch_log_group.ecs.name\n      }\n    }\n  }\n\n  tags = {\n    Name = \"dealsphere-${var.environment}-cluster\"\n  }\n}\n\n# CloudWatch Log Group\nresource \"aws_cloudwatch_log_group\" \"ecs\" {\n  name              = \"/ecs/dealsphere-${var.environment}\"\n  retention_in_days = var.environment == \"production\" ? 30 : 7\n\n  tags = {\n    Name = \"dealsphere-${var.environment}-logs\"\n  }\n}\n\n# Backend Security Group\nresource \"aws_security_group\" \"backend\" {\n  name_prefix = \"dealsphere-${var.environment}-backend-\"\n  vpc_id      = aws_vpc.main.id\n\n  ingress {\n    description     = \"HTTP from ALB\"\n    from_port       = 8080\n    to_port         = 8080\n    protocol        = \"tcp\"\n    security_groups = [aws_security_group.alb.id]\n  }\n\n  egress {\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  tags = {\n    Name = \"dealsphere-${var.environment}-backend-sg\"\n  }\n}\n\n# ECS Task Definition\nresource \"aws_ecs_task_definition\" \"backend\" {\n  family                   = \"dealsphere-${var.environment}-backend\"\n  network_mode             = \"awsvpc\"\n  requires_compatibilities = [\"FARGATE\"]\n  cpu                      = var.environment == \"production\" ? 2048 : 1024\n  memory                   = var.environment == \"production\" ? 4096 : 2048\n  execution_role_arn       = aws_iam_role.ecs_execution.arn\n  task_role_arn           = aws_iam_role.ecs_task.arn\n\n  container_definitions = jsonencode([\n    {\n      name  = \"backend\"\n      image = \"your-account.dkr.ecr.${var.aws_region}.amazonaws.com/dealsphere-backend:latest\"\n\n      portMappings = [\n        {\n          containerPort = 8080\n          protocol      = \"tcp\"\n        }\n      ]\n\n      environment = [\n        {\n          name  = \"SPRING_PROFILES_ACTIVE\"\n          value = \"production\"\n        },\n        {\n          name  = \"POSTGRES_HOST\"\n          value = aws_db_instance.main.address\n        },\n        {\n          name  = \"POSTGRES_DB\"\n          value = aws_db_instance.main.db_name\n        },\n        {\n          name  = \"POSTGRES_USER\"\n          value = aws_db_instance.main.username\n        }\n      ]\n\n      secrets = [\n        {\n          name      = \"POSTGRES_PASSWORD\"\n          valueFrom = aws_secretsmanager_secret.db_password.arn\n        }\n      ]\n\n      logConfiguration = {\n        logDriver = \"awslogs\"\n        options = {\n          awslogs-group         = aws_cloudwatch_log_group.ecs.name\n          awslogs-region        = var.aws_region\n          awslogs-stream-prefix = \"backend\"\n        }\n      }\n\n      healthCheck = {\n        command = [\"CMD-SHELL\", \"curl -f http://localhost:8080/actuator/health || exit 1\"]\n        interval = 30\n        timeout = 5\n        retries = 3\n      }\n\n      essential = true\n    }\n  ])\n\n  tags = {\n    Name = \"dealsphere-${var.environment}-backend-task\"\n  }\n}\n\n# ECS Service\nresource \"aws_ecs_service\" \"backend\" {\n  name            = \"dealsphere-${var.environment}-backend\"\n  cluster         = aws_ecs_cluster.main.id\n  task_definition = aws_ecs_task_definition.backend.arn\n  desired_count   = var.environment == \"production\" ? 2 : 1\n  launch_type     = \"FARGATE\"\n\n  network_configuration {\n    subnets         = aws_subnet.private[*].id\n    security_groups = [aws_security_group.backend.id]\n  }\n\n  load_balancer {\n    target_group_arn = aws_lb_target_group.backend.arn\n    container_name   = \"backend\"\n    container_port   = 8080\n  }\n\n  depends_on = [aws_lb_listener.backend]\n\n  tags = {\n    Name = \"dealsphere-${var.environment}-backend-service\"\n  }\n}\n\n# IAM Roles for ECS\nresource \"aws_iam_role\" \"ecs_execution\" {\n  name = \"dealsphere-${var.environment}-ecs-execution-role\"\n\n  assume_role_policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Action = \"sts:AssumeRole\"\n        Effect = \"Allow\"\n        Principal = {\n          Service = \"ecs-tasks.amazonaws.com\"\n        }\n      }\n    ]\n  })\n}\n\nresource \"aws_iam_role_policy_attachment\" \"ecs_execution\" {\n  role       = aws_iam_role.ecs_execution.name\n  policy_arn = \"arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy\"\n}\n\nresource \"aws_iam_role_policy\" \"ecs_secrets\" {\n  name = \"ecs-secrets-policy\"\n  role = aws_iam_role.ecs_execution.id\n\n  policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Effect = \"Allow\"\n        Action = [\n          \"secretsmanager:GetSecretValue\"\n        ]\n        Resource = [\n          aws_secretsmanager_secret.db_password.arn\n        ]\n      }\n    ]\n  })\n}\n\nresource \"aws_iam_role\" \"ecs_task\" {\n  name = \"dealsphere-${var.environment}-ecs-task-role\"\n\n  assume_role_policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Action = \"sts:AssumeRole\"\n        Effect = \"Allow\"\n        Principal = {\n          Service = \"ecs-tasks.amazonaws.com\"\n        }\n      }\n    ]\n  })\n}\n</code></pre>"},{"location":"deployment/cloud-infrastructure/#load-balancer-albtf","title":"Load Balancer (alb.tf)","text":"<pre><code># Application Load Balancer\nresource \"aws_lb\" \"main\" {\n  name               = \"dealsphere-${var.environment}-alb\"\n  internal           = false\n  load_balancer_type = \"application\"\n  security_groups    = [aws_security_group.alb.id]\n  subnets           = aws_subnet.public[*].id\n\n  enable_deletion_protection = var.environment == \"production\"\n\n  tags = {\n    Name = \"dealsphere-${var.environment}-alb\"\n  }\n}\n\n# ALB Security Group\nresource \"aws_security_group\" \"alb\" {\n  name_prefix = \"dealsphere-${var.environment}-alb-\"\n  vpc_id      = aws_vpc.main.id\n\n  ingress {\n    description = \"HTTP\"\n    from_port   = 80\n    to_port     = 80\n    protocol    = \"tcp\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  ingress {\n    description = \"HTTPS\"\n    from_port   = 443\n    to_port     = 443\n    protocol    = \"tcp\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  egress {\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  tags = {\n    Name = \"dealsphere-${var.environment}-alb-sg\"\n  }\n}\n\n# Target Groups\nresource \"aws_lb_target_group\" \"backend\" {\n  name     = \"dealsphere-${var.environment}-backend-tg\"\n  port     = 8080\n  protocol = \"HTTP\"\n  vpc_id   = aws_vpc.main.id\n  target_type = \"ip\"\n\n  health_check {\n    enabled             = true\n    healthy_threshold   = 2\n    interval            = 30\n    matcher             = \"200\"\n    path                = \"/actuator/health\"\n    port                = \"traffic-port\"\n    protocol            = \"HTTP\"\n    timeout             = 5\n    unhealthy_threshold = 3\n  }\n\n  tags = {\n    Name = \"dealsphere-${var.environment}-backend-tg\"\n  }\n}\n\n# SSL Certificate\ndata \"aws_acm_certificate\" \"main\" {\n  domain   = var.domain_name\n  statuses = [\"ISSUED\"]\n}\n\n# ALB Listeners\nresource \"aws_lb_listener\" \"redirect_http\" {\n  load_balancer_arn = aws_lb.main.arn\n  port              = \"80\"\n  protocol          = \"HTTP\"\n\n  default_action {\n    type = \"redirect\"\n\n    redirect {\n      port        = \"443\"\n      protocol    = \"HTTPS\"\n      status_code = \"HTTP_301\"\n    }\n  }\n}\n\nresource \"aws_lb_listener\" \"backend\" {\n  load_balancer_arn = aws_lb.main.arn\n  port              = \"443\"\n  protocol          = \"HTTPS\"\n  ssl_policy        = \"ELBSecurityPolicy-TLS-1-2-2017-01\"\n  certificate_arn   = data.aws_acm_certificate.main.arn\n\n  default_action {\n    type             = \"forward\"\n    target_group_arn = aws_lb_target_group.backend.arn\n  }\n}\n</code></pre>"},{"location":"deployment/cloud-infrastructure/#s3-and-cloudfront-s3tf","title":"S3 and CloudFront (s3.tf)","text":"<pre><code># S3 Bucket for Frontend\nresource \"aws_s3_bucket\" \"frontend\" {\n  bucket = \"dealsphere-${var.environment}-frontend-${random_id.bucket_suffix.hex}\"\n\n  tags = {\n    Name = \"dealsphere-${var.environment}-frontend\"\n  }\n}\n\nresource \"random_id\" \"bucket_suffix\" {\n  byte_length = 4\n}\n\nresource \"aws_s3_bucket_public_access_block\" \"frontend\" {\n  bucket = aws_s3_bucket.frontend.id\n\n  block_public_acls       = true\n  block_public_policy     = true\n  ignore_public_acls      = true\n  restrict_public_buckets = true\n}\n\nresource \"aws_s3_bucket_versioning\" \"frontend\" {\n  bucket = aws_s3_bucket.frontend.id\n  versioning_configuration {\n    status = \"Enabled\"\n  }\n}\n\n# CloudFront Distribution\nresource \"aws_cloudfront_origin_access_control\" \"main\" {\n  name                              = \"dealsphere-${var.environment}-oac\"\n  origin_access_control_origin_type = \"s3\"\n  signing_behavior                  = \"always\"\n  signing_protocol                  = \"sigv4\"\n}\n\nresource \"aws_cloudfront_distribution\" \"main\" {\n  origin {\n    domain_name              = aws_s3_bucket.frontend.bucket_regional_domain_name\n    origin_id                = \"S3-${aws_s3_bucket.frontend.bucket}\"\n    origin_access_control_id = aws_cloudfront_origin_access_control.main.id\n  }\n\n  origin {\n    domain_name = aws_lb.main.dns_name\n    origin_id   = \"ALB-backend\"\n\n    custom_origin_config {\n      http_port              = 80\n      https_port             = 443\n      origin_protocol_policy = \"https-only\"\n      origin_ssl_protocols   = [\"TLSv1.2\"]\n    }\n  }\n\n  enabled             = true\n  is_ipv6_enabled     = true\n  default_root_object = \"index.html\"\n  aliases             = [var.domain_name]\n\n  default_cache_behavior {\n    allowed_methods  = [\"DELETE\", \"GET\", \"HEAD\", \"OPTIONS\", \"PATCH\", \"POST\", \"PUT\"]\n    cached_methods   = [\"GET\", \"HEAD\"]\n    target_origin_id = \"S3-${aws_s3_bucket.frontend.bucket}\"\n\n    forwarded_values {\n      query_string = false\n      cookies {\n        forward = \"none\"\n      }\n    }\n\n    viewer_protocol_policy = \"redirect-to-https\"\n    min_ttl                = 0\n    default_ttl            = 3600\n    max_ttl                = 86400\n  }\n\n  ordered_cache_behavior {\n    path_pattern     = \"/api/*\"\n    allowed_methods  = [\"DELETE\", \"GET\", \"HEAD\", \"OPTIONS\", \"PATCH\", \"POST\", \"PUT\"]\n    cached_methods   = [\"GET\", \"HEAD\"]\n    target_origin_id = \"ALB-backend\"\n\n    forwarded_values {\n      query_string = true\n      headers      = [\"*\"]\n      cookies {\n        forward = \"all\"\n      }\n    }\n\n    viewer_protocol_policy = \"https-only\"\n    min_ttl                = 0\n    default_ttl            = 0\n    max_ttl                = 0\n  }\n\n  restrictions {\n    geo_restriction {\n      restriction_type = \"none\"\n    }\n  }\n\n  viewer_certificate {\n    acm_certificate_arn = data.aws_acm_certificate.main.arn\n    ssl_support_method  = \"sni-only\"\n  }\n\n  tags = {\n    Name = \"dealsphere-${var.environment}-cloudfront\"\n  }\n}\n\n# S3 bucket policy for CloudFront\nresource \"aws_s3_bucket_policy\" \"frontend\" {\n  bucket = aws_s3_bucket.frontend.id\n\n  policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Effect = \"Allow\"\n        Principal = {\n          Service = \"cloudfront.amazonaws.com\"\n        }\n        Action   = \"s3:GetObject\"\n        Resource = \"${aws_s3_bucket.frontend.arn}/*\"\n        Condition = {\n          StringEquals = {\n            \"AWS:SourceArn\" = aws_cloudfront_distribution.main.arn\n          }\n        }\n      }\n    ]\n  })\n}\n</code></pre>"},{"location":"deployment/cloud-infrastructure/#deployment-commands","title":"Deployment Commands","text":"<pre><code># Initialize Terraform\nterraform init\n\n# Plan deployment\nterraform plan -var=\"domain_name=yourdomain.com\"\n\n# Apply infrastructure\nterraform apply -var=\"domain_name=yourdomain.com\"\n\n# Get outputs\nterraform output\n</code></pre>"},{"location":"deployment/cloud-infrastructure/#google-cloud-platform-gcp","title":"Google Cloud Platform (GCP)","text":""},{"location":"deployment/cloud-infrastructure/#prerequisites_1","title":"Prerequisites","text":"<pre><code># Install Google Cloud SDK\ncurl https://sdk.cloud.google.com | bash\nexec -l $SHELL\n\n# Install Terraform\n# (Same as AWS section above)\n\n# Initialize and authenticate\ngcloud init\ngcloud auth application-default login\n</code></pre>"},{"location":"deployment/cloud-infrastructure/#terraform-configuration","title":"Terraform Configuration","text":""},{"location":"deployment/cloud-infrastructure/#main-infrastructure-maintf_1","title":"Main Infrastructure (main.tf)","text":"<pre><code>terraform {\n  required_version = \"&gt;= 1.0\"\n  required_providers {\n    google = {\n      source  = \"hashicorp/google\"\n      version = \"~&gt; 5.0\"\n    }\n  }\n\n  backend \"gcs\" {\n    bucket = \"dealsphere-terraform-state\"\n    prefix = \"production\"\n  }\n}\n\nprovider \"google\" {\n  project = var.project_id\n  region  = var.region\n  zone    = var.zone\n}\n\nvariable \"project_id\" {\n  description = \"GCP Project ID\"\n  type        = string\n}\n\nvariable \"region\" {\n  description = \"GCP region\"\n  type        = string\n  default     = \"us-central1\"\n}\n\nvariable \"zone\" {\n  description = \"GCP zone\"\n  type        = string\n  default     = \"us-central1-a\"\n}\n\nvariable \"environment\" {\n  description = \"Environment (staging/production)\"\n  type        = string\n  default     = \"production\"\n}\n\n# VPC Network\nresource \"google_compute_network\" \"vpc\" {\n  name                    = \"dealsphere-${var.environment}-vpc\"\n  auto_create_subnetworks = false\n}\n\nresource \"google_compute_subnetwork\" \"public\" {\n  name          = \"dealsphere-${var.environment}-public\"\n  ip_cidr_range = \"10.0.1.0/24\"\n  region        = var.region\n  network       = google_compute_network.vpc.id\n}\n\nresource \"google_compute_subnetwork\" \"private\" {\n  name          = \"dealsphere-${var.environment}-private\"\n  ip_cidr_range = \"10.0.2.0/24\"\n  region        = var.region\n  network       = google_compute_network.vpc.id\n\n  private_ip_google_access = true\n}\n\n# Firewall Rules\nresource \"google_compute_firewall\" \"allow_http_https\" {\n  name    = \"dealsphere-${var.environment}-allow-http-https\"\n  network = google_compute_network.vpc.name\n\n  allow {\n    protocol = \"tcp\"\n    ports    = [\"80\", \"443\"]\n  }\n\n  source_ranges = [\"0.0.0.0/0\"]\n  target_tags   = [\"web-server\"]\n}\n\nresource \"google_compute_firewall\" \"allow_internal\" {\n  name    = \"dealsphere-${var.environment}-allow-internal\"\n  network = google_compute_network.vpc.name\n\n  allow {\n    protocol = \"tcp\"\n    ports    = [\"0-65535\"]\n  }\n\n  allow {\n    protocol = \"udp\"\n    ports    = [\"0-65535\"]\n  }\n\n  source_ranges = [\"10.0.0.0/8\"]\n}\n</code></pre>"},{"location":"deployment/cloud-infrastructure/#gke-cluster-gketf","title":"GKE Cluster (gke.tf)","text":"<pre><code># GKE Cluster\nresource \"google_container_cluster\" \"primary\" {\n  name     = \"dealsphere-${var.environment}-gke\"\n  location = var.region\n\n  remove_default_node_pool = true\n  initial_node_count       = 1\n\n  network    = google_compute_network.vpc.name\n  subnetwork = google_compute_subnetwork.private.name\n\n  ip_allocation_policy {\n    cluster_ipv4_cidr_block  = \"10.1.0.0/16\"\n    services_ipv4_cidr_block = \"10.2.0.0/16\"\n  }\n\n  private_cluster_config {\n    enable_private_nodes    = true\n    enable_private_endpoint = false\n    master_ipv4_cidr_block  = \"172.16.0.0/28\"\n  }\n\n  workload_identity_config {\n    workload_pool = \"${var.project_id}.svc.id.goog\"\n  }\n\n  addons_config {\n    http_load_balancing {\n      disabled = false\n    }\n    horizontal_pod_autoscaling {\n      disabled = false\n    }\n  }\n\n  deletion_protection = var.environment == \"production\"\n}\n\n# Node Pool\nresource \"google_container_node_pool\" \"primary_nodes\" {\n  name       = \"dealsphere-${var.environment}-nodes\"\n  location   = var.region\n  cluster    = google_container_cluster.primary.name\n  node_count = var.environment == \"production\" ? 2 : 1\n\n  node_config {\n    preemptible  = var.environment != \"production\"\n    machine_type = var.environment == \"production\" ? \"e2-standard-4\" : \"e2-standard-2\"\n\n    service_account = google_service_account.gke_nodes.email\n    oauth_scopes = [\n      \"https://www.googleapis.com/auth/cloud-platform\"\n    ]\n\n    labels = {\n      environment = var.environment\n    }\n\n    tags = [\"gke-node\", \"dealsphere-${var.environment}\"]\n  }\n\n  autoscaling {\n    min_node_count = 1\n    max_node_count = var.environment == \"production\" ? 10 : 3\n  }\n\n  management {\n    auto_repair  = true\n    auto_upgrade = true\n  }\n}\n\n# Service Account for GKE Nodes\nresource \"google_service_account\" \"gke_nodes\" {\n  account_id   = \"dealsphere-${var.environment}-gke-nodes\"\n  display_name = \"GKE Nodes Service Account\"\n}\n\nresource \"google_project_iam_member\" \"gke_nodes\" {\n  for_each = toset([\n    \"roles/logging.logWriter\",\n    \"roles/monitoring.metricWriter\",\n    \"roles/monitoring.viewer\",\n    \"roles/stackdriver.resourceMetadata.writer\",\n    \"roles/storage.objectViewer\"\n  ])\n\n  project = var.project_id\n  role    = each.key\n  member  = \"serviceAccount:${google_service_account.gke_nodes.email}\"\n}\n</code></pre>"},{"location":"deployment/cloud-infrastructure/#cloud-sql-cloudsqltf","title":"Cloud SQL (cloudsql.tf)","text":"<pre><code># Random password for database\nresource \"random_password\" \"db_password\" {\n  length  = 32\n  special = true\n}\n\n# Cloud SQL Instance\nresource \"google_sql_database_instance\" \"main\" {\n  name             = \"dealsphere-${var.environment}-db\"\n  database_version = \"POSTGRES_16\"\n  region           = var.region\n\n  settings {\n    tier              = var.environment == \"production\" ? \"db-standard-2\" : \"db-f1-micro\"\n    availability_type = var.environment == \"production\" ? \"REGIONAL\" : \"ZONAL\"\n    disk_type         = \"PD_SSD\"\n    disk_size         = var.environment == \"production\" ? 100 : 20\n    disk_autoresize   = true\n\n    backup_configuration {\n      enabled                        = true\n      start_time                     = \"03:00\"\n      point_in_time_recovery_enabled = var.environment == \"production\"\n      backup_retention_settings {\n        retained_backups = var.environment == \"production\" ? 30 : 7\n      }\n    }\n\n    ip_configuration {\n      ipv4_enabled    = false\n      private_network = google_compute_network.vpc.id\n      require_ssl     = true\n    }\n\n    maintenance_window {\n      day  = 7\n      hour = 3\n    }\n\n    insights_config {\n      query_insights_enabled  = true\n      query_string_length     = 1024\n      record_application_tags = false\n      record_client_address   = false\n    }\n  }\n\n  deletion_protection = var.environment == \"production\"\n}\n\n# Database\nresource \"google_sql_database\" \"database\" {\n  name     = \"dealsphere\"\n  instance = google_sql_database_instance.main.name\n}\n\n# Database User\nresource \"google_sql_user\" \"user\" {\n  name     = \"dealsphere\"\n  instance = google_sql_database_instance.main.name\n  password = random_password.db_password.result\n}\n\n# Private Service Access\nresource \"google_compute_global_address\" \"private_ip_address\" {\n  name          = \"dealsphere-${var.environment}-private-ip\"\n  purpose       = \"VPC_PEERING\"\n  address_type  = \"INTERNAL\"\n  prefix_length = 16\n  network       = google_compute_network.vpc.id\n}\n\nresource \"google_service_networking_connection\" \"private_vpc_connection\" {\n  network                 = google_compute_network.vpc.id\n  service                 = \"servicenetworking.googleapis.com\"\n  reserved_peering_ranges = [google_compute_global_address.private_ip_address.name]\n}\n\n# Secret Manager for database credentials\nresource \"google_secret_manager_secret\" \"db_password\" {\n  secret_id = \"dealsphere-${var.environment}-db-password\"\n\n  replication {\n    automatic = true\n  }\n}\n\nresource \"google_secret_manager_secret_version\" \"db_password\" {\n  secret      = google_secret_manager_secret.db_password.id\n  secret_data = random_password.db_password.result\n}\n</code></pre>"},{"location":"deployment/cloud-infrastructure/#deployment-commands_1","title":"Deployment Commands","text":"<pre><code># Set project\nexport GOOGLE_PROJECT=your-project-id\n\n# Initialize Terraform\nterraform init\n\n# Plan deployment\nterraform plan -var=\"project_id=${GOOGLE_PROJECT}\"\n\n# Apply infrastructure\nterraform apply -var=\"project_id=${GOOGLE_PROJECT}\"\n\n# Configure kubectl\ngcloud container clusters get-credentials dealsphere-production-gke --region us-central1\n\n# Deploy application\nkubectl apply -f k8s/\n</code></pre>"},{"location":"deployment/cloud-infrastructure/#microsoft-azure","title":"Microsoft Azure","text":""},{"location":"deployment/cloud-infrastructure/#prerequisites_2","title":"Prerequisites","text":"<pre><code># Install Azure CLI\ncurl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash\n\n# Login to Azure\naz login\n\n# Set subscription\naz account set --subscription \"your-subscription-id\"\n</code></pre>"},{"location":"deployment/cloud-infrastructure/#terraform-configuration_1","title":"Terraform Configuration","text":""},{"location":"deployment/cloud-infrastructure/#main-infrastructure-maintf_2","title":"Main Infrastructure (main.tf)","text":"<pre><code>terraform {\n  required_providers {\n    azurerm = {\n      source  = \"hashicorp/azurerm\"\n      version = \"~&gt; 3.0\"\n    }\n  }\n\n  backend \"azurerm\" {\n    resource_group_name  = \"terraform-state-rg\"\n    storage_account_name = \"dealspherestate\"\n    container_name       = \"tfstate\"\n    key                  = \"production.terraform.tfstate\"\n  }\n}\n\nprovider \"azurerm\" {\n  features {}\n}\n\nvariable \"location\" {\n  description = \"Azure region\"\n  type        = string\n  default     = \"East US\"\n}\n\nvariable \"environment\" {\n  description = \"Environment (staging/production)\"\n  type        = string\n  default     = \"production\"\n}\n\n# Resource Group\nresource \"azurerm_resource_group\" \"main\" {\n  name     = \"dealsphere-${var.environment}-rg\"\n  location = var.location\n\n  tags = {\n    Environment = var.environment\n    Project     = \"DealSphere\"\n  }\n}\n\n# Virtual Network\nresource \"azurerm_virtual_network\" \"main\" {\n  name                = \"dealsphere-${var.environment}-vnet\"\n  address_space       = [\"10.0.0.0/16\"]\n  location            = azurerm_resource_group.main.location\n  resource_group_name = azurerm_resource_group.main.name\n\n  tags = {\n    Environment = var.environment\n  }\n}\n\nresource \"azurerm_subnet\" \"public\" {\n  name                 = \"public\"\n  resource_group_name  = azurerm_resource_group.main.name\n  virtual_network_name = azurerm_virtual_network.main.name\n  address_prefixes     = [\"10.0.1.0/24\"]\n}\n\nresource \"azurerm_subnet\" \"private\" {\n  name                 = \"private\"\n  resource_group_name  = azurerm_resource_group.main.name\n  virtual_network_name = azurerm_virtual_network.main.name\n  address_prefixes     = [\"10.0.2.0/24\"]\n\n  service_endpoints = [\"Microsoft.Sql\"]\n}\n\n# Network Security Groups\nresource \"azurerm_network_security_group\" \"public\" {\n  name                = \"dealsphere-${var.environment}-public-nsg\"\n  location            = azurerm_resource_group.main.location\n  resource_group_name = azurerm_resource_group.main.name\n\n  security_rule {\n    name                       = \"HTTP\"\n    priority                   = 1001\n    direction                  = \"Inbound\"\n    access                     = \"Allow\"\n    protocol                   = \"Tcp\"\n    source_port_range          = \"*\"\n    destination_port_range     = \"80\"\n    source_address_prefix      = \"*\"\n    destination_address_prefix = \"*\"\n  }\n\n  security_rule {\n    name                       = \"HTTPS\"\n    priority                   = 1002\n    direction                  = \"Inbound\"\n    access                     = \"Allow\"\n    protocol                   = \"Tcp\"\n    source_port_range          = \"*\"\n    destination_port_range     = \"443\"\n    source_address_prefix      = \"*\"\n    destination_address_prefix = \"*\"\n  }\n}\n\nresource \"azurerm_subnet_network_security_group_association\" \"public\" {\n  subnet_id                 = azurerm_subnet.public.id\n  network_security_group_id = azurerm_network_security_group.public.id\n}\n</code></pre>"},{"location":"deployment/cloud-infrastructure/#aks-cluster-akstf","title":"AKS Cluster (aks.tf)","text":"<pre><code># AKS Cluster\nresource \"azurerm_kubernetes_cluster\" \"main\" {\n  name                = \"dealsphere-${var.environment}-aks\"\n  location            = azurerm_resource_group.main.location\n  resource_group_name = azurerm_resource_group.main.name\n  dns_prefix          = \"dealsphere-${var.environment}\"\n\n  default_node_pool {\n    name       = \"default\"\n    node_count = var.environment == \"production\" ? 2 : 1\n    vm_size    = var.environment == \"production\" ? \"Standard_D4s_v3\" : \"Standard_B2s\"\n\n    vnet_subnet_id = azurerm_subnet.private.id\n  }\n\n  identity {\n    type = \"SystemAssigned\"\n  }\n\n  network_profile {\n    network_plugin = \"azure\"\n    service_cidr   = \"10.1.0.0/16\"\n    dns_service_ip = \"10.1.0.10\"\n  }\n\n  tags = {\n    Environment = var.environment\n  }\n}\n\n# Additional Node Pool for Production\nresource \"azurerm_kubernetes_cluster_node_pool\" \"production\" {\n  count = var.environment == \"production\" ? 1 : 0\n\n  name                  = \"production\"\n  kubernetes_cluster_id = azurerm_kubernetes_cluster.main.id\n  vm_size              = \"Standard_D8s_v3\"\n  node_count           = 3\n  vnet_subnet_id       = azurerm_subnet.private.id\n\n  node_taints = [\"workload=production:NoSchedule\"]\n  node_labels = {\n    \"workload\" = \"production\"\n  }\n\n  tags = {\n    Environment = var.environment\n  }\n}\n</code></pre>"},{"location":"deployment/cloud-infrastructure/#postgresql-database-postgresqltf","title":"PostgreSQL Database (postgresql.tf)","text":"<pre><code># Random password for database\nresource \"random_password\" \"db_password\" {\n  length  = 32\n  special = true\n}\n\n# PostgreSQL Server\nresource \"azurerm_postgresql_flexible_server\" \"main\" {\n  name                   = \"dealsphere-${var.environment}-psql\"\n  resource_group_name    = azurerm_resource_group.main.name\n  location               = azurerm_resource_group.main.location\n  version                = \"16\"\n\n  administrator_login    = \"dealsphere\"\n  administrator_password = random_password.db_password.result\n\n  storage_mb   = var.environment == \"production\" ? 102400 : 32768\n  storage_tier = \"P4\"\n\n  sku_name = var.environment == \"production\" ? \"GP_Standard_D4s_v3\" : \"B_Standard_B1ms\"\n  zone     = \"1\"\n\n  backup_retention_days        = var.environment == \"production\" ? 35 : 7\n  point_in_time_restore_time_in_minutes = var.environment == \"production\" ? 10080 : 60\n\n  high_availability {\n    mode = var.environment == \"production\" ? \"ZoneRedundant\" : \"Disabled\"\n  }\n\n  tags = {\n    Environment = var.environment\n  }\n}\n\n# PostgreSQL Database\nresource \"azurerm_postgresql_flexible_server_database\" \"main\" {\n  name      = \"dealsphere\"\n  server_id = azurerm_postgresql_flexible_server.main.id\n  collation = \"en_US.UTF8\"\n  charset   = \"UTF8\"\n}\n\n# Firewall rule for AKS subnet\nresource \"azurerm_postgresql_flexible_server_firewall_rule\" \"aks\" {\n  name             = \"aks-subnet\"\n  server_id        = azurerm_postgresql_flexible_server.main.id\n  start_ip_address = cidrhost(azurerm_subnet.private.address_prefixes[0], 0)\n  end_ip_address   = cidrhost(azurerm_subnet.private.address_prefixes[0], -1)\n}\n\n# Key Vault for secrets\nresource \"azurerm_key_vault\" \"main\" {\n  name                       = \"dealsphere-${var.environment}-kv-${random_id.kv_suffix.hex}\"\n  location                   = azurerm_resource_group.main.location\n  resource_group_name        = azurerm_resource_group.main.name\n  tenant_id                  = data.azurerm_client_config.current.tenant_id\n  sku_name                   = \"standard\"\n  soft_delete_retention_days = 7\n\n  access_policy {\n    tenant_id = data.azurerm_client_config.current.tenant_id\n    object_id = data.azurerm_client_config.current.object_id\n\n    secret_permissions = [\n      \"Get\",\n      \"List\",\n      \"Set\",\n      \"Delete\",\n      \"Recover\",\n      \"Backup\",\n      \"Restore\"\n    ]\n  }\n\n  tags = {\n    Environment = var.environment\n  }\n}\n\nresource \"random_id\" \"kv_suffix\" {\n  byte_length = 4\n}\n\ndata \"azurerm_client_config\" \"current\" {}\n\n# Store database password in Key Vault\nresource \"azurerm_key_vault_secret\" \"db_password\" {\n  name         = \"db-password\"\n  value        = random_password.db_password.result\n  key_vault_id = azurerm_key_vault.main.id\n}\n</code></pre>"},{"location":"deployment/cloud-infrastructure/#digital-ocean-simplified","title":"Digital Ocean (Simplified)","text":""},{"location":"deployment/cloud-infrastructure/#terraform-configuration_2","title":"Terraform Configuration","text":"<pre><code>terraform {\n  required_providers {\n    digitalocean = {\n      source  = \"digitalocean/digitalocean\"\n      version = \"~&gt; 2.0\"\n    }\n  }\n}\n\nprovider \"digitalocean\" {\n  token = var.do_token\n}\n\nvariable \"do_token\" {\n  description = \"DigitalOcean API Token\"\n  type        = string\n  sensitive   = true\n}\n\n# VPC\nresource \"digitalocean_vpc\" \"main\" {\n  name     = \"dealsphere-${var.environment}-vpc\"\n  region   = \"nyc3\"\n  ip_range = \"10.10.0.0/16\"\n}\n\n# Kubernetes Cluster\nresource \"digitalocean_kubernetes_cluster\" \"main\" {\n  name    = \"dealsphere-${var.environment}\"\n  region  = \"nyc3\"\n  version = \"1.28.2-do.0\"\n  vpc_uuid = digitalocean_vpc.main.id\n\n  node_pool {\n    name       = \"worker-pool\"\n    size       = var.environment == \"production\" ? \"s-4vcpu-8gb\" : \"s-2vcpu-4gb\"\n    node_count = var.environment == \"production\" ? 3 : 2\n    auto_scale = true\n    min_nodes  = 1\n    max_nodes  = var.environment == \"production\" ? 10 : 5\n  }\n\n  tags = [\"dealsphere\", var.environment]\n}\n\n# Database\nresource \"digitalocean_database_cluster\" \"main\" {\n  name       = \"dealsphere-${var.environment}-db\"\n  engine     = \"pg\"\n  version    = \"16\"\n  size       = var.environment == \"production\" ? \"db-s-4vcpu-8gb\" : \"db-s-1vcpu-2gb\"\n  region     = \"nyc3\"\n  node_count = var.environment == \"production\" ? 2 : 1\n\n  private_network_uuid = digitalocean_vpc.main.id\n\n  tags = [\"dealsphere\", var.environment]\n}\n\nresource \"digitalocean_database_db\" \"dealsphere\" {\n  cluster_id = digitalocean_database_cluster.main.id\n  name       = \"dealsphere\"\n}\n\nresource \"digitalocean_database_user\" \"dealsphere\" {\n  cluster_id = digitalocean_database_cluster.main.id\n  name       = \"dealsphere\"\n}\n\n# Load Balancer\nresource \"digitalocean_loadbalancer\" \"main\" {\n  name     = \"dealsphere-${var.environment}-lb\"\n  region   = \"nyc3\"\n  vpc_uuid = digitalocean_vpc.main.id\n\n  forwarding_rule {\n    entry_protocol  = \"http\"\n    entry_port      = 80\n    target_protocol = \"http\"\n    target_port     = 80\n    redirect_http_to_https = true\n  }\n\n  forwarding_rule {\n    entry_protocol  = \"https\"\n    entry_port      = 443\n    target_protocol = \"http\"\n    target_port     = 80\n    certificate_name = digitalocean_certificate.main.name\n  }\n\n  healthcheck {\n    protocol = \"http\"\n    port     = 80\n    path     = \"/health\"\n  }\n\n  tags = [\"dealsphere\", var.environment]\n}\n\n# SSL Certificate\nresource \"digitalocean_certificate\" \"main\" {\n  name    = \"dealsphere-${var.environment}-cert\"\n  type    = \"lets_encrypt\"\n  domains = [var.domain_name]\n}\n\n# Container Registry\nresource \"digitalocean_container_registry\" \"main\" {\n  name                   = \"dealsphere\"\n  subscription_tier_slug = \"basic\"\n  region                 = \"nyc3\"\n}\n</code></pre>"},{"location":"deployment/cloud-infrastructure/#cicd-integration","title":"CI/CD Integration","text":""},{"location":"deployment/cloud-infrastructure/#github-actions-for-cloud-deployment","title":"GitHub Actions for Cloud Deployment","text":"<pre><code># .github/workflows/deploy-cloud.yml\nname: Deploy to Cloud\n\non:\n  push:\n    branches: [main]\n  workflow_dispatch:\n    inputs:\n      environment:\n        description: 'Environment to deploy'\n        required: true\n        default: 'staging'\n        type: choice\n        options:\n          - staging\n          - production\n\nenv:\n  ENVIRONMENT: ${{ github.event.inputs.environment || 'staging' }}\n\njobs:\n  deploy-infrastructure:\n    name: Deploy Infrastructure\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Setup Terraform\n        uses: hashicorp/setup-terraform@v3\n        with:\n          terraform_version: 1.6.0\n\n      - name: Configure AWS credentials\n        uses: aws-actions/configure-aws-credentials@v4\n        with:\n          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}\n          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n          aws-region: us-west-2\n\n      - name: Terraform Init\n        run: terraform init\n        working-directory: ./infrastructure/aws\n\n      - name: Terraform Plan\n        run: terraform plan -var=\"environment=${{ env.ENVIRONMENT }}\"\n        working-directory: ./infrastructure/aws\n\n      - name: Terraform Apply\n        if: github.ref == 'refs/heads/main'\n        run: terraform apply -auto-approve -var=\"environment=${{ env.ENVIRONMENT }}\"\n        working-directory: ./infrastructure/aws\n\n  deploy-application:\n    name: Deploy Application\n    runs-on: ubuntu-latest\n    needs: [deploy-infrastructure]\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Configure AWS credentials\n        uses: aws-actions/configure-aws-credentials@v4\n        with:\n          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}\n          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n          aws-region: us-west-2\n\n      - name: Login to Amazon ECR\n        id: login-ecr\n        uses: aws-actions/amazon-ecr-login@v2\n\n      - name: Build and push Docker images\n        run: |\n          # Backend\n          docker build -t $ECR_REGISTRY/dealsphere-backend:${{ github.sha }} ./backend\n          docker push $ECR_REGISTRY/dealsphere-backend:${{ github.sha }}\n\n          # Frontend\n          docker build -t $ECR_REGISTRY/dealsphere-frontend:${{ github.sha }} ./frontend\n          docker push $ECR_REGISTRY/dealsphere-frontend:${{ github.sha }}\n        env:\n          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}\n\n      - name: Deploy to ECS\n        run: |\n          # Update task definition with new image\n          aws ecs update-service \\\n            --cluster dealsphere-${{ env.ENVIRONMENT }} \\\n            --service dealsphere-backend \\\n            --force-new-deployment\n\n      - name: Wait for deployment\n        run: |\n          aws ecs wait services-stable \\\n            --cluster dealsphere-${{ env.ENVIRONMENT }} \\\n            --services dealsphere-backend\n</code></pre>"},{"location":"deployment/cloud-infrastructure/#monitoring-and-observability","title":"Monitoring and Observability","text":""},{"location":"deployment/cloud-infrastructure/#cloud-native-monitoring","title":"Cloud-Native Monitoring","text":"<p>AWS CloudWatch: - Application logs and metrics - Custom dashboards and alarms - Integration with ECS and RDS</p> <p>GCP Cloud Monitoring: - GKE cluster monitoring - Application performance monitoring - Log aggregation with Cloud Logging</p> <p>Azure Monitor: - AKS monitoring with Container Insights - Application Insights for APM - Log Analytics workspace</p>"},{"location":"deployment/cloud-infrastructure/#example-cloudwatch-dashboard","title":"Example CloudWatch Dashboard","text":"<pre><code>{\n  \"widgets\": [\n    {\n      \"type\": \"metric\",\n      \"properties\": {\n        \"metrics\": [\n          [\"AWS/ECS\", \"CPUUtilization\", \"ServiceName\", \"dealsphere-backend\"],\n          [\".\", \"MemoryUtilization\", \".\", \".\"]\n        ],\n        \"period\": 300,\n        \"stat\": \"Average\",\n        \"region\": \"us-west-2\",\n        \"title\": \"ECS Service Metrics\"\n      }\n    },\n    {\n      \"type\": \"log\",\n      \"properties\": {\n        \"query\": \"SOURCE '/ecs/dealsphere-production' | fields @timestamp, @message\\n| filter @message like /ERROR/\\n| sort @timestamp desc\\n| limit 20\",\n        \"region\": \"us-west-2\",\n        \"title\": \"Recent Errors\"\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"deployment/cloud-infrastructure/#cost-optimization","title":"Cost Optimization","text":""},{"location":"deployment/cloud-infrastructure/#aws-cost-optimization","title":"AWS Cost Optimization","text":"<p>Reserved Instances: - RDS Reserved Instances for database - EC2 Reserved Instances for predictable workloads - ECS Fargate Savings Plans</p> <p>Resource Scheduling: - Auto Scaling for ECS services - RDS instance scheduling for non-production - CloudFront edge caching</p> <p>Storage Optimization: - S3 Intelligent Tiering - EBS GP3 storage type - Regular snapshot cleanup</p>"},{"location":"deployment/cloud-infrastructure/#multi-cloud-cost-comparison","title":"Multi-Cloud Cost Comparison","text":"Service AWS GCP Azure Digital Ocean Compute (2 vCPU, 8GB) $140/mo $130/mo $135/mo $96/mo Database (Small) $85/mo $75/mo $80/mo $60/mo Load Balancer $18/mo $15/mo $20/mo $12/mo Storage (100GB) $10/mo $10/mo $12/mo $10/mo Total (Est.) $253/mo $230/mo $247/mo $178/mo"},{"location":"deployment/cloud-infrastructure/#disaster-recovery","title":"Disaster Recovery","text":""},{"location":"deployment/cloud-infrastructure/#multi-region-setup","title":"Multi-Region Setup","text":"<p>AWS Multi-Region:</p> <pre><code># Primary region: us-west-2\n# DR region: us-east-1\n\nresource \"aws_s3_bucket_replication_configuration\" \"main\" {\n  bucket = aws_s3_bucket.main.id\n  role   = aws_iam_role.replication.arn\n\n  rule {\n    id     = \"replicate-to-dr\"\n    status = \"Enabled\"\n\n    destination {\n      bucket = aws_s3_bucket.dr.arn\n    }\n  }\n}\n\n# RDS Cross-Region Automated Backups\nresource \"aws_db_instance_automated_backups_replication\" \"main\" {\n  source_db_instance_arn = aws_db_instance.main.arn\n  kms_key_id            = aws_kms_key.dr.arn\n}\n</code></pre>"},{"location":"deployment/cloud-infrastructure/#backup-and-recovery-procedures","title":"Backup and Recovery Procedures","text":"<ol> <li>Database Backups: Automated daily backups with cross-region replication</li> <li>Application State: Stateless applications with external state storage</li> <li>Configuration: Infrastructure as Code in version control</li> <li>Monitoring: Health checks and automated failover procedures</li> </ol>"},{"location":"deployment/cloud-infrastructure/#security-best-practices","title":"Security Best Practices","text":""},{"location":"deployment/cloud-infrastructure/#infrastructure-security","title":"Infrastructure Security","text":"<p>Network Security: - VPC with private subnets for databases - Security groups with least privilege access - WAF for web application protection</p> <p>Encryption: - Encryption at rest for all storage - TLS 1.2+ for all communication - KMS/Key Vault for key management</p> <p>Access Control: - IAM roles with minimal permissions - Service accounts for application access - Multi-factor authentication for admin access</p>"},{"location":"deployment/cloud-infrastructure/#troubleshooting","title":"Troubleshooting","text":""},{"location":"deployment/cloud-infrastructure/#common-cloud-issues","title":"Common Cloud Issues","text":"<p>ECS/EKS Task Failures:</p> <pre><code># Check task logs\naws ecs describe-tasks --cluster my-cluster --tasks task-id\nkubectl logs -f deployment/my-app\n\n# Check service events\naws ecs describe-services --cluster my-cluster --services my-service\nkubectl describe deployment my-app\n</code></pre> <p>Database Connection Issues:</p> <pre><code># Test connectivity\ntelnet db-endpoint 5432\nnslookup db-endpoint\n\n# Check security groups\naws ec2 describe-security-groups --group-ids sg-xxxxx\n</code></pre> <p>SSL Certificate Issues:</p> <pre><code># Check certificate status\naws acm list-certificates\ngcloud compute ssl-certificates list\naz network application-gateway ssl-cert list\n</code></pre>"},{"location":"deployment/cloud-infrastructure/#related-documentation","title":"Related Documentation","text":"<ul> <li>Production Deployment</li> <li>Environment Management</li> <li>Security and Secrets Management</li> <li>Observability and Monitoring</li> </ul>"},{"location":"deployment/environment-management/","title":"Environment Management","text":"<p>This guide covers environment configuration, secrets management, and deployment pipelines for DealSphere across different environments (development, staging, production).</p>"},{"location":"deployment/environment-management/#overview","title":"Overview","text":"<p>DealSphere uses a multi-environment approach to ensure code quality and system reliability:</p> <ul> <li>Development: Local development environment with Docker Compose</li> <li>Staging: Pre-production environment for testing and integration</li> <li>Production: Live environment serving real users</li> </ul>"},{"location":"deployment/environment-management/#environment-configuration","title":"Environment Configuration","text":""},{"location":"deployment/environment-management/#environment-variables-structure","title":"Environment Variables Structure","text":"<p>Each environment uses specific configuration files:</p> <pre><code>environments/\n\u251c\u2500\u2500 .env.development      # Local development\n\u251c\u2500\u2500 .env.staging         # Staging environment\n\u251c\u2500\u2500 .env.production      # Production environment\n\u2514\u2500\u2500 .env.example         # Template with all variables\n</code></pre>"},{"location":"deployment/environment-management/#core-environment-variables","title":"Core Environment Variables","text":"<pre><code># Application Configuration\nAPP_ENV=production\nAPP_NAME=dealsphere\nAPP_VERSION=1.0.0\nAPP_URL=https://dealsphere.com\nAPP_PORT=8080\n\n# Database Configuration\nDB_HOST=dealsphere-db-cluster\nDB_PORT=5432\nDB_NAME=dealsphere_prod\nDB_USERNAME=dealsphere_user\nDB_PASSWORD=${DB_PASSWORD_SECRET}\nDB_SSL_MODE=require\nDB_POOL_SIZE=20\n\n# Redis Configuration\nREDIS_HOST=dealsphere-redis-cluster\nREDIS_PORT=6379\nREDIS_PASSWORD=${REDIS_PASSWORD_SECRET}\nREDIS_DATABASE=0\nREDIS_SSL=true\n\n# JWT Configuration\nJWT_SECRET=${JWT_SECRET_KEY}\nJWT_EXPIRATION=7200\nJWT_REFRESH_EXPIRATION=604800\n\n# GraphQL Configuration\nGRAPHQL_PLAYGROUND_ENABLED=false\nGRAPHQL_INTROSPECTION_ENABLED=false\n\n# Logging Configuration\nLOG_LEVEL=INFO\nLOG_FORMAT=JSON\nLOG_FILE_ENABLED=true\nLOG_FILE_PATH=/var/log/dealsphere/app.log\n\n# Monitoring Configuration\nMETRICS_ENABLED=true\nMETRICS_PORT=9090\nHEALTH_CHECK_ENABLED=true\n\n# Email Configuration\nSMTP_HOST=${SMTP_HOST}\nSMTP_PORT=587\nSMTP_USERNAME=${SMTP_USERNAME}\nSMTP_PASSWORD=${SMTP_PASSWORD}\nSMTP_FROM=noreply@dealsphere.com\n\n# File Storage Configuration\nSTORAGE_PROVIDER=aws-s3\nSTORAGE_BUCKET=dealsphere-files-prod\nAWS_REGION=us-west-2\nAWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}\nAWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}\n\n# Feature Flags\nFEATURE_ADVANCED_ANALYTICS=true\nFEATURE_REAL_TIME_NOTIFICATIONS=true\nFEATURE_AUDIT_LOGGING=true\n</code></pre>"},{"location":"deployment/environment-management/#environment-specific-configurations","title":"Environment-Specific Configurations","text":""},{"location":"deployment/environment-management/#development-environment","title":"Development Environment","text":"<pre><code># .env.development\nAPP_ENV=development\nAPP_URL=http://localhost:3000\nDB_HOST=localhost\nDB_SSL_MODE=disable\nGRAPHQL_PLAYGROUND_ENABLED=true\nGRAPHQL_INTROSPECTION_ENABLED=true\nLOG_LEVEL=DEBUG\nMETRICS_ENABLED=false\n</code></pre>"},{"location":"deployment/environment-management/#staging-environment","title":"Staging Environment","text":"<pre><code># .env.staging\nAPP_ENV=staging\nAPP_URL=https://staging.dealsphere.com\nDB_HOST=staging-db.dealsphere.internal\nDB_SSL_MODE=require\nGRAPHQL_PLAYGROUND_ENABLED=true\nGRAPHQL_INTROSPECTION_ENABLED=false\nLOG_LEVEL=INFO\nMETRICS_ENABLED=true\n</code></pre>"},{"location":"deployment/environment-management/#production-environment","title":"Production Environment","text":"<pre><code># .env.production\nAPP_ENV=production\nAPP_URL=https://dealsphere.com\nDB_HOST=prod-db-cluster.dealsphere.internal\nDB_SSL_MODE=require\nGRAPHQL_PLAYGROUND_ENABLED=false\nGRAPHQL_INTROSPECTION_ENABLED=false\nLOG_LEVEL=WARN\nMETRICS_ENABLED=true\n</code></pre>"},{"location":"deployment/environment-management/#secrets-management","title":"Secrets Management","text":""},{"location":"deployment/environment-management/#local-development","title":"Local Development","text":"<p>For local development, use a <code>.env</code> file:</p> <pre><code># Copy template\ncp .env.example .env.development\n\n# Edit with your local values\nvim .env.development\n</code></pre>"},{"location":"deployment/environment-management/#cloud-environments","title":"Cloud Environments","text":""},{"location":"deployment/environment-management/#aws-secrets-manager","title":"AWS Secrets Manager","text":"<pre><code># Store database credentials\naws secretsmanager create-secret \\\n    --name \"dealsphere/prod/database\" \\\n    --description \"Production database credentials\" \\\n    --secret-string '{\n        \"username\": \"dealsphere_user\",\n        \"password\": \"secure-db-password\",\n        \"host\": \"prod-db-cluster.amazonaws.com\",\n        \"port\": 5432,\n        \"database\": \"dealsphere_prod\"\n    }'\n\n# Store JWT secret\naws secretsmanager create-secret \\\n    --name \"dealsphere/prod/jwt-secret\" \\\n    --description \"JWT signing secret\" \\\n    --secret-string \"your-super-secure-jwt-secret-key\"\n\n# Store Redis password\naws secretsmanager create-secret \\\n    --name \"dealsphere/prod/redis-password\" \\\n    --description \"Redis authentication password\" \\\n    --secret-string \"secure-redis-password\"\n</code></pre>"},{"location":"deployment/environment-management/#kubernetes-secrets","title":"Kubernetes Secrets","text":"<pre><code># secrets.yaml\napiVersion: v1\nkind: Secret\nmetadata:\n  name: dealsphere-secrets\n  namespace: dealsphere-prod\ntype: Opaque\ndata:\n  # Base64 encoded values\n  DB_PASSWORD: c2VjdXJlLWRiLXBhc3N3b3Jk\n  JWT_SECRET: eW91ci1zdXBlci1zZWN1cmUtand0LXNlY3JldC1rZXk=\n  REDIS_PASSWORD: c2VjdXJlLXJlZGlzLXBhc3N3b3Jk\n  SMTP_PASSWORD: c210cC1wYXNzd29yZA==\n  AWS_SECRET_ACCESS_KEY: YXdzLXNlY3JldC1hY2Nlc3Mta2V5\n---\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: dealsphere-config\n  namespace: dealsphere-prod\ndata:\n  APP_ENV: \"production\"\n  DB_HOST: \"prod-db-cluster.dealsphere.internal\"\n  DB_PORT: \"5432\"\n  DB_NAME: \"dealsphere_prod\"\n  DB_USERNAME: \"dealsphere_user\"\n  REDIS_HOST: \"prod-redis-cluster.dealsphere.internal\"\n  REDIS_PORT: \"6379\"\n  LOG_LEVEL: \"INFO\"\n  METRICS_ENABLED: \"true\"\n</code></pre>"},{"location":"deployment/environment-management/#docker-swarm-secrets","title":"Docker Swarm Secrets","text":"<pre><code># Create secrets\necho \"secure-db-password\" | docker secret create db_password -\necho \"your-jwt-secret-key\" | docker secret create jwt_secret -\necho \"secure-redis-password\" | docker secret create redis_password -\n\n# Use in docker-compose.yml\nversion: '3.8'\nservices:\n  backend:\n    image: dealsphere/backend:latest\n    secrets:\n      - db_password\n      - jwt_secret\n      - redis_password\n    environment:\n      - DB_PASSWORD_FILE=/run/secrets/db_password\n      - JWT_SECRET_FILE=/run/secrets/jwt_secret\n      - REDIS_PASSWORD_FILE=/run/secrets/redis_password\n\nsecrets:\n  db_password:\n    external: true\n  jwt_secret:\n    external: true\n  redis_password:\n    external: true\n</code></pre>"},{"location":"deployment/environment-management/#configuration-management","title":"Configuration Management","text":""},{"location":"deployment/environment-management/#application-properties-template","title":"Application Properties Template","text":"<p>Create <code>application-template.yml</code> for environment-specific overrides:</p> <pre><code># application-template.yml\nserver:\n  port: ${APP_PORT:8080}\n  servlet:\n    context-path: /api\n\nspring:\n  application:\n    name: ${APP_NAME:dealsphere}\n  profiles:\n    active: ${APP_ENV:development}\n\n  datasource:\n    url: jdbc:postgresql://${DB_HOST:localhost}:${DB_PORT:5432}/${DB_NAME:dealsphere}\n    username: ${DB_USERNAME:dealsphere}\n    password: ${DB_PASSWORD:password}\n    driver-class-name: org.postgresql.Driver\n    hikari:\n      maximum-pool-size: ${DB_POOL_SIZE:10}\n      minimum-idle: 2\n      connection-timeout: 30000\n      idle-timeout: 600000\n      max-lifetime: 1800000\n\n  redis:\n    host: ${REDIS_HOST:localhost}\n    port: ${REDIS_PORT:6379}\n    password: ${REDIS_PASSWORD:}\n    database: ${REDIS_DATABASE:0}\n    ssl: ${REDIS_SSL:false}\n\n  jpa:\n    hibernate:\n      ddl-auto: ${HIBERNATE_DDL_AUTO:validate}\n    show-sql: ${JPA_SHOW_SQL:false}\n    properties:\n      hibernate:\n        dialect: org.hibernate.dialect.PostgreSQLDialect\n        format_sql: true\n\nlogging:\n  level:\n    com.dealsphere: ${LOG_LEVEL:INFO}\n    org.springframework.security: ${SECURITY_LOG_LEVEL:WARN}\n  pattern:\n    console: \"%d{yyyy-MM-dd HH:mm:ss} - %msg%n\"\n    file: \"%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n\"\n  file:\n    name: ${LOG_FILE_PATH:/var/log/dealsphere/app.log}\n\nmanagement:\n  endpoints:\n    web:\n      exposure:\n        include: health,metrics,prometheus\n  endpoint:\n    health:\n      enabled: ${HEALTH_CHECK_ENABLED:true}\n      show-details: when-authorized\n  metrics:\n    export:\n      prometheus:\n        enabled: ${METRICS_ENABLED:false}\n\njwt:\n  secret: ${JWT_SECRET:default-dev-secret}\n  expiration: ${JWT_EXPIRATION:3600}\n  refresh-expiration: ${JWT_REFRESH_EXPIRATION:604800}\n\ngraphql:\n  playground:\n    enabled: ${GRAPHQL_PLAYGROUND_ENABLED:false}\n  introspection:\n    enabled: ${GRAPHQL_INTROSPECTION_ENABLED:false}\n</code></pre>"},{"location":"deployment/environment-management/#environment-validation","title":"Environment Validation","text":"<p>Create environment validation script:</p> <pre><code>#!/bin/bash\n# validate-environment.sh\n\nset -e\n\nREQUIRED_VARS=(\n    \"APP_ENV\"\n    \"DB_HOST\" \"DB_USERNAME\" \"DB_PASSWORD\"\n    \"REDIS_HOST\"\n    \"JWT_SECRET\"\n)\n\necho \"\ud83d\udd0d Validating environment configuration...\"\n\nmissing_vars=()\n\nfor var in \"${REQUIRED_VARS[@]}\"; do\n    if [[ -z \"${!var}\" ]]; then\n        missing_vars+=(\"$var\")\n    fi\ndone\n\nif [[ ${#missing_vars[@]} -ne 0 ]]; then\n    echo \"\u274c Missing required environment variables:\"\n    printf '  - %s\\n' \"${missing_vars[@]}\"\n    exit 1\nfi\n\n# Environment-specific validations\nif [[ \"$APP_ENV\" == \"production\" ]]; then\n    PROD_REQUIRED_VARS=(\n        \"DB_SSL_MODE\"\n        \"REDIS_SSL\"\n        \"SMTP_HOST\" \"SMTP_USERNAME\" \"SMTP_PASSWORD\"\n        \"AWS_ACCESS_KEY_ID\" \"AWS_SECRET_ACCESS_KEY\"\n    )\n\n    prod_missing=()\n    for var in \"${PROD_REQUIRED_VARS[@]}\"; do\n        if [[ -z \"${!var}\" ]]; then\n            prod_missing+=(\"$var\")\n        fi\n    done\n\n    if [[ ${#prod_missing[@]} -ne 0 ]]; then\n        echo \"\u274c Missing production-specific variables:\"\n        printf '  - %s\\n' \"${prod_missing[@]}\"\n        exit 1\n    fi\n\n    # Security checks\n    if [[ \"$JWT_SECRET\" == \"default-dev-secret\" ]]; then\n        echo \"\u274c Production environment cannot use default JWT secret\"\n        exit 1\n    fi\n\n    if [[ \"$DB_SSL_MODE\" != \"require\" ]]; then\n        echo \"\u26a0\ufe0f  Warning: Database SSL should be 'require' in production\"\n    fi\nfi\n\necho \"\u2705 Environment validation passed\"\n\n# Test database connection\necho \"\ud83d\udd0d Testing database connection...\"\nif command -v psql &gt;/dev/null; then\n    if PGPASSWORD=\"$DB_PASSWORD\" psql -h \"$DB_HOST\" -U \"$DB_USERNAME\" -d \"$DB_NAME\" -c \"SELECT 1\" &gt;/dev/null 2&gt;&amp;1; then\n        echo \"\u2705 Database connection successful\"\n    else\n        echo \"\u274c Database connection failed\"\n        exit 1\n    fi\nelse\n    echo \"\u26a0\ufe0f  psql not found, skipping database connection test\"\nfi\n\n# Test Redis connection\necho \"\ud83d\udd0d Testing Redis connection...\"\nif command -v redis-cli &gt;/dev/null; then\n    if redis-cli -h \"$REDIS_HOST\" -p \"$REDIS_PORT\" ${REDIS_PASSWORD:+-a \"$REDIS_PASSWORD\"} ping &gt;/dev/null 2&gt;&amp;1; then\n        echo \"\u2705 Redis connection successful\"\n    else\n        echo \"\u274c Redis connection failed\"\n        exit 1\n    fi\nelse\n    echo \"\u26a0\ufe0f  redis-cli not found, skipping Redis connection test\"\nfi\n\necho \"\ud83c\udf89 All environment checks passed!\"\n</code></pre>"},{"location":"deployment/environment-management/#deployment-pipelines","title":"Deployment Pipelines","text":""},{"location":"deployment/environment-management/#cicd-configuration","title":"CI/CD Configuration","text":""},{"location":"deployment/environment-management/#github-actions-workflow","title":"GitHub Actions Workflow","text":"<pre><code># .github/workflows/deploy.yml\nname: Deploy DealSphere\n\non:\n  push:\n    branches: [main, staging]\n  pull_request:\n    branches: [main]\n\nenv:\n  REGISTRY: ghcr.io\n  IMAGE_NAME: dealsphere-inc/dealsphere-platform\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    services:\n      postgres:\n        image: postgres:15\n        env:\n          POSTGRES_PASSWORD: test\n          POSTGRES_DB: dealsphere_test\n        options: &gt;-\n          --health-cmd pg_isready\n          --health-interval 10s\n          --health-timeout 5s\n          --health-retries 5\n      redis:\n        image: redis:7\n        options: &gt;-\n          --health-cmd \"redis-cli ping\"\n          --health-interval 10s\n          --health-timeout 5s\n          --health-retries 5\n\n    steps:\n    - uses: actions/checkout@v4\n\n    - name: Set up JDK 17\n      uses: actions/setup-java@v3\n      with:\n        java-version: '17'\n        distribution: 'temurin'\n\n    - name: Set up Node.js\n      uses: actions/setup-node@v4\n      with:\n        node-version: '18'\n        cache: 'npm'\n        cache-dependency-path: frontend/package-lock.json\n\n    - name: Validate Environment\n      run: |\n        cp .env.example .env.test\n        chmod +x scripts/validate-environment.sh\n        ./scripts/validate-environment.sh\n\n    - name: Run Backend Tests\n      run: |\n        cd backend\n        ./gradlew test jacocoTestReport\n      env:\n        DB_HOST: localhost\n        DB_USERNAME: postgres\n        DB_PASSWORD: test\n        DB_NAME: dealsphere_test\n        REDIS_HOST: localhost\n        JWT_SECRET: test-jwt-secret\n\n    - name: Run Frontend Tests\n      run: |\n        cd frontend\n        npm ci\n        npm run test:coverage\n\n    - name: Upload Coverage\n      uses: codecov/codecov-action@v3\n\n  build:\n    needs: test\n    runs-on: ubuntu-latest\n    if: github.event_name == 'push'\n\n    steps:\n    - uses: actions/checkout@v4\n\n    - name: Log in to Container Registry\n      uses: docker/login-action@v2\n      with:\n        registry: ${{ env.REGISTRY }}\n        username: ${{ github.actor }}\n        password: ${{ secrets.GITHUB_TOKEN }}\n\n    - name: Extract metadata\n      id: meta\n      uses: docker/metadata-action@v4\n      with:\n        images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}\n        tags: |\n          type=ref,event=branch\n          type=sha,prefix={{branch}}-\n          type=raw,value=latest,enable={{is_default_branch}}\n\n    - name: Build and Push Backend\n      uses: docker/build-push-action@v4\n      with:\n        context: ./backend\n        file: ./backend/Dockerfile\n        push: true\n        tags: ${{ steps.meta.outputs.tags }}-backend\n        labels: ${{ steps.meta.outputs.labels }}\n\n    - name: Build and Push Frontend\n      uses: docker/build-push-action@v4\n      with:\n        context: ./frontend\n        file: ./frontend/Dockerfile\n        push: true\n        tags: ${{ steps.meta.outputs.tags }}-frontend\n        labels: ${{ steps.meta.outputs.labels }}\n\n  deploy-staging:\n    needs: build\n    runs-on: ubuntu-latest\n    if: github.ref == 'refs/heads/staging'\n    environment: staging\n\n    steps:\n    - uses: actions/checkout@v4\n\n    - name: Deploy to Staging\n      run: |\n        echo \"Deploying to staging environment...\"\n        # Add staging deployment commands\n      env:\n        STAGING_HOST: ${{ secrets.STAGING_HOST }}\n        STAGING_SSH_KEY: ${{ secrets.STAGING_SSH_KEY }}\n\n  deploy-production:\n    needs: build\n    runs-on: ubuntu-latest\n    if: github.ref == 'refs/heads/main'\n    environment: production\n\n    steps:\n    - uses: actions/checkout@v4\n\n    - name: Deploy to Production\n      run: |\n        echo \"Deploying to production environment...\"\n        # Add production deployment commands\n      env:\n        PRODUCTION_HOST: ${{ secrets.PRODUCTION_HOST }}\n        PRODUCTION_SSH_KEY: ${{ secrets.PRODUCTION_SSH_KEY }}\n        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}\n        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n</code></pre>"},{"location":"deployment/environment-management/#deployment-scripts","title":"Deployment Scripts","text":""},{"location":"deployment/environment-management/#rolling-deployment-script","title":"Rolling Deployment Script","text":"<pre><code>#!/bin/bash\n# scripts/deploy.sh\n\nset -e\n\nENVIRONMENT=${1:-staging}\nVERSION=${2:-latest}\nHEALTH_CHECK_TIMEOUT=300\nROLLBACK_ON_FAILURE=true\n\necho \"\ud83d\ude80 Starting deployment to $ENVIRONMENT (version: $VERSION)\"\n\n# Load environment-specific configuration\nif [[ -f \".env.$ENVIRONMENT\" ]]; then\n    source \".env.$ENVIRONMENT\"\nelse\n    echo \"\u274c Environment file .env.$ENVIRONMENT not found\"\n    exit 1\nfi\n\n# Validate environment\n./scripts/validate-environment.sh\n\n# Pre-deployment health check\necho \"\ud83c\udfe5 Pre-deployment health check...\"\nif ! curl -f \"$APP_URL/actuator/health\" &gt;/dev/null 2&gt;&amp;1; then\n    echo \"\u26a0\ufe0f  Application not responding, proceeding with deployment\"\nfi\n\n# Database migrations (if needed)\nif [[ \"$RUN_MIGRATIONS\" == \"true\" ]]; then\n    echo \"\ud83d\udcca Running database migrations...\"\n    docker run --rm \\\n        --network dealsphere-network \\\n        -e DB_HOST=\"$DB_HOST\" \\\n        -e DB_USERNAME=\"$DB_USERNAME\" \\\n        -e DB_PASSWORD=\"$DB_PASSWORD\" \\\n        -e DB_NAME=\"$DB_NAME\" \\\n        ghcr.io/dealsphere-inc/dealsphere-platform:${VERSION}-backend \\\n        java -jar app.jar --spring.profiles.active=migration\nfi\n\n# Rolling deployment\necho \"\ud83d\udd04 Performing rolling deployment...\"\n\nif command -v docker-compose &gt;/dev/null; then\n    # Docker Compose deployment\n    export IMAGE_TAG=$VERSION\n    docker-compose -f docker-compose.prod.yml pull\n    docker-compose -f docker-compose.prod.yml up -d --remove-orphans\n\nelif command -v kubectl &gt;/dev/null; then\n    # Kubernetes deployment\n    kubectl set image deployment/dealsphere-backend \\\n        backend=ghcr.io/dealsphere-inc/dealsphere-platform:${VERSION}-backend\n    kubectl set image deployment/dealsphere-frontend \\\n        frontend=ghcr.io/dealsphere-inc/dealsphere-platform:${VERSION}-frontend\n\n    kubectl rollout status deployment/dealsphere-backend --timeout=300s\n    kubectl rollout status deployment/dealsphere-frontend --timeout=300s\nelse\n    echo \"\u274c No supported orchestration tool found\"\n    exit 1\nfi\n\n# Health check with retry\necho \"\ud83c\udfe5 Post-deployment health check...\"\nfor i in {1..30}; do\n    if curl -f \"$APP_URL/actuator/health\" &gt;/dev/null 2&gt;&amp;1; then\n        echo \"\u2705 Application is healthy\"\n        break\n    fi\n\n    if [[ $i -eq 30 ]]; then\n        echo \"\u274c Health check failed after 30 attempts\"\n\n        if [[ \"$ROLLBACK_ON_FAILURE\" == \"true\" ]]; then\n            echo \"\ud83d\udd04 Rolling back deployment...\"\n            if command -v kubectl &gt;/dev/null; then\n                kubectl rollout undo deployment/dealsphere-backend\n                kubectl rollout undo deployment/dealsphere-frontend\n            else\n                docker-compose -f docker-compose.prod.yml down\n                # Restore previous version logic here\n            fi\n        fi\n        exit 1\n    fi\n\n    echo \"\u23f3 Waiting for application to become healthy (attempt $i/30)...\"\n    sleep 10\ndone\n\n# Smoke tests\necho \"\ud83e\uddea Running smoke tests...\"\n./scripts/smoke-tests.sh \"$APP_URL\"\n\necho \"\ud83c\udf89 Deployment completed successfully!\"\n\n# Post-deployment notifications\nif [[ -n \"$SLACK_WEBHOOK_URL\" ]]; then\n    curl -X POST -H 'Content-type: application/json' \\\n        --data \"{\\\"text\\\":\\\"\u2705 DealSphere $ENVIRONMENT deployment completed (version: $VERSION)\\\"}\" \\\n        \"$SLACK_WEBHOOK_URL\"\nfi\n</code></pre>"},{"location":"deployment/environment-management/#smoke-tests-script","title":"Smoke Tests Script","text":"<pre><code>#!/bin/bash\n# scripts/smoke-tests.sh\n\nset -e\n\nBASE_URL=${1:-http://localhost:8080}\nTIMEOUT=30\n\necho \"\ud83e\uddea Running smoke tests against $BASE_URL\"\n\n# Test health endpoint\necho \"Testing health endpoint...\"\nif ! curl -f --max-time $TIMEOUT \"$BASE_URL/actuator/health\" &gt;/dev/null; then\n    echo \"\u274c Health check failed\"\n    exit 1\nfi\necho \"\u2705 Health check passed\"\n\n# Test metrics endpoint\necho \"Testing metrics endpoint...\"\nif ! curl -f --max-time $TIMEOUT \"$BASE_URL/actuator/prometheus\" &gt;/dev/null; then\n    echo \"\u274c Metrics endpoint failed\"\n    exit 1\nfi\necho \"\u2705 Metrics endpoint passed\"\n\n# Test GraphQL endpoint\necho \"Testing GraphQL endpoint...\"\nGRAPHQL_QUERY='{\"query\":\"query { __schema { queryType { name } } }\"}'\nif ! curl -f --max-time $TIMEOUT \\\n    -H \"Content-Type: application/json\" \\\n    -d \"$GRAPHQL_QUERY\" \\\n    \"$BASE_URL/graphql\" &gt;/dev/null; then\n    echo \"\u274c GraphQL endpoint failed\"\n    exit 1\nfi\necho \"\u2705 GraphQL endpoint passed\"\n\n# Test database connectivity (through app)\necho \"Testing database connectivity...\"\nDB_QUERY='{\"query\":\"query { organizations { id name } }\"}'\nif ! curl -f --max-time $TIMEOUT \\\n    -H \"Content-Type: application/json\" \\\n    -H \"Authorization: Bearer test-token\" \\\n    -d \"$DB_QUERY\" \\\n    \"$BASE_URL/graphql\" &gt;/dev/null 2&gt;&amp;1; then\n    echo \"\u26a0\ufe0f  Database connectivity test skipped (requires auth)\"\nelse\n    echo \"\u2705 Database connectivity passed\"\nfi\n\necho \"\ud83c\udf89 All smoke tests passed!\"\n</code></pre>"},{"location":"deployment/environment-management/#environment-monitoring","title":"Environment Monitoring","text":""},{"location":"deployment/environment-management/#health-checks-configuration","title":"Health Checks Configuration","text":"<pre><code># health-checks.yml\nversion: '3.8'\nservices:\n  backend:\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8080/actuator/health\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n      start_period: 60s\n\n  frontend:\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:3000/health\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n      start_period: 30s\n\n  postgres:\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -U ${DB_USERNAME} -d ${DB_NAME}\"]\n      interval: 30s\n      timeout: 5s\n      retries: 5\n\n  redis:\n    healthcheck:\n      test: [\"CMD\", \"redis-cli\", \"ping\"]\n      interval: 30s\n      timeout: 5s\n      retries: 3\n</code></pre>"},{"location":"deployment/environment-management/#monitoring-integration","title":"Monitoring Integration","text":"<p>Environment monitoring is integrated with the observability stack. Each environment reports to centralized monitoring:</p> <ul> <li>Development: Local Grafana dashboard</li> <li>Staging: Shared monitoring cluster with environment labels</li> <li>Production: Dedicated monitoring infrastructure with high availability</li> </ul> <p>Key metrics tracked per environment:</p> <ul> <li>Application health and availability</li> <li>Resource utilization (CPU, memory, disk)</li> <li>Request rates and response times</li> <li>Error rates and types</li> <li>Database performance</li> <li>Security events and audit logs</li> </ul>"},{"location":"deployment/environment-management/#troubleshooting","title":"Troubleshooting","text":""},{"location":"deployment/environment-management/#common-environment-issues","title":"Common Environment Issues","text":"<p>Environment Variables Not Loading</p> <pre><code># Check environment file exists and has correct permissions\nls -la .env.*\nchmod 644 .env.production\n\n# Verify variables are exported\nenv | grep -E '^(DB_|REDIS_|JWT_)'\n\n# Test with explicit source\nsource .env.production &amp;&amp; ./scripts/validate-environment.sh\n</code></pre> <p>Database Connection Issues</p> <pre><code># Test direct connection\nPGPASSWORD=$DB_PASSWORD psql -h $DB_HOST -U $DB_USERNAME -d $DB_NAME -c \"SELECT version();\"\n\n# Check network connectivity\nnslookup $DB_HOST\ntelnet $DB_HOST $DB_PORT\n\n# Verify SSL configuration\npsql \"postgresql://$DB_USERNAME:$DB_PASSWORD@$DB_HOST:$DB_PORT/$DB_NAME?sslmode=$DB_SSL_MODE\"\n</code></pre> <p>Secrets Access Issues</p> <pre><code># AWS Secrets Manager\naws secretsmanager get-secret-value --secret-id \"dealsphere/prod/database\"\n\n# Kubernetes secrets\nkubectl get secrets -n dealsphere-prod\nkubectl describe secret dealsphere-secrets -n dealsphere-prod\n\n# Docker secrets\ndocker secret ls\ndocker secret inspect jwt_secret\n</code></pre> <p>This comprehensive environment management guide ensures consistent, secure, and reliable deployments across all DealSphere environments.</p>"},{"location":"deployment/observability-monitoring/","title":"Observability and Monitoring","text":"<p>This guide covers the comprehensive observability stack for DealSphere, including metrics collection, logging, distributed tracing, alerting, and performance monitoring across all environments.</p>"},{"location":"deployment/observability-monitoring/#overview","title":"Overview","text":"<p>DealSphere uses a modern observability stack that provides full visibility into application performance, infrastructure health, and user experience:</p> <ul> <li>Metrics: Prometheus + Grafana for time-series data and visualization</li> <li>Logging: Loki + Promtail for centralized log aggregation</li> <li>Tracing: Jaeger + OpenTelemetry for distributed request tracing</li> <li>Alerting: AlertManager for proactive issue detection</li> <li>Infrastructure Monitoring: Node Exporter + cAdvisor for system metrics</li> </ul>"},{"location":"deployment/observability-monitoring/#quick-start","title":"Quick Start","text":""},{"location":"deployment/observability-monitoring/#1-start-the-monitoring-stack","title":"1. Start the Monitoring Stack","text":"<pre><code>cd monitoring\ndocker compose -f docker-compose.monitoring.yml up -d\n</code></pre>"},{"location":"deployment/observability-monitoring/#2-access-dashboards","title":"2. Access Dashboards","text":"Service URL Credentials Grafana http://localhost:3000 admin/admin123 Prometheus http://localhost:9090 - Jaeger http://localhost:16686 - AlertManager http://localhost:9093 -"},{"location":"deployment/observability-monitoring/#3-verify-metrics-collection","title":"3. Verify Metrics Collection","text":"<pre><code># Check backend metrics\ncurl http://localhost:8080/actuator/prometheus\ncurl http://localhost:8080/actuator/health\n\n# Check monitoring stack health\ndocker compose -f docker-compose.monitoring.yml ps\n</code></pre>"},{"location":"deployment/observability-monitoring/#monitoring-stack-architecture","title":"Monitoring Stack Architecture","text":""},{"location":"deployment/observability-monitoring/#service-overview","title":"Service Overview","text":"Service Port Purpose Data Retention Prometheus 9090 Metrics storage &amp; querying 30 days / 10GB Grafana 3000 Dashboards &amp; visualization Persistent Loki 3100 Log aggregation 30 days Promtail - Log collection agent - Jaeger 16686 Distributed tracing UI 24 hours AlertManager 9093 Alert management &amp; routing 5 days Node Exporter 9100 System metrics collection - cAdvisor 8080 Container metrics - OTEL Collector 4317/4318 Telemetry data collection -"},{"location":"deployment/observability-monitoring/#network-architecture","title":"Network Architecture","text":"<pre><code>graph TB\n    subgraph \"Application Layer\"\n        BE[Backend App:8080]\n        FE[Frontend App:3000]\n    end\n\n    subgraph \"Collection Layer\"\n        OC[OTEL Collector:4317/4318]\n        PT[Promtail]\n        NE[Node Exporter:9100]\n        CA[cAdvisor:8080]\n    end\n\n    subgraph \"Storage Layer\"\n        PR[Prometheus:9090]\n        LK[Loki:3100]\n        JG[Jaeger:16686]\n    end\n\n    subgraph \"Visualization Layer\"\n        GR[Grafana:3000]\n        AM[AlertManager:9093]\n    end\n\n    BE --&gt; OC\n    FE --&gt; OC\n    BE --&gt; PT\n    FE --&gt; PT\n\n    OC --&gt; PR\n    OC --&gt; JG\n    PT --&gt; LK\n    NE --&gt; PR\n    CA --&gt; PR\n\n    PR --&gt; GR\n    LK --&gt; GR\n    JG --&gt; GR\n    PR --&gt; AM\n</code></pre>"},{"location":"deployment/observability-monitoring/#metrics-collection","title":"Metrics Collection","text":""},{"location":"deployment/observability-monitoring/#backend-metrics-spring-boot-micrometer","title":"Backend Metrics (Spring Boot + Micrometer)","text":"<p>The backend automatically exposes comprehensive metrics via Spring Boot Actuator:</p>"},{"location":"deployment/observability-monitoring/#available-endpoints","title":"Available Endpoints","text":"<pre><code># Health status with detailed checks\nGET /actuator/health\n\n# All available metrics\nGET /actuator/metrics\n\n# Prometheus-formatted metrics\nGET /actuator/prometheus\n\n# Application info\nGET /actuator/info\n\n# Environment variables\nGET /actuator/env\n\n# Configuration properties\nGET /actuator/configprops\n</code></pre>"},{"location":"deployment/observability-monitoring/#key-metrics-categories","title":"Key Metrics Categories","text":"<p>HTTP Request Metrics - <code>http_server_requests_seconds</code> - Request duration percentiles - <code>http_server_requests_total</code> - Request count by status code - <code>http_server_active_requests</code> - Currently active requests</p> <p>JVM Metrics - <code>jvm_memory_used_bytes</code> - Memory usage by pool - <code>jvm_gc_pause_seconds</code> - Garbage collection pause times - <code>jvm_threads_live_threads</code> - Active thread count - <code>jvm_classes_loaded_classes</code> - Loaded class count</p> <p>Database Metrics - <code>hikaricp_connections_active</code> - Active database connections - <code>hikaricp_connections_pending</code> - Pending connection requests - <code>hikaricp_connections_timeout_total</code> - Connection timeouts</p> <p>GraphQL Metrics - <code>graphql_request_seconds</code> - GraphQL operation duration - <code>graphql_error_total</code> - GraphQL errors by type - <code>graphql_request_total</code> - GraphQL requests by operation</p> <p>Custom Business Metrics</p> <pre><code>@Component\npublic class BusinessMetrics {\n    private final MeterRegistry meterRegistry;\n    private final Counter userLoginAttempts;\n    private final Timer orderProcessingTime;\n    private final Gauge activeUserSessions;\n\n    public BusinessMetrics(MeterRegistry meterRegistry, SessionService sessionService) {\n        this.meterRegistry = meterRegistry;\n\n        this.userLoginAttempts = Counter.builder(\"user.login.attempts\")\n            .description(\"Total user login attempts\")\n            .tag(\"status\", \"success\")\n            .register(meterRegistry);\n\n        this.orderProcessingTime = Timer.builder(\"order.processing.time\")\n            .description(\"Time taken to process orders\")\n            .register(meterRegistry);\n\n        this.activeUserSessions = Gauge.builder(\"user.sessions.active\")\n            .description(\"Number of active user sessions\")\n            .register(meterRegistry, sessionService, SessionService::getActiveCount);\n    }\n\n    public void recordLoginAttempt(boolean success) {\n        userLoginAttempts.increment(Tags.of(\"status\", success ? \"success\" : \"failure\"));\n    }\n\n    public void recordOrderProcessing(Duration duration) {\n        orderProcessingTime.record(duration);\n    }\n}\n</code></pre>"},{"location":"deployment/observability-monitoring/#frontend-metrics-opentelemetry-web","title":"Frontend Metrics (OpenTelemetry Web)","text":"<p>Frontend telemetry captures user experience and performance metrics:</p>"},{"location":"deployment/observability-monitoring/#web-vitals-tracking","title":"Web Vitals Tracking","text":"<pre><code>// src/utils/telemetry.js\nimport { getWebVitals } from 'web-vitals';\n\nexport class MetricsCollector {\n    constructor() {\n        this.init();\n    }\n\n    init() {\n        // Initialize OpenTelemetry Web SDK\n        this.setupWebVitals();\n        this.setupUserInteractions();\n        this.setupAPITracking();\n    }\n\n    setupWebVitals() {\n        getWebVitals(({ name, value, rating }) =&gt; {\n            this.recordMetric(`web_vital_${name.toLowerCase()}`, value, {\n                rating,\n                timestamp: Date.now()\n            });\n        });\n    }\n\n    trackUserInteraction(action, element, metadata = {}) {\n        this.recordMetric('user_interaction', 1, {\n            action,\n            element,\n            page: window.location.pathname,\n            ...metadata\n        });\n    }\n\n    trackAPICall(endpoint, method, duration, statusCode) {\n        this.recordMetric('api_call_duration', duration, {\n            endpoint,\n            method,\n            status_code: statusCode,\n            success: statusCode &lt; 400\n        });\n    }\n\n    trackPageView(path, loadTime) {\n        this.recordMetric('page_view', 1, {\n            path,\n            load_time: loadTime,\n            timestamp: Date.now()\n        });\n    }\n\n    recordMetric(name, value, labels = {}) {\n        // Send to OpenTelemetry Collector\n        fetch('/api/metrics', {\n            method: 'POST',\n            headers: { 'Content-Type': 'application/json' },\n            body: JSON.stringify({ name, value, labels, timestamp: Date.now() })\n        });\n    }\n}\n\n// Usage in components\nconst metricsCollector = new MetricsCollector();\n\n// Track button clicks\nmetricsCollector.trackUserInteraction('click', 'search_button', {\n    search_term: 'electronics'\n});\n\n// Track API performance\nconst startTime = performance.now();\nconst result = await api.fetchProducts();\nconst duration = performance.now() - startTime;\nmetricsCollector.trackAPICall('/api/products', 'GET', duration, 200);\n</code></pre>"},{"location":"deployment/observability-monitoring/#logging-strategy","title":"Logging Strategy","text":""},{"location":"deployment/observability-monitoring/#structured-logging-configuration","title":"Structured Logging Configuration","text":""},{"location":"deployment/observability-monitoring/#backend-logging-logback","title":"Backend Logging (Logback)","text":"<pre><code>&lt;!-- src/main/resources/logback-spring.xml --&gt;\n&lt;configuration&gt;\n    &lt;springProfile name=\"!local\"&gt;\n        &lt;appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt;\n            &lt;encoder class=\"net.logstash.logback.encoder.LogstashEncoder\"&gt;\n                &lt;customFields&gt;{\"service\":\"dealsphere-backend\",\"version\":\"${app.version:-unknown}\"}&lt;/customFields&gt;\n                &lt;fieldNames&gt;\n                    &lt;timestamp&gt;@timestamp&lt;/timestamp&gt;\n                    &lt;message&gt;message&lt;/message&gt;\n                    &lt;level&gt;level&lt;/level&gt;\n                    &lt;thread&gt;thread&lt;/thread&gt;\n                    &lt;logger&gt;logger&lt;/logger&gt;\n                &lt;/fieldNames&gt;\n                &lt;includeContext&gt;true&lt;/includeContext&gt;\n                &lt;includeMdc&gt;true&lt;/includeMdc&gt;\n            &lt;/encoder&gt;\n        &lt;/appender&gt;\n    &lt;/springProfile&gt;\n\n    &lt;springProfile name=\"local\"&gt;\n        &lt;appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt;\n            &lt;encoder&gt;\n                &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level [%X{traceId:-},%X{spanId:-}] %logger{36} - %msg%n&lt;/pattern&gt;\n            &lt;/encoder&gt;\n        &lt;/appender&gt;\n    &lt;/springProfile&gt;\n\n    &lt;appender name=\"FILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt;\n        &lt;file&gt;/var/log/dealsphere/application.log&lt;/file&gt;\n        &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.TimeBasedRollingPolicy\"&gt;\n            &lt;fileNamePattern&gt;/var/log/dealsphere/application.%d{yyyy-MM-dd}.%i.log&lt;/fileNamePattern&gt;\n            &lt;maxFileSize&gt;100MB&lt;/maxFileSize&gt;\n            &lt;maxHistory&gt;30&lt;/maxHistory&gt;\n            &lt;totalSizeCap&gt;3GB&lt;/totalSizeCap&gt;\n        &lt;/rollingPolicy&gt;\n        &lt;encoder class=\"net.logstash.logback.encoder.LogstashEncoder\"&gt;\n            &lt;customFields&gt;{\"service\":\"dealsphere-backend\"}&lt;/customFields&gt;\n        &lt;/encoder&gt;\n    &lt;/appender&gt;\n\n    &lt;logger name=\"com.dealsphere\" level=\"INFO\"/&gt;\n    &lt;logger name=\"org.springframework.security\" level=\"WARN\"/&gt;\n    &lt;logger name=\"org.hibernate.SQL\" level=\"DEBUG\"/&gt;\n\n    &lt;root level=\"INFO\"&gt;\n        &lt;appender-ref ref=\"STDOUT\"/&gt;\n        &lt;appender-ref ref=\"FILE\"/&gt;\n    &lt;/root&gt;\n&lt;/configuration&gt;\n</code></pre>"},{"location":"deployment/observability-monitoring/#structured-logging-examples","title":"Structured Logging Examples","text":"<pre><code>// Using structured logging with MDC\nimport org.slf4j.MDC;\n\n@Service\npublic class UserService {\n    private static final Logger logger = LoggerFactory.getLogger(UserService.class);\n\n    public User createUser(CreateUserRequest request) {\n        MDC.put(\"operation\", \"create_user\");\n        MDC.put(\"user_email\", request.getEmail());\n\n        try {\n            logger.info(\"Creating new user account\");\n\n            User user = userRepository.save(new User(request));\n\n            logger.info(\"User account created successfully\",\n                kv(\"user_id\", user.getId()),\n                kv(\"organization_id\", user.getOrganizationId()));\n\n            return user;\n        } catch (Exception e) {\n            logger.error(\"Failed to create user account\",\n                kv(\"error\", e.getMessage()), e);\n            throw e;\n        } finally {\n            MDC.clear();\n        }\n    }\n}\n</code></pre>"},{"location":"deployment/observability-monitoring/#log-aggregation-with-loki","title":"Log Aggregation with Loki","text":""},{"location":"deployment/observability-monitoring/#promtail-configuration","title":"Promtail Configuration","text":"<pre><code># promtail/promtail-config.yml\nserver:\n  http_listen_port: 9080\n  grpc_listen_port: 0\n\npositions:\n  filename: /tmp/positions.yaml\n\nclients:\n  - url: http://loki:3100/loki/api/v1/push\n\nscrape_configs:\n  # Application logs\n  - job_name: dealsphere-backend\n    static_configs:\n      - targets:\n          - localhost\n        labels:\n          job: dealsphere-backend\n          service: backend\n          environment: ${ENVIRONMENT:-development}\n          __path__: /var/log/dealsphere/application*.log\n\n  # Docker container logs\n  - job_name: containers\n    static_configs:\n      - targets:\n          - localhost\n        labels:\n          job: containerlogs\n          __path__: /var/lib/docker/containers/*/*log\n\n    pipeline_stages:\n      - json:\n          expressions:\n            output: log\n            stream: stream\n            attrs:\n      - json:\n          source: attrs\n          expressions:\n            tag:\n      - regex:\n          source: tag\n          expression: (?P&lt;service_name&gt;(?:[^|]*))\\|\n      - labels:\n          service_name:\n          stream:\n\n  # System logs\n  - job_name: syslog\n    static_configs:\n      - targets:\n          - localhost\n        labels:\n          job: syslog\n          __path__: /var/log/syslog\n\n  # Nginx access logs\n  - job_name: nginx\n    static_configs:\n      - targets:\n          - localhost\n        labels:\n          job: nginx\n          __path__: /var/log/nginx/*log\n\n    pipeline_stages:\n      - regex:\n          expression: '(?P&lt;remote_addr&gt;\\S+) - (?P&lt;remote_user&gt;\\S+) \\[(?P&lt;time_local&gt;[^\\]]+)\\] \"(?P&lt;method&gt;\\S+) (?P&lt;request_uri&gt;\\S+) (?P&lt;protocol&gt;\\S+)\" (?P&lt;status&gt;\\d+) (?P&lt;body_bytes_sent&gt;\\d+) \"(?P&lt;http_referer&gt;[^\"]*)\" \"(?P&lt;http_user_agent&gt;[^\"]*)\"'\n      - labels:\n          method:\n          status:\n          remote_addr:\n</code></pre>"},{"location":"deployment/observability-monitoring/#distributed-tracing","title":"Distributed Tracing","text":""},{"location":"deployment/observability-monitoring/#opentelemetry-configuration","title":"OpenTelemetry Configuration","text":""},{"location":"deployment/observability-monitoring/#backend-tracing-setup","title":"Backend Tracing Setup","text":"<pre><code>// Automatic instrumentation via Java agent\n// Add to Dockerfile:\n// COPY opentelemetry-javaagent.jar /app/\n// ENV JAVA_TOOL_OPTIONS=\"-javaagent:/app/opentelemetry-javaagent.jar\"\n\n// Manual instrumentation for custom spans\n@Service\npublic class OrderService {\n    private final Tracer tracer;\n\n    public OrderService() {\n        this.tracer = GlobalOpenTelemetry.getTracer(\"dealsphere-backend\");\n    }\n\n    @NewSpan(\"process_order\")\n    public Order processOrder(@SpanAttribute(\"order_id\") String orderId) {\n        Span span = tracer.spanBuilder(\"order.validation\")\n            .setSpanKind(SpanKind.INTERNAL)\n            .startSpan();\n\n        try (Scope scope = span.makeCurrent()) {\n            span.setStatus(StatusCode.OK);\n            span.addEvent(\"Order validation started\");\n\n            // Business logic here\n            validateOrder(orderId);\n\n            span.addEvent(\"Order validation completed\");\n            return processPayment(orderId);\n        } catch (Exception e) {\n            span.setStatus(StatusCode.ERROR, e.getMessage());\n            span.recordException(e);\n            throw e;\n        } finally {\n            span.end();\n        }\n    }\n}\n</code></pre>"},{"location":"deployment/observability-monitoring/#frontend-tracing-setup","title":"Frontend Tracing Setup","text":"<pre><code>// src/utils/tracing.js\nimport { WebTracerProvider } from '@opentelemetry/sdk-trace-web';\nimport { Resource } from '@opentelemetry/resources';\nimport { SemanticResourceAttributes } from '@opentelemetry/semantic-conventions';\nimport { BatchSpanProcessor } from '@opentelemetry/sdk-trace-base';\nimport { OTLPTraceExporter } from '@opentelemetry/exporter-otlp-http';\n\nconst provider = new WebTracerProvider({\n  resource: new Resource({\n    [SemanticResourceAttributes.SERVICE_NAME]: 'dealsphere-frontend',\n    [SemanticResourceAttributes.SERVICE_VERSION]: '1.0.0',\n  }),\n});\n\nconst exporter = new OTLPTraceExporter({\n  url: 'http://localhost:4318/v1/traces',\n});\n\nprovider.addSpanProcessor(new BatchSpanProcessor(exporter));\nprovider.register();\n\nexport const tracer = provider.getTracer('dealsphere-frontend');\n\n// Usage in React components\nexport const withTracing = (WrappedComponent, spanName) =&gt; {\n  return (props) =&gt; {\n    useEffect(() =&gt; {\n      const span = tracer.startSpan(spanName);\n      span.setAttributes({\n        'component.name': WrappedComponent.name,\n        'user.id': getCurrentUserId(),\n      });\n\n      return () =&gt; span.end();\n    }, []);\n\n    return &lt;WrappedComponent {...props} /&gt;;\n  };\n};\n\n// Track user interactions\nexport const trackUserAction = (action, metadata = {}) =&gt; {\n  const span = tracer.startSpan(`user.${action}`);\n  span.setAttributes({\n    'user.action': action,\n    'page.url': window.location.href,\n    ...metadata\n  });\n  span.end();\n};\n</code></pre>"},{"location":"deployment/observability-monitoring/#opentelemetry-collector-configuration","title":"OpenTelemetry Collector Configuration","text":"<pre><code># otel/otel-collector-config.yml\nreceivers:\n  otlp:\n    protocols:\n      grpc:\n        endpoint: 0.0.0.0:4317\n      http:\n        endpoint: 0.0.0.0:4318\n\nprocessors:\n  batch:\n  resource:\n    attributes:\n      - key: environment\n        value: ${ENVIRONMENT}\n        action: insert\n      - key: service.version\n        value: ${SERVICE_VERSION}\n        action: insert\n\nexporters:\n  # Traces to Jaeger\n  jaeger:\n    endpoint: jaeger:14250\n    tls:\n      insecure: true\n\n  # Metrics to Prometheus\n  prometheus:\n    endpoint: \"0.0.0.0:8889\"\n\n  # Logs to Loki\n  loki:\n    endpoint: http://loki:3100/loki/api/v1/push\n\nservice:\n  pipelines:\n    traces:\n      receivers: [otlp]\n      processors: [resource, batch]\n      exporters: [jaeger]\n\n    metrics:\n      receivers: [otlp]\n      processors: [resource, batch]\n      exporters: [prometheus]\n\n    logs:\n      receivers: [otlp]\n      processors: [resource, batch]\n      exporters: [loki]\n</code></pre>"},{"location":"deployment/observability-monitoring/#alerting-configuration","title":"Alerting Configuration","text":""},{"location":"deployment/observability-monitoring/#prometheus-alert-rules","title":"Prometheus Alert Rules","text":"<pre><code># prometheus/alert_rules.yml\ngroups:\n  - name: dealsphere.rules\n    rules:\n      # Application alerts\n      - alert: ApplicationDown\n        expr: up{job=\"dealsphere-backend\"} == 0\n        for: 1m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"DealSphere application is down\"\n          description: \"Application {{ $labels.instance }} has been down for more than 1 minute\"\n\n      - alert: HighErrorRate\n        expr: rate(http_server_requests_total{status=~\"5..\"}[5m]) / rate(http_server_requests_total[5m]) &gt; 0.1\n        for: 5m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"High error rate detected\"\n          description: \"Error rate is {{ $value | humanizePercentage }} for {{ $labels.instance }}\"\n\n      - alert: HighResponseTime\n        expr: histogram_quantile(0.95, rate(http_server_requests_seconds_bucket[5m])) &gt; 2\n        for: 10m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"High response time\"\n          description: \"95th percentile response time is {{ $value }}s for {{ $labels.instance }}\"\n\n      # Infrastructure alerts\n      - alert: HighCPUUsage\n        expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode=\"idle\"}[5m])) * 100) &gt; 80\n        for: 10m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"High CPU usage\"\n          description: \"CPU usage is {{ $value }}% on {{ $labels.instance }}\"\n\n      - alert: HighMemoryUsage\n        expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 &gt; 90\n        for: 5m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"High memory usage\"\n          description: \"Memory usage is {{ $value }}% on {{ $labels.instance }}\"\n\n      - alert: LowDiskSpace\n        expr: (1 - (node_filesystem_avail_bytes{fstype!=\"tmpfs\"} / node_filesystem_size_bytes)) * 100 &gt; 90\n        for: 5m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"Low disk space\"\n          description: \"Disk usage is {{ $value }}% on {{ $labels.instance }}\"\n\n      # Database alerts\n      - alert: DatabaseConnectionsHigh\n        expr: hikaricp_connections_active / hikaricp_connections_max &gt; 0.8\n        for: 5m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"High database connection usage\"\n          description: \"Database connection pool is {{ $value | humanizePercentage }} full\"\n\n      - alert: DatabaseSlowQueries\n        expr: rate(hikaricp_connections_timeout_total[5m]) &gt; 0.1\n        for: 5m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"Database connection timeouts\"\n          description: \"Database connection timeout rate: {{ $value }}/s\"\n\n      # Business metrics alerts\n      - alert: LowUserActivity\n        expr: rate(user_login_attempts_total[1h]) &lt; 10\n        for: 30m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"Low user activity\"\n          description: \"User login rate is {{ $value }}/hour\"\n</code></pre>"},{"location":"deployment/observability-monitoring/#alertmanager-configuration","title":"AlertManager Configuration","text":"<pre><code># alertmanager/alertmanager.yml\nglobal:\n  smtp_smarthost: '${SMTP_HOST}:587'\n  smtp_from: 'alerts@dealsphere.com'\n  smtp_auth_username: '${SMTP_USERNAME}'\n  smtp_auth_password: '${SMTP_PASSWORD}'\n\nroute:\n  group_by: ['alertname', 'cluster', 'service']\n  group_wait: 10s\n  group_interval: 10s\n  repeat_interval: 1h\n  receiver: 'default'\n  routes:\n    - match:\n        severity: critical\n      receiver: 'critical-alerts'\n    - match:\n        severity: warning\n      receiver: 'warning-alerts'\n\nreceivers:\n  - name: 'default'\n    email_configs:\n      - to: 'devops@dealsphere.com'\n        subject: 'DealSphere Alert: {{ .GroupLabels.alertname }}'\n        body: |\n          {{ range .Alerts }}\n          Alert: {{ .Annotations.summary }}\n          Description: {{ .Annotations.description }}\n          Instance: {{ .Labels.instance }}\n          Severity: {{ .Labels.severity }}\n          {{ end }}\n\n  - name: 'critical-alerts'\n    email_configs:\n      - to: 'oncall@dealsphere.com'\n        subject: '\ud83d\udea8 CRITICAL: {{ .GroupLabels.alertname }}'\n    slack_configs:\n      - api_url: '${SLACK_WEBHOOK_URL}'\n        channel: '#alerts-critical'\n        title: '\ud83d\udea8 Critical Alert'\n        text: |\n          {{ range .Alerts }}\n          *{{ .Annotations.summary }}*\n          {{ .Annotations.description }}\n          {{ end }}\n\n  - name: 'warning-alerts'\n    email_configs:\n      - to: 'devops@dealsphere.com'\n        subject: '\u26a0\ufe0f WARNING: {{ .GroupLabels.alertname }}'\n    slack_configs:\n      - api_url: '${SLACK_WEBHOOK_URL}'\n        channel: '#alerts-warning'\n        title: '\u26a0\ufe0f Warning Alert'\n        text: |\n          {{ range .Alerts }}\n          *{{ .Annotations.summary }}*\n          {{ .Annotations.description }}\n          {{ end }}\n\ninhibit_rules:\n  - source_match:\n      severity: 'critical'\n    target_match:\n      severity: 'warning'\n    equal: ['alertname', 'instance']\n</code></pre>"},{"location":"deployment/observability-monitoring/#grafana-dashboards","title":"Grafana Dashboards","text":""},{"location":"deployment/observability-monitoring/#application-dashboard-configuration","title":"Application Dashboard Configuration","text":"<pre><code>{\n  \"dashboard\": {\n    \"id\": null,\n    \"title\": \"DealSphere Application Overview\",\n    \"tags\": [\"dealsphere\", \"application\"],\n    \"timezone\": \"browser\",\n    \"panels\": [\n      {\n        \"title\": \"Request Rate\",\n        \"type\": \"graph\",\n        \"targets\": [\n          {\n            \"expr\": \"rate(http_server_requests_total[5m])\",\n            \"legendFormat\": \"{{ instance }} - {{ method }} {{ uri }}\"\n          }\n        ]\n      },\n      {\n        \"title\": \"Response Time (95th percentile)\",\n        \"type\": \"graph\",\n        \"targets\": [\n          {\n            \"expr\": \"histogram_quantile(0.95, rate(http_server_requests_seconds_bucket[5m]))\",\n            \"legendFormat\": \"{{ instance }}\"\n          }\n        ]\n      },\n      {\n        \"title\": \"Error Rate\",\n        \"type\": \"graph\",\n        \"targets\": [\n          {\n            \"expr\": \"rate(http_server_requests_total{status=~\\\"5..\\\"}[5m]) / rate(http_server_requests_total[5m])\",\n            \"legendFormat\": \"{{ instance }}\"\n          }\n        ]\n      },\n      {\n        \"title\": \"Active Database Connections\",\n        \"type\": \"graph\",\n        \"targets\": [\n          {\n            \"expr\": \"hikaricp_connections_active\",\n            \"legendFormat\": \"Active Connections\"\n          },\n          {\n            \"expr\": \"hikaricp_connections_max\",\n            \"legendFormat\": \"Max Connections\"\n          }\n        ]\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"deployment/observability-monitoring/#infrastructure-dashboard","title":"Infrastructure Dashboard","text":"<p>Key panels for infrastructure monitoring:</p> <ul> <li>System Overview: CPU, Memory, Disk usage across all hosts</li> <li>Network: Network I/O, connections, packet loss</li> <li>Container Metrics: Docker container resource usage</li> <li>Database Performance: Query times, connection pools, locks</li> <li>Application JVM: Heap usage, GC performance, thread counts</li> </ul>"},{"location":"deployment/observability-monitoring/#performance-monitoring","title":"Performance Monitoring","text":""},{"location":"deployment/observability-monitoring/#slaslo-tracking","title":"SLA/SLO Tracking","text":"<pre><code># Service Level Objectives\nslos:\n  availability:\n    target: 99.9%\n    measurement: up{job=\"dealsphere-backend\"}\n\n  response_time:\n    target: 95% &lt; 2s\n    measurement: histogram_quantile(0.95, rate(http_server_requests_seconds_bucket[5m]))\n\n  error_rate:\n    target: &lt; 1%\n    measurement: rate(http_server_requests_total{status=~\"5..\"}[5m]) / rate(http_server_requests_total[5m])\n</code></pre>"},{"location":"deployment/observability-monitoring/#capacity-planning-queries","title":"Capacity Planning Queries","text":"<pre><code># CPU utilization trend\navg_over_time(100 - (avg by(instance) (irate(node_cpu_seconds_total{mode=\"idle\"}[5m])) * 100)[7d:1h])\n\n# Memory usage growth\nincrease(node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes[7d])\n\n# Request volume projection\npredict_linear(rate(http_server_requests_total[1h])[7d:1h], 7*24*3600)\n\n# Database connection pool utilization\navg_over_time((hikaricp_connections_active / hikaricp_connections_max)[7d:1h])\n</code></pre>"},{"location":"deployment/observability-monitoring/#security-monitoring","title":"Security Monitoring","text":""},{"location":"deployment/observability-monitoring/#security-metrics","title":"Security Metrics","text":"<pre><code>// Track security events\n@Component\npublic class SecurityMetrics {\n    private final Counter failedLogins;\n    private final Counter suspiciousActivity;\n    private final Timer authenticationTime;\n\n    public SecurityMetrics(MeterRegistry registry) {\n        this.failedLogins = Counter.builder(\"security.login.failed\")\n            .description(\"Failed login attempts\")\n            .tag(\"type\", \"authentication\")\n            .register(registry);\n\n        this.suspiciousActivity = Counter.builder(\"security.suspicious.activity\")\n            .description(\"Suspicious user activity detected\")\n            .register(registry);\n\n        this.authenticationTime = Timer.builder(\"security.authentication.time\")\n            .description(\"Time taken for authentication\")\n            .register(registry);\n    }\n}\n</code></pre>"},{"location":"deployment/observability-monitoring/#security-alerts","title":"Security Alerts","text":"<pre><code># Security-focused alert rules\n- alert: HighFailedLoginRate\n  expr: rate(security_login_failed_total[5m]) &gt; 10\n  for: 2m\n  labels:\n    severity: warning\n  annotations:\n    summary: \"High failed login rate detected\"\n\n- alert: SuspiciousActivity\n  expr: increase(security_suspicious_activity_total[5m]) &gt; 5\n  for: 1m\n  labels:\n    severity: critical\n  annotations:\n    summary: \"Suspicious user activity detected\"\n</code></pre>"},{"location":"deployment/observability-monitoring/#troubleshooting","title":"Troubleshooting","text":""},{"location":"deployment/observability-monitoring/#common-issues","title":"Common Issues","text":"<p>No Metrics Appearing</p> <pre><code># Check application health\ncurl http://localhost:8080/actuator/health\n\n# Verify Prometheus targets\ncurl http://localhost:9090/api/v1/targets\n\n# Check network connectivity\ndocker compose -f docker-compose.monitoring.yml logs prometheus\n</code></pre> <p>Missing Traces</p> <pre><code># Verify OpenTelemetry configuration\ncurl http://localhost:4318/v1/traces\n\n# Check sampling configuration\necho \"OTEL_TRACES_SAMPLER=always_on\" &gt;&gt; .env\n\n# Inspect Jaeger\ncurl http://localhost:16686/api/services\n</code></pre> <p>High Resource Usage</p> <pre><code># Adjust retention policies\n# Edit prometheus/prometheus.yml\nretention.time: 15d\nretention.size: 5GB\n\n# Reduce scrape intervals\nscrape_interval: 30s\n</code></pre> <p>This comprehensive observability setup provides enterprise-grade monitoring capabilities, enabling proactive issue detection and performance optimization for the DealSphere platform.</p>"},{"location":"deployment/production-deployment/","title":"Production Deployment Guide","text":"<p>This guide provides step-by-step instructions for deploying the DealSphere platform to production environments.</p>"},{"location":"deployment/production-deployment/#overview","title":"Overview","text":"<p>The DealSphere production deployment consists of:</p> <ul> <li>Backend: Spring Boot application with PostgreSQL database</li> <li>Frontend: React application served via nginx</li> <li>Observability: Prometheus, Grafana, Loki, Jaeger stack</li> <li>Infrastructure: Containerized services with Docker/Kubernetes</li> <li>Security: SSL/TLS, secrets management, network security</li> </ul>"},{"location":"deployment/production-deployment/#prerequisites","title":"Prerequisites","text":""},{"location":"deployment/production-deployment/#infrastructure-requirements","title":"Infrastructure Requirements","text":"<p>Minimum Production Specifications:</p> <pre><code>Backend Service:\n- CPU: 2 vCPUs\n- RAM: 4GB\n- Storage: 50GB SSD\n\nDatabase (PostgreSQL):\n- CPU: 2 vCPUs\n- RAM: 4GB\n- Storage: 100GB SSD (with backup)\n\nFrontend/Nginx:\n- CPU: 1 vCPU\n- RAM: 1GB\n- Storage: 20GB SSD\n\nMonitoring Stack:\n- CPU: 2 vCPUs\n- RAM: 4GB\n- Storage: 100GB SSD\n</code></pre> <p>Recommended Production Specifications:</p> <pre><code>Backend Service:\n- CPU: 4 vCPUs\n- RAM: 8GB\n- Storage: 100GB SSD\n\nDatabase (PostgreSQL):\n- CPU: 4 vCPUs\n- RAM: 8GB\n- Storage: 500GB SSD (with automated backup)\n\nLoad Balancer/Frontend:\n- CPU: 2 vCPUs\n- RAM: 2GB\n- Storage: 50GB SSD\n\nMonitoring Stack:\n- CPU: 4 vCPUs\n- RAM: 8GB\n- Storage: 200GB SSD\n</code></pre>"},{"location":"deployment/production-deployment/#software-requirements","title":"Software Requirements","text":"<ul> <li>Docker: 24.0+</li> <li>Docker Compose: 2.20+</li> <li>Domain: Registered domain with DNS control</li> <li>SSL Certificate: Valid SSL certificate (Let's Encrypt recommended)</li> </ul>"},{"location":"deployment/production-deployment/#deployment-methods","title":"Deployment Methods","text":""},{"location":"deployment/production-deployment/#method-1-docker-compose-recommended-for-small-teams","title":"Method 1: Docker Compose (Recommended for Small Teams)","text":""},{"location":"deployment/production-deployment/#1-server-preparation","title":"1. Server Preparation","text":"<pre><code># Update system packages\nsudo apt update &amp;&amp; sudo apt upgrade -y\n\n# Install Docker\ncurl -fsSL https://get.docker.com -o get-docker.sh\nsh get-docker.sh\nsudo usermod -aG docker $USER\n\n# Install Docker Compose\nsudo curl -L \"https://github.com/docker/compose/releases/download/v2.20.0/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose\nsudo chmod +x /usr/local/bin/docker-compose\n\n# Reboot to apply group changes\nsudo reboot\n</code></pre>"},{"location":"deployment/production-deployment/#2-application-deployment","title":"2. Application Deployment","text":"<pre><code># Clone the repository\ngit clone https://github.com/your-org/dealsphere-platform.git\ncd dealsphere-platform\n\n# Create production environment file\ncp .env.production .env\n\n# Edit environment variables (see Environment Configuration section)\nnano .env\n\n# Pull latest images\ndocker compose pull\n\n# Start the application stack\ndocker compose -f docker-compose.yml up -d\n\n# Verify deployment\ndocker compose ps\ndocker compose logs -f backend\n</code></pre>"},{"location":"deployment/production-deployment/#3-database-setup","title":"3. Database Setup","text":"<pre><code># Check database initialization\ndocker compose exec backend ./gradlew flyway:info\n\n# Run database migrations (if needed)\ndocker compose exec backend ./gradlew flyway:migrate\n\n# Verify database connection\ndocker compose exec db psql -U $POSTGRES_USER -d $POSTGRES_DB -c \"SELECT version();\"\n</code></pre>"},{"location":"deployment/production-deployment/#method-2-kubernetes-recommended-for-scalability","title":"Method 2: Kubernetes (Recommended for Scalability)","text":""},{"location":"deployment/production-deployment/#1-kubernetes-manifests","title":"1. Kubernetes Manifests","text":"<p>Create Kubernetes deployment files:</p> <pre><code># k8s/namespace.yaml\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: dealsphere-prod\n---\n# k8s/backend-deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: dealsphere-backend\n  namespace: dealsphere-prod\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: dealsphere-backend\n  template:\n    metadata:\n      labels:\n        app: dealsphere-backend\n    spec:\n      containers:\n      - name: backend\n        image: your-registry/dealsphere-backend:latest\n        ports:\n        - containerPort: 8080\n        env:\n        - name: SPRING_PROFILES_ACTIVE\n          value: \"production\"\n        - name: POSTGRES_URL\n          valueFrom:\n            secretKeyRef:\n              name: database-secret\n              key: url\n        resources:\n          requests:\n            memory: \"2Gi\"\n            cpu: \"1000m\"\n          limits:\n            memory: \"4Gi\"\n            cpu: \"2000m\"\n        readinessProbe:\n          httpGet:\n            path: /actuator/health\n            port: 8080\n          initialDelaySeconds: 30\n          periodSeconds: 10\n        livenessProbe:\n          httpGet:\n            path: /actuator/health\n            port: 8080\n          initialDelaySeconds: 60\n          periodSeconds: 30\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: dealsphere-backend-service\n  namespace: dealsphere-prod\nspec:\n  selector:\n    app: dealsphere-backend\n  ports:\n  - protocol: TCP\n    port: 80\n    targetPort: 8080\n  type: ClusterIP\n</code></pre>"},{"location":"deployment/production-deployment/#2-deploy-to-kubernetes","title":"2. Deploy to Kubernetes","text":"<pre><code># Apply Kubernetes manifests\nkubectl apply -f k8s/\n\n# Check deployment status\nkubectl get pods -n dealsphere-prod\nkubectl get services -n dealsphere-prod\n\n# View logs\nkubectl logs -f deployment/dealsphere-backend -n dealsphere-prod\n</code></pre>"},{"location":"deployment/production-deployment/#environment-configuration","title":"Environment Configuration","text":""},{"location":"deployment/production-deployment/#production-environment-variables","title":"Production Environment Variables","text":"<p>Create <code>.env.production</code>:</p> <pre><code># === Database Configuration ===\nPOSTGRES_DB=dealsphere_prod\nPOSTGRES_USER=dealsphere_prod\nPOSTGRES_PASSWORD=your-secure-db-password\nPOSTGRES_HOST=your-db-host.amazonaws.com\nPOSTGRES_PORT=5432\n\n# === Application Configuration ===\nSPRING_PROFILES_ACTIVE=production\nSERVER_PORT=8080\nSPRING_JPA_HIBERNATE_DDL_AUTO=validate\n\n# === Security Configuration ===\nJWT_SECRET=your-256-bit-jwt-secret-key-here\nJWT_EXPIRATION_HOURS=24\nSSL_ENABLED=true\n\n# === Frontend Configuration ===\nVITE_API_URL=https://api.yourdomain.com\nVITE_GRAPHQL_URL=https://api.yourdomain.com/graphql\nVITE_ENV=production\n\n# === CORS Configuration ===\nCORS_ALLOWED_ORIGINS=https://yourdomain.com,https://www.yourdomain.com\nCORS_ALLOWED_METHODS=GET,POST,OPTIONS,PUT,DELETE\nCORS_ALLOWED_HEADERS=*\nCORS_ALLOW_CREDENTIALS=true\n\n# === Logging Configuration ===\nLOGGING_LEVEL_ROOT=WARN\nLOGGING_LEVEL_COM_DEALSPHERE=INFO\n\n# === Monitoring Configuration ===\nMANAGEMENT_ENDPOINTS_WEB_EXPOSURE_INCLUDE=health,metrics,prometheus,info\nMANAGEMENT_ENDPOINT_HEALTH_SHOW_DETAILS=when-authorized\n\n# === Email Configuration (Optional) ===\nSPRING_MAIL_HOST=smtp.yourdomain.com\nSPRING_MAIL_PORT=587\nSPRING_MAIL_USERNAME=noreply@yourdomain.com\nSPRING_MAIL_PASSWORD=your-email-password\nSPRING_MAIL_PROPERTIES_MAIL_SMTP_AUTH=true\nSPRING_MAIL_PROPERTIES_MAIL_SMTP_STARTTLS_ENABLE=true\n</code></pre>"},{"location":"deployment/production-deployment/#ssltls-configuration","title":"SSL/TLS Configuration","text":""},{"location":"deployment/production-deployment/#option-1-lets-encrypt-with-certbot","title":"Option 1: Let's Encrypt with Certbot","text":"<pre><code># Install Certbot\nsudo apt install certbot python3-certbot-nginx\n\n# Obtain SSL certificate\nsudo certbot --nginx -d yourdomain.com -d www.yourdomain.com\n\n# Verify auto-renewal\nsudo certbot renew --dry-run\n</code></pre>"},{"location":"deployment/production-deployment/#option-2-custom-ssl-certificate","title":"Option 2: Custom SSL Certificate","text":"<pre><code># Create SSL directory\nsudo mkdir -p /etc/ssl/dealsphere\n\n# Copy your certificate files\nsudo cp your-domain.crt /etc/ssl/dealsphere/\nsudo cp your-domain.key /etc/ssl/dealsphere/\nsudo cp ca-bundle.crt /etc/ssl/dealsphere/\n\n# Set proper permissions\nsudo chmod 600 /etc/ssl/dealsphere/*.key\nsudo chmod 644 /etc/ssl/dealsphere/*.crt\n</code></pre>"},{"location":"deployment/production-deployment/#nginx-ssl-configuration","title":"Nginx SSL Configuration","text":"<pre><code># /etc/nginx/sites-available/dealsphere\nserver {\n    listen 80;\n    server_name yourdomain.com www.yourdomain.com;\n    return 301 https://$server_name$request_uri;\n}\n\nserver {\n    listen 443 ssl http2;\n    server_name yourdomain.com www.yourdomain.com;\n\n    ssl_certificate /etc/ssl/dealsphere/your-domain.crt;\n    ssl_certificate_key /etc/ssl/dealsphere/your-domain.key;\n\n    ssl_protocols TLSv1.2 TLSv1.3;\n    ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512;\n    ssl_prefer_server_ciphers off;\n    ssl_session_cache shared:SSL:10m;\n    ssl_session_timeout 10m;\n\n    # Security headers\n    add_header Strict-Transport-Security \"max-age=63072000\" always;\n    add_header X-Content-Type-Options \"nosniff\" always;\n    add_header X-Frame-Options \"DENY\" always;\n    add_header X-XSS-Protection \"1; mode=block\" always;\n\n    location / {\n        proxy_pass http://frontend:3000;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n    }\n\n    location /api/ {\n        proxy_pass http://backend:8080/;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n    }\n}\n</code></pre>"},{"location":"deployment/production-deployment/#database-management","title":"Database Management","text":""},{"location":"deployment/production-deployment/#production-database-setup","title":"Production Database Setup","text":""},{"location":"deployment/production-deployment/#postgresql-production-configuration","title":"PostgreSQL Production Configuration","text":"<pre><code>-- Create production database and user\nCREATE DATABASE dealsphere_prod;\nCREATE USER dealsphere_prod WITH ENCRYPTED PASSWORD 'your-secure-password';\nGRANT ALL PRIVILEGES ON DATABASE dealsphere_prod TO dealsphere_prod;\nGRANT ALL ON SCHEMA public TO dealsphere_prod;\n</code></pre>"},{"location":"deployment/production-deployment/#database-migration-strategy","title":"Database Migration Strategy","text":"<pre><code># 1. Backup current database (if updating)\npg_dump -h your-db-host -U dealsphere_prod dealsphere_prod &gt; backup_$(date +%Y%m%d_%H%M%S).sql\n\n# 2. Test migrations on staging first\ndocker compose -f docker-compose.staging.yml exec backend ./gradlew flyway:info\ndocker compose -f docker-compose.staging.yml exec backend ./gradlew flyway:migrate\n\n# 3. Apply to production (during maintenance window)\ndocker compose exec backend ./gradlew flyway:migrate\n\n# 4. Verify migration success\ndocker compose exec backend ./gradlew flyway:info\n</code></pre>"},{"location":"deployment/production-deployment/#database-backup-strategy","title":"Database Backup Strategy","text":"<pre><code># Create backup script\ncat &gt; /scripts/backup-dealsphere.sh &lt;&lt; 'EOF'\n#!/bin/bash\nBACKUP_DIR=\"/backups/dealsphere\"\nTIMESTAMP=$(date +%Y%m%d_%H%M%S)\nBACKUP_FILE=\"dealsphere_prod_backup_${TIMESTAMP}.sql\"\n\nmkdir -p $BACKUP_DIR\n\n# Create backup\npg_dump -h your-db-host -U dealsphere_prod dealsphere_prod &gt; $BACKUP_DIR/$BACKUP_FILE\n\n# Compress backup\ngzip $BACKUP_DIR/$BACKUP_FILE\n\n# Keep only last 30 days of backups\nfind $BACKUP_DIR -name \"*.sql.gz\" -mtime +30 -delete\n\necho \"Backup completed: $BACKUP_FILE.gz\"\nEOF\n\nchmod +x /scripts/backup-dealsphere.sh\n\n# Schedule daily backups\necho \"0 2 * * * /scripts/backup-dealsphere.sh\" | sudo crontab -\n</code></pre>"},{"location":"deployment/production-deployment/#health-checks-and-monitoring","title":"Health Checks and Monitoring","text":""},{"location":"deployment/production-deployment/#application-health-endpoints","title":"Application Health Endpoints","text":"<pre><code># Check application health\ncurl -f https://yourdomain.com/api/actuator/health\n\n# Check detailed health information\ncurl -f https://yourdomain.com/api/actuator/health/db\ncurl -f https://yourdomain.com/api/actuator/health/diskSpace\n\n# Check metrics\ncurl -f https://yourdomain.com/api/actuator/metrics\ncurl -f https://yourdomain.com/api/actuator/prometheus\n</code></pre>"},{"location":"deployment/production-deployment/#production-monitoring-setup","title":"Production Monitoring Setup","text":"<pre><code># Start monitoring stack\ncd monitoring\ndocker compose -f docker-compose.monitoring.yml up -d\n\n# Configure alerts for production\n# See: observability-monitoring.md for detailed setup\n</code></pre>"},{"location":"deployment/production-deployment/#load-balancer-health-checks","title":"Load Balancer Health Checks","text":"<p>Configure your load balancer health checks: - Health Check URL: <code>https://yourdomain.com/api/actuator/health</code> - Interval: 30 seconds - Timeout: 10 seconds - Healthy Threshold: 2 consecutive successes - Unhealthy Threshold: 3 consecutive failures</p>"},{"location":"deployment/production-deployment/#scaling-and-performance","title":"Scaling and Performance","text":""},{"location":"deployment/production-deployment/#horizontal-scaling","title":"Horizontal Scaling","text":""},{"location":"deployment/production-deployment/#docker-compose-scaling","title":"Docker Compose Scaling","text":"<pre><code># Scale backend service\ndocker compose up -d --scale backend=3\n\n# Use nginx load balancing\n# Update nginx.conf:\nupstream backend {\n    server backend_1:8080;\n    server backend_2:8080;\n    server backend_3:8080;\n}\n</code></pre>"},{"location":"deployment/production-deployment/#kubernetes-scaling","title":"Kubernetes Scaling","text":"<pre><code># Scale deployment\nkubectl scale deployment dealsphere-backend --replicas=5 -n dealsphere-prod\n\n# Auto-scaling configuration\nkubectl apply -f - &lt;&lt;EOF\napiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: dealsphere-backend-hpa\n  namespace: dealsphere-prod\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: dealsphere-backend\n  minReplicas: 2\n  maxReplicas: 10\n  metrics:\n  - type: Resource\n    resource:\n      name: cpu\n      target:\n        type: Utilization\n        averageUtilization: 70\nEOF\n</code></pre>"},{"location":"deployment/production-deployment/#performance-optimization","title":"Performance Optimization","text":""},{"location":"deployment/production-deployment/#jvm-tuning","title":"JVM Tuning","text":"<pre><code># Production JVM settings\nJAVA_OPTS=\"-Xms2g -Xmx4g \\\n-XX:+UseG1GC \\\n-XX:MaxGCPauseMillis=200 \\\n-XX:+HeapDumpOnOutOfMemoryError \\\n-XX:HeapDumpPath=/tmp/heapdump.hprof \\\n-Djava.security.egd=file:/dev/./urandom\"\n</code></pre>"},{"location":"deployment/production-deployment/#database-performance","title":"Database Performance","text":"<pre><code>-- PostgreSQL performance tuning\nALTER SYSTEM SET shared_buffers = '256MB';\nALTER SYSTEM SET effective_cache_size = '1GB';\nALTER SYSTEM SET maintenance_work_mem = '64MB';\nALTER SYSTEM SET checkpoint_completion_target = 0.7;\nALTER SYSTEM SET wal_buffers = '16MB';\nALTER SYSTEM SET default_statistics_target = 100;\nALTER SYSTEM SET random_page_cost = 1.1;\nALTER SYSTEM SET effective_io_concurrency = 200;\n\n-- Reload configuration\nSELECT pg_reload_conf();\n</code></pre>"},{"location":"deployment/production-deployment/#disaster-recovery","title":"Disaster Recovery","text":""},{"location":"deployment/production-deployment/#backup-strategy","title":"Backup Strategy","text":"<p>Automated Backups: - Database: Daily full backup + continuous WAL archiving - Application Data: Weekly backup of uploaded files - Configuration: Version-controlled infrastructure as code</p> <p>Backup Locations: - Primary: Local server storage - Secondary: Cloud storage (S3, GCS, Azure Blob) - Tertiary: Geographic backup location</p>"},{"location":"deployment/production-deployment/#recovery-procedures","title":"Recovery Procedures","text":""},{"location":"deployment/production-deployment/#database-recovery","title":"Database Recovery","text":"<pre><code># Stop application\ndocker compose stop backend\n\n# Restore database from backup\ngunzip -c /backups/dealsphere/dealsphere_prod_backup_20231215_020000.sql.gz | \\\n  psql -h your-db-host -U dealsphere_prod dealsphere_prod\n\n# Restart application\ndocker compose start backend\n\n# Verify recovery\ncurl -f https://yourdomain.com/api/actuator/health\n</code></pre>"},{"location":"deployment/production-deployment/#full-system-recovery","title":"Full System Recovery","text":"<pre><code># 1. Provision new infrastructure\n# 2. Restore application code\ngit clone https://github.com/your-org/dealsphere-platform.git\n\n# 3. Restore configuration\ncp /backups/config/.env.production .env\n\n# 4. Restore database\n# (See database recovery above)\n\n# 5. Deploy application\ndocker compose -f docker-compose.yml up -d\n\n# 6. Verify all services\n./scripts/health-check.sh\n</code></pre>"},{"location":"deployment/production-deployment/#security-hardening","title":"Security Hardening","text":""},{"location":"deployment/production-deployment/#server-security","title":"Server Security","text":"<pre><code># Update system packages\nsudo apt update &amp;&amp; sudo apt upgrade -y\n\n# Configure firewall\nsudo ufw default deny incoming\nsudo ufw default allow outgoing\nsudo ufw allow ssh\nsudo ufw allow 80/tcp\nsudo ufw allow 443/tcp\nsudo ufw --force enable\n\n# Disable root login\nsudo sed -i 's/PermitRootLogin yes/PermitRootLogin no/' /etc/ssh/sshd_config\nsudo systemctl reload sshd\n\n# Install fail2ban\nsudo apt install fail2ban\nsudo systemctl enable fail2ban\nsudo systemctl start fail2ban\n</code></pre>"},{"location":"deployment/production-deployment/#application-security","title":"Application Security","text":"<ul> <li>Secrets Management: Use environment variables, never commit secrets</li> <li>Input Validation: All user inputs validated and sanitized</li> <li>Authentication: JWT tokens with proper expiration</li> <li>Authorization: Role-based access control (RBAC)</li> <li>HTTPS: All communication encrypted with TLS 1.2+</li> <li>Security Headers: HSTS, X-Frame-Options, CSP implemented</li> </ul>"},{"location":"deployment/production-deployment/#network-security","title":"Network Security","text":"<pre><code># Docker network isolation\ndocker network create --driver bridge dealsphere-network\n\n# Configure iptables rules (example)\nsudo iptables -A INPUT -p tcp --dport 8080 -s 10.0.0.0/8 -j ACCEPT\nsudo iptables -A INPUT -p tcp --dport 8080 -j DROP\n</code></pre>"},{"location":"deployment/production-deployment/#troubleshooting","title":"Troubleshooting","text":""},{"location":"deployment/production-deployment/#common-production-issues","title":"Common Production Issues","text":""},{"location":"deployment/production-deployment/#application-wont-start","title":"Application Won't Start","text":"<pre><code># Check container logs\ndocker compose logs backend\ndocker compose logs frontend\ndocker compose logs db\n\n# Check resource usage\ndocker stats\n\n# Check disk space\ndf -h\n\n# Check memory usage\nfree -h\n\n# Check application health\ncurl -f https://yourdomain.com/api/actuator/health\n</code></pre>"},{"location":"deployment/production-deployment/#database-connection-issues","title":"Database Connection Issues","text":"<pre><code># Test database connectivity\ndocker compose exec backend ping db\ndocker compose exec backend nc -zv db 5432\n\n# Check database logs\ndocker compose logs db\n\n# Verify database credentials\ndocker compose exec backend env | grep POSTGRES\n</code></pre>"},{"location":"deployment/production-deployment/#high-memory-usage","title":"High Memory Usage","text":"<pre><code># Monitor JVM memory\ncurl -s https://yourdomain.com/api/actuator/metrics/jvm.memory.used | jq .\n\n# Generate heap dump\ndocker compose exec backend kill -3 1\n\n# Analyze garbage collection\ncurl -s https://yourdomain.com/api/actuator/metrics/jvm.gc.pause | jq .\n</code></pre>"},{"location":"deployment/production-deployment/#ssl-certificate-issues","title":"SSL Certificate Issues","text":"<pre><code># Check certificate expiration\nopenssl s_client -connect yourdomain.com:443 -servername yourdomain.com 2&gt;/dev/null | \\\n  openssl x509 -noout -dates\n\n# Renew Let's Encrypt certificate\nsudo certbot renew --force-renewal\n\n# Test SSL configuration\ncurl -I https://yourdomain.com\n</code></pre>"},{"location":"deployment/production-deployment/#performance-issues","title":"Performance Issues","text":""},{"location":"deployment/production-deployment/#high-cpu-usage","title":"High CPU Usage","text":"<pre><code># Monitor CPU usage\ndocker stats\n\n# Check for long-running queries\ndocker compose exec db psql -U $POSTGRES_USER -d $POSTGRES_DB -c \"\n  SELECT pid, now() - pg_stat_activity.query_start AS duration, query\n  FROM pg_stat_activity\n  WHERE (now() - pg_stat_activity.query_start) &gt; interval '5 minutes';\n\"\n\n# Profile application\ncurl -s https://yourdomain.com/api/actuator/metrics/process.cpu.usage | jq .\n</code></pre>"},{"location":"deployment/production-deployment/#high-response-times","title":"High Response Times","text":"<pre><code># Check response times\ncurl -w \"@curl-format.txt\" -o /dev/null -s https://yourdomain.com/api/health\n\n# Monitor database performance\ndocker compose exec db psql -U $POSTGRES_USER -d $POSTGRES_DB -c \"\n  SELECT query, mean_time, calls\n  FROM pg_stat_statements\n  ORDER BY mean_time DESC\n  LIMIT 10;\n\"\n\n# Check for thread pool exhaustion\ncurl -s https://yourdomain.com/api/actuator/metrics/http.server.requests | jq .\n</code></pre>"},{"location":"deployment/production-deployment/#maintenance","title":"Maintenance","text":""},{"location":"deployment/production-deployment/#regular-maintenance-tasks","title":"Regular Maintenance Tasks","text":"<p>Daily: - Monitor application logs - Check system resource usage - Verify backup completion - Review security alerts</p> <p>Weekly: - Update system packages - Review application metrics - Test disaster recovery procedures - Clean up old log files</p> <p>Monthly: - Update application dependencies - Review and rotate secrets - Performance optimization analysis - Security vulnerability scanning</p>"},{"location":"deployment/production-deployment/#maintenance-windows","title":"Maintenance Windows","text":"<pre><code># Create maintenance script\ncat &gt; /scripts/maintenance.sh &lt;&lt; 'EOF'\n#!/bin/bash\necho \"Starting maintenance window...\"\n\n# 1. Enable maintenance mode\ndocker compose exec nginx cp /etc/nginx/maintenance.html /usr/share/nginx/html/index.html\n\n# 2. Graceful shutdown\ndocker compose stop backend\nsleep 30\n\n# 3. Backup database\n/scripts/backup-dealsphere.sh\n\n# 4. Update application\ngit pull origin main\ndocker compose pull\n\n# 5. Database migrations\ndocker compose up -d db\nsleep 30\ndocker compose run --rm backend ./gradlew flyway:migrate\n\n# 6. Start application\ndocker compose up -d\n\n# 7. Health checks\nsleep 60\ncurl -f https://yourdomain.com/api/actuator/health || exit 1\n\n# 8. Disable maintenance mode\ndocker compose exec nginx cp /etc/nginx/index.html /usr/share/nginx/html/index.html\n\necho \"Maintenance window completed successfully\"\nEOF\n\nchmod +x /scripts/maintenance.sh\n</code></pre>"},{"location":"deployment/production-deployment/#related-documentation","title":"Related Documentation","text":"<ul> <li>Cloud Infrastructure Setup</li> <li>Environment Management</li> <li>Observability and Monitoring</li> <li>Security and Secrets Management</li> <li>Local CI/CD Setup</li> <li>GitHub Actions</li> </ul>"},{"location":"deployment/security-secrets/","title":"Security and Secrets Management","text":"<p>This guide covers comprehensive security practices for DealSphere, including data encryption, secrets management, access controls, and security monitoring for both data at rest and in transit.</p>"},{"location":"deployment/security-secrets/#overview","title":"Overview","text":"<p>DealSphere implements defense-in-depth security principles with multiple layers of protection:</p> <ul> <li>Data Encryption: End-to-end encryption for data at rest and in transit</li> <li>Secrets Management: Centralized and secure handling of sensitive configuration</li> <li>Access Controls: Role-based authentication and authorization</li> <li>Network Security: TLS/SSL, VPNs, and network segmentation</li> <li>Security Monitoring: Real-time threat detection and audit logging</li> <li>Compliance: GDPR, SOC 2, and industry best practices</li> </ul>"},{"location":"deployment/security-secrets/#data-security","title":"Data Security","text":""},{"location":"deployment/security-secrets/#data-at-rest-encryption","title":"Data at Rest Encryption","text":""},{"location":"deployment/security-secrets/#database-encryption","title":"Database Encryption","text":"<p>PostgreSQL Transparent Data Encryption (TDE)</p> <pre><code>-- Enable encryption at database level\nCREATE DATABASE dealsphere_prod WITH ENCRYPTION;\n\n-- Column-level encryption for sensitive data\nCREATE TABLE user_credentials (\n    id UUID PRIMARY KEY,\n    email VARCHAR(255) NOT NULL,\n    password_hash VARCHAR(255) NOT NULL,\n    -- Encrypted sensitive fields\n    ssn_encrypted BYTEA,  -- Encrypted SSN\n    payment_info_encrypted BYTEA,  -- Encrypted payment info\n    created_at TIMESTAMP DEFAULT NOW(),\n    updated_at TIMESTAMP DEFAULT NOW()\n);\n\n-- Application-level encryption functions\nCREATE OR REPLACE FUNCTION encrypt_sensitive_data(plain_text TEXT, encryption_key TEXT)\nRETURNS BYTEA AS $$\nBEGIN\n    RETURN pgp_sym_encrypt(plain_text, encryption_key);\nEND;\n$$ LANGUAGE plpgsql;\n\nCREATE OR REPLACE FUNCTION decrypt_sensitive_data(encrypted_data BYTEA, encryption_key TEXT)\nRETURNS TEXT AS $$\nBEGIN\n    RETURN pgp_sym_decrypt(encrypted_data, encryption_key);\nEND;\n$$ LANGUAGE plpgsql;\n</code></pre> <p>AWS RDS Encryption</p> <pre><code># terraform/rds.tf\nresource \"aws_db_instance\" \"dealsphere_prod\" {\n  identifier = \"dealsphere-prod-db\"\n\n  # Encryption configuration\n  storage_encrypted = true\n  kms_key_id       = aws_kms_key.database_key.arn\n\n  # Backup encryption\n  backup_retention_period = 30\n  backup_window          = \"03:00-04:00\"\n  copy_tags_to_snapshot  = true\n\n  # Performance Insights encryption\n  performance_insights_enabled = true\n  performance_insights_kms_key_id = aws_kms_key.database_key.arn\n\n  # Additional security settings\n  deletion_protection = true\n  skip_final_snapshot = false\n  final_snapshot_identifier = \"dealsphere-prod-final-snapshot\"\n}\n\nresource \"aws_kms_key\" \"database_key\" {\n  description = \"KMS key for DealSphere database encryption\"\n\n  policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Effect = \"Allow\"\n        Principal = {\n          AWS = \"arn:aws:iam::${data.aws_caller_identity.current.account_id}:root\"\n        }\n        Action = \"kms:*\"\n        Resource = \"*\"\n      }\n    ]\n  })\n\n  tags = {\n    Name = \"dealsphere-database-key\"\n    Environment = \"production\"\n  }\n}\n</code></pre>"},{"location":"deployment/security-secrets/#file-storage-encryption","title":"File Storage Encryption","text":"<p>AWS S3 Server-Side Encryption</p> <pre><code># terraform/s3.tf\nresource \"aws_s3_bucket\" \"dealsphere_storage\" {\n  bucket = \"dealsphere-files-prod\"\n}\n\nresource \"aws_s3_bucket_server_side_encryption_configuration\" \"dealsphere_storage\" {\n  bucket = aws_s3_bucket.dealsphere_storage.id\n\n  rule {\n    apply_server_side_encryption_by_default {\n      sse_algorithm     = \"aws:kms\"\n      kms_master_key_id = aws_kms_key.s3_key.arn\n    }\n    bucket_key_enabled = true\n  }\n}\n\nresource \"aws_s3_bucket_public_access_block\" \"dealsphere_storage\" {\n  bucket = aws_s3_bucket.dealsphere_storage.id\n\n  block_public_acls       = true\n  block_public_policy     = true\n  ignore_public_acls      = true\n  restrict_public_buckets = true\n}\n\nresource \"aws_kms_key\" \"s3_key\" {\n  description = \"KMS key for DealSphere S3 encryption\"\n\n  policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Effect = \"Allow\"\n        Principal = {\n          AWS = \"arn:aws:iam::${data.aws_caller_identity.current.account_id}:root\"\n        }\n        Action = \"kms:*\"\n        Resource = \"*\"\n      }\n    ]\n  })\n}\n</code></pre> <p>Application-Level File Encryption</p> <pre><code>// File encryption service\n@Service\npublic class FileEncryptionService {\n    private final KmsClient kmsClient;\n    private final String dataKeyId;\n\n    public FileEncryptionService(KmsClient kmsClient,\n                               @Value(\"${aws.kms.data-key-id}\") String dataKeyId) {\n        this.kmsClient = kmsClient;\n        this.dataKeyId = dataKeyId;\n    }\n\n    public byte[] encryptFile(byte[] fileData) throws Exception {\n        // Generate data key\n        GenerateDataKeyRequest keyRequest = GenerateDataKeyRequest.builder()\n            .keyId(dataKeyId)\n            .keySpec(DataKeySpec.AES_256)\n            .build();\n\n        GenerateDataKeyResponse keyResponse = kmsClient.generateDataKey(keyRequest);\n        byte[] plaintextKey = keyResponse.plaintext().asByteArray();\n        byte[] encryptedKey = keyResponse.ciphertextBlob().asByteArray();\n\n        // Encrypt file with data key\n        Cipher cipher = Cipher.getInstance(\"AES/GCM/NoPadding\");\n        SecretKeySpec keySpec = new SecretKeySpec(plaintextKey, \"AES\");\n        cipher.init(Cipher.ENCRYPT_MODE, keySpec);\n\n        byte[] encryptedData = cipher.doFinal(fileData);\n        byte[] iv = cipher.getIV();\n\n        // Combine encrypted key, IV, and encrypted data\n        ByteArrayOutputStream output = new ByteArrayOutputStream();\n        output.write(encryptedKey.length);\n        output.write(encryptedKey);\n        output.write(iv.length);\n        output.write(iv);\n        output.write(encryptedData);\n\n        return output.toByteArray();\n    }\n\n    public byte[] decryptFile(byte[] encryptedFileData) throws Exception {\n        ByteArrayInputStream input = new ByteArrayInputStream(encryptedFileData);\n\n        // Extract encrypted key\n        int keyLength = input.read();\n        byte[] encryptedKey = new byte[keyLength];\n        input.read(encryptedKey);\n\n        // Extract IV\n        int ivLength = input.read();\n        byte[] iv = new byte[ivLength];\n        input.read(iv);\n\n        // Extract encrypted data\n        byte[] encryptedData = input.readAllBytes();\n\n        // Decrypt data key\n        DecryptRequest decryptRequest = DecryptRequest.builder()\n            .ciphertextBlob(SdkBytes.fromByteArray(encryptedKey))\n            .build();\n\n        DecryptResponse decryptResponse = kmsClient.decrypt(decryptRequest);\n        byte[] plaintextKey = decryptResponse.plaintext().asByteArray();\n\n        // Decrypt file data\n        Cipher cipher = Cipher.getInstance(\"AES/GCM/NoPadding\");\n        SecretKeySpec keySpec = new SecretKeySpec(plaintextKey, \"AES\");\n        GCMParameterSpec gcmSpec = new GCMParameterSpec(128, iv);\n        cipher.init(Cipher.DECRYPT_MODE, keySpec, gcmSpec);\n\n        return cipher.doFinal(encryptedData);\n    }\n}\n</code></pre>"},{"location":"deployment/security-secrets/#data-in-transit-encryption","title":"Data in Transit Encryption","text":""},{"location":"deployment/security-secrets/#tlsssl-configuration","title":"TLS/SSL Configuration","text":"<p>Application TLS Configuration</p> <pre><code># application-security.yml\nserver:\n  ssl:\n    enabled: true\n    key-store: classpath:keystore.p12\n    key-store-password: ${SSL_KEYSTORE_PASSWORD}\n    key-store-type: PKCS12\n    key-alias: dealsphere\n\n    # TLS version and cipher configuration\n    protocol: TLS\n    enabled-protocols: TLSv1.2,TLSv1.3\n    ciphers:\n      - TLS_AES_256_GCM_SHA384\n      - TLS_CHACHA20_POLY1305_SHA256\n      - TLS_AES_128_GCM_SHA256\n      - TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\n      - TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256\n\n    # Client certificate authentication (optional)\n    client-auth: want\n    trust-store: classpath:truststore.p12\n    trust-store-password: ${SSL_TRUSTSTORE_PASSWORD}\n\nmanagement:\n  server:\n    ssl:\n      enabled: true\n      key-store: classpath:keystore.p12\n      key-store-password: ${SSL_KEYSTORE_PASSWORD}\n</code></pre> <p>Nginx TLS Termination</p> <pre><code># nginx/ssl.conf\nserver {\n    listen 443 ssl http2;\n    server_name dealsphere.com;\n\n    # SSL Certificate configuration\n    ssl_certificate /etc/ssl/certs/dealsphere.crt;\n    ssl_certificate_key /etc/ssl/private/dealsphere.key;\n\n    # SSL Security configuration\n    ssl_protocols TLSv1.2 TLSv1.3;\n    ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512:ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-GCM-SHA384;\n    ssl_prefer_server_ciphers off;\n    ssl_session_cache shared:SSL:10m;\n    ssl_session_timeout 10m;\n\n    # HSTS (HTTP Strict Transport Security)\n    add_header Strict-Transport-Security \"max-age=31536000; includeSubDomains; preload\" always;\n\n    # Security headers\n    add_header X-Frame-Options \"SAMEORIGIN\" always;\n    add_header X-Content-Type-Options \"nosniff\" always;\n    add_header X-XSS-Protection \"1; mode=block\" always;\n    add_header Referrer-Policy \"strict-origin-when-cross-origin\" always;\n    add_header Content-Security-Policy \"default-src 'self'; script-src 'self' 'unsafe-inline'; style-src 'self' 'unsafe-inline'; img-src 'self' data: https:; font-src 'self' https:; connect-src 'self' https:; frame-ancestors 'self';\" always;\n\n    # OCSP Stapling\n    ssl_stapling on;\n    ssl_stapling_verify on;\n    ssl_trusted_certificate /etc/ssl/certs/chain.crt;\n\n    location / {\n        proxy_pass http://backend:8080;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n        proxy_set_header X-Forwarded-Port $server_port;\n    }\n}\n\n# Redirect HTTP to HTTPS\nserver {\n    listen 80;\n    server_name dealsphere.com;\n    return 301 https://$server_name$request_uri;\n}\n</code></pre>"},{"location":"deployment/security-secrets/#database-connection-security","title":"Database Connection Security","text":"<pre><code># Database SSL configuration\nspring:\n  datasource:\n    url: jdbc:postgresql://${DB_HOST}:${DB_PORT}/${DB_NAME}?sslmode=require&amp;sslcert=/etc/ssl/certs/client-cert.pem&amp;sslkey=/etc/ssl/private/client-key.pem&amp;sslrootcert=/etc/ssl/certs/ca-cert.pem\n    hikari:\n      connection-test-query: SELECT 1\n      connection-timeout: 30000\n      validation-timeout: 5000\n      leak-detection-threshold: 60000\n</code></pre>"},{"location":"deployment/security-secrets/#secrets-management","title":"Secrets Management","text":""},{"location":"deployment/security-secrets/#aws-secrets-manager-integration","title":"AWS Secrets Manager Integration","text":""},{"location":"deployment/security-secrets/#secrets-storage","title":"Secrets Storage","text":"<pre><code># Store database credentials\naws secretsmanager create-secret \\\n    --name \"dealsphere/prod/database\" \\\n    --description \"Production database credentials\" \\\n    --secret-string '{\n        \"username\": \"dealsphere_user\",\n        \"password\": \"super-secure-db-password-123!\",\n        \"host\": \"dealsphere-prod-cluster.cluster-abc123.us-west-2.rds.amazonaws.com\",\n        \"port\": 5432,\n        \"database\": \"dealsphere_prod\",\n        \"ssl_mode\": \"require\"\n    }'\n\n# Store JWT secrets\naws secretsmanager create-secret \\\n    --name \"dealsphere/prod/jwt\" \\\n    --description \"JWT signing and encryption keys\" \\\n    --secret-string '{\n        \"signing_key\": \"jwt-signing-key-256-bit-random-string\",\n        \"encryption_key\": \"jwt-encryption-key-256-bit-random\",\n        \"refresh_key\": \"jwt-refresh-key-256-bit-random-string\"\n    }'\n\n# Store third-party API keys\naws secretsmanager create-secret \\\n    --name \"dealsphere/prod/external-apis\" \\\n    --description \"External API credentials\" \\\n    --secret-string '{\n        \"stripe_secret_key\": \"sk_live_...\",\n        \"sendgrid_api_key\": \"SG.abc123...\",\n        \"aws_access_key\": \"AKIA...\",\n        \"aws_secret_key\": \"abc123...\"\n    }'\n\n# Store encryption keys\naws secretsmanager create-secret \\\n    --name \"dealsphere/prod/encryption\" \\\n    --description \"Application encryption keys\" \\\n    --secret-string '{\n        \"data_encryption_key\": \"32-byte-random-encryption-key-here\",\n        \"file_encryption_key\": \"32-byte-file-encryption-key-here\",\n        \"field_encryption_key\": \"32-byte-field-encryption-key\"\n    }'\n</code></pre>"},{"location":"deployment/security-secrets/#secrets-rotation","title":"Secrets Rotation","text":"<pre><code># terraform/secrets-rotation.tf\nresource \"aws_secretsmanager_secret\" \"database_credentials\" {\n  name = \"dealsphere/prod/database\"\n  description = \"Production database credentials\"\n\n  replica {\n    region = \"us-east-1\"\n  }\n}\n\nresource \"aws_secretsmanager_secret_rotation\" \"database_rotation\" {\n  secret_id           = aws_secretsmanager_secret.database_credentials.id\n  rotation_lambda_arn = aws_lambda_function.rotation_lambda.arn\n\n  rotation_rules {\n    automatically_after_days = 30\n  }\n}\n\nresource \"aws_lambda_function\" \"rotation_lambda\" {\n  filename         = \"rotation-lambda.zip\"\n  function_name    = \"dealsphere-secret-rotation\"\n  role            = aws_iam_role.rotation_lambda_role.arn\n  handler         = \"lambda_function.lambda_handler\"\n  runtime         = \"python3.9\"\n  timeout         = 30\n\n  environment {\n    variables = {\n      SECRETS_MANAGER_ENDPOINT = \"https://secretsmanager.us-west-2.amazonaws.com\"\n      EXCLUDE_CHARACTERS       = \" %+~`#$&amp;*()|[]{}:;&lt;&gt;?!'/\\\\\\\"@\"\n    }\n  }\n}\n</code></pre>"},{"location":"deployment/security-secrets/#application-secrets-integration","title":"Application Secrets Integration","text":"<pre><code>// Secrets manager integration\n@Configuration\n@EnableConfigurationProperties\npublic class SecretsConfiguration {\n\n    @Bean\n    public SecretsManagerClient secretsManagerClient() {\n        return SecretsManagerClient.builder()\n            .region(Region.US_WEST_2)\n            .build();\n    }\n\n    @Bean\n    @ConfigurationProperties(prefix = \"app.secrets\")\n    public SecretsProperties secretsProperties() {\n        return new SecretsProperties();\n    }\n}\n\n@Service\npublic class SecretsService {\n    private final SecretsManagerClient secretsClient;\n    private final ObjectMapper objectMapper;\n    private final Map&lt;String, Object&gt; secretsCache = new ConcurrentHashMap&lt;&gt;();\n\n    public SecretsService(SecretsManagerClient secretsClient) {\n        this.secretsClient = secretsClient;\n        this.objectMapper = new ObjectMapper();\n    }\n\n    @Cacheable(value = \"secrets\", key = \"#secretName\")\n    public &lt;T&gt; T getSecret(String secretName, Class&lt;T&gt; type) {\n        try {\n            GetSecretValueRequest request = GetSecretValueRequest.builder()\n                .secretId(secretName)\n                .build();\n\n            GetSecretValueResponse response = secretsClient.getSecretValue(request);\n            String secretValue = response.secretString();\n\n            if (type == String.class) {\n                return type.cast(secretValue);\n            } else {\n                return objectMapper.readValue(secretValue, type);\n            }\n        } catch (Exception e) {\n            throw new SecretRetrievalException(\"Failed to retrieve secret: \" + secretName, e);\n        }\n    }\n\n    public DatabaseCredentials getDatabaseCredentials() {\n        return getSecret(\"dealsphere/prod/database\", DatabaseCredentials.class);\n    }\n\n    public JwtSecrets getJwtSecrets() {\n        return getSecret(\"dealsphere/prod/jwt\", JwtSecrets.class);\n    }\n\n    public String getApiKey(String serviceName) {\n        ExternalApiSecrets secrets = getSecret(\"dealsphere/prod/external-apis\", ExternalApiSecrets.class);\n        return secrets.getApiKey(serviceName);\n    }\n\n    @EventListener(ContextRefreshedEvent.class)\n    public void warmUpSecrets() {\n        // Pre-load critical secrets at startup\n        getDatabaseCredentials();\n        getJwtSecrets();\n    }\n}\n\n// Data classes for secrets\n@Data\npublic class DatabaseCredentials {\n    private String username;\n    private String password;\n    private String host;\n    private int port;\n    private String database;\n    private String sslMode;\n}\n\n@Data\npublic class JwtSecrets {\n    private String signingKey;\n    private String encryptionKey;\n    private String refreshKey;\n}\n</code></pre>"},{"location":"deployment/security-secrets/#kubernetes-secrets-management","title":"Kubernetes Secrets Management","text":""},{"location":"deployment/security-secrets/#external-secrets-operator","title":"External Secrets Operator","text":"<pre><code># external-secrets/secret-store.yml\napiVersion: external-secrets.io/v1beta1\nkind: SecretStore\nmetadata:\n  name: aws-secrets-manager\n  namespace: dealsphere-prod\nspec:\n  provider:\n    aws:\n      service: SecretsManager\n      region: us-west-2\n      auth:\n        jwt:\n          serviceAccountRef:\n            name: external-secrets-sa\n---\napiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: database-credentials\n  namespace: dealsphere-prod\nspec:\n  refreshInterval: 1h\n  secretStoreRef:\n    name: aws-secrets-manager\n    kind: SecretStore\n  target:\n    name: database-credentials\n    creationPolicy: Owner\n  data:\n  - secretKey: username\n    remoteRef:\n      key: dealsphere/prod/database\n      property: username\n  - secretKey: password\n    remoteRef:\n      key: dealsphere/prod/database\n      property: password\n  - secretKey: host\n    remoteRef:\n      key: dealsphere/prod/database\n      property: host\n---\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: external-secrets-sa\n  namespace: dealsphere-prod\n  annotations:\n    eks.amazonaws.com/role-arn: arn:aws:iam::ACCOUNT:role/external-secrets-role\n</code></pre>"},{"location":"deployment/security-secrets/#access-control-and-authentication","title":"Access Control and Authentication","text":""},{"location":"deployment/security-secrets/#jwt-security-implementation","title":"JWT Security Implementation","text":"<pre><code>// Enhanced JWT service with encryption\n@Service\npublic class JwtService {\n    private final JwtSecrets jwtSecrets;\n    private final Algorithm signingAlgorithm;\n    private final JWEAlgorithm encryptionAlgorithm;\n\n    public JwtService(SecretsService secretsService) {\n        this.jwtSecrets = secretsService.getJwtSecrets();\n        this.signingAlgorithm = Algorithm.HMAC256(jwtSecrets.getSigningKey());\n        this.encryptionAlgorithm = JWEAlgorithm.A256KW;\n    }\n\n    public String generateAccessToken(UserPrincipal user) {\n        try {\n            // Create JWT claims\n            String token = JWT.create()\n                .withIssuer(\"dealsphere\")\n                .withSubject(user.getId().toString())\n                .withClaim(\"email\", user.getEmail())\n                .withClaim(\"roles\", user.getRoles().stream()\n                    .map(Role::getName)\n                    .collect(Collectors.toList()))\n                .withClaim(\"organizationId\", user.getOrganizationId().toString())\n                .withIssuedAt(new Date())\n                .withExpiresAt(new Date(System.currentTimeMillis() + JWT_EXPIRATION))\n                .withJWTId(UUID.randomUUID().toString())\n                .sign(signingAlgorithm);\n\n            // Encrypt the JWT\n            return encryptJWT(token);\n        } catch (Exception e) {\n            throw new TokenGenerationException(\"Failed to generate access token\", e);\n        }\n    }\n\n    public String generateRefreshToken(UserPrincipal user) {\n        try {\n            String token = JWT.create()\n                .withIssuer(\"dealsphere\")\n                .withSubject(user.getId().toString())\n                .withClaim(\"type\", \"refresh\")\n                .withIssuedAt(new Date())\n                .withExpiresAt(new Date(System.currentTimeMillis() + REFRESH_EXPIRATION))\n                .withJWTId(UUID.randomUUID().toString())\n                .sign(Algorithm.HMAC256(jwtSecrets.getRefreshKey()));\n\n            return encryptJWT(token);\n        } catch (Exception e) {\n            throw new TokenGenerationException(\"Failed to generate refresh token\", e);\n        }\n    }\n\n    public DecodedJWT validateAndDecodeToken(String encryptedToken) {\n        try {\n            // Decrypt the JWT\n            String token = decryptJWT(encryptedToken);\n\n            // Verify signature and decode\n            JWTVerifier verifier = JWT.require(signingAlgorithm)\n                .withIssuer(\"dealsphere\")\n                .build();\n\n            return verifier.verify(token);\n        } catch (Exception e) {\n            throw new TokenValidationException(\"Invalid token\", e);\n        }\n    }\n\n    private String encryptJWT(String jwt) throws Exception {\n        // Use JWE with A256KW algorithm\n        JWEHeader header = new JWEHeader(encryptionAlgorithm, EncryptionMethod.A256GCM);\n        Payload payload = new Payload(jwt);\n\n        JWEObject jweObject = new JWEObject(header, payload);\n        jweObject.encrypt(new AESEncrypter(jwtSecrets.getEncryptionKey().getBytes()));\n\n        return jweObject.serialize();\n    }\n\n    private String decryptJWT(String encryptedJWT) throws Exception {\n        JWEObject jweObject = JWEObject.parse(encryptedJWT);\n        jweObject.decrypt(new AESDecrypter(jwtSecrets.getEncryptionKey().getBytes()));\n\n        return jweObject.getPayload().toString();\n    }\n}\n</code></pre>"},{"location":"deployment/security-secrets/#multi-factor-authentication","title":"Multi-Factor Authentication","text":"<pre><code>// TOTP-based MFA implementation\n@Service\npublic class MfaService {\n    private final UserRepository userRepository;\n    private final SecretGenerator secretGenerator;\n\n    public MfaSetupResponse setupMfa(UUID userId) {\n        User user = userRepository.findById(userId)\n            .orElseThrow(() -&gt; new UserNotFoundException(\"User not found\"));\n\n        // Generate secret key\n        String secretKey = secretGenerator.generate();\n\n        // Store encrypted secret\n        user.setMfaSecret(encryptSecret(secretKey));\n        user.setMfaEnabled(false); // Enable after verification\n        userRepository.save(user);\n\n        // Generate QR code\n        String qrCodeUrl = generateQrCodeUrl(user.getEmail(), secretKey);\n\n        return MfaSetupResponse.builder()\n            .secretKey(secretKey)\n            .qrCodeUrl(qrCodeUrl)\n            .backupCodes(generateBackupCodes(userId))\n            .build();\n    }\n\n    public boolean verifyMfaToken(UUID userId, String token) {\n        User user = userRepository.findById(userId)\n            .orElseThrow(() -&gt; new UserNotFoundException(\"User not found\"));\n\n        if (!user.isMfaEnabled()) {\n            throw new MfaNotEnabledException(\"MFA not enabled for user\");\n        }\n\n        String secretKey = decryptSecret(user.getMfaSecret());\n\n        // Verify TOTP token (allow for time skew)\n        for (int i = -1; i &lt;= 1; i++) {\n            long timeWindow = System.currentTimeMillis() / 30000 + i;\n            String expectedToken = generateTotp(secretKey, timeWindow);\n\n            if (token.equals(expectedToken)) {\n                return true;\n            }\n        }\n\n        // Check backup codes\n        return verifyBackupCode(userId, token);\n    }\n\n    private String generateTotp(String secretKey, long timeWindow) {\n        try {\n            byte[] data = ByteBuffer.allocate(8).putLong(timeWindow).array();\n            Mac mac = Mac.getInstance(\"HmacSHA1\");\n            mac.init(new SecretKeySpec(Base32.decode(secretKey), \"HmacSHA1\"));\n            byte[] hash = mac.doFinal(data);\n\n            int offset = hash[hash.length - 1] &amp; 0xF;\n            int code = ((hash[offset] &amp; 0x7F) &lt;&lt; 24) |\n                      ((hash[offset + 1] &amp; 0xFF) &lt;&lt; 16) |\n                      ((hash[offset + 2] &amp; 0xFF) &lt;&lt; 8) |\n                      (hash[offset + 3] &amp; 0xFF);\n\n            return String.format(\"%06d\", code % 1000000);\n        } catch (Exception e) {\n            throw new MfaException(\"Failed to generate TOTP\", e);\n        }\n    }\n}\n</code></pre>"},{"location":"deployment/security-secrets/#network-security","title":"Network Security","text":""},{"location":"deployment/security-secrets/#vpc-and-network-segmentation","title":"VPC and Network Segmentation","text":"<pre><code># terraform/vpc.tf\nresource \"aws_vpc\" \"dealsphere_vpc\" {\n  cidr_block           = \"10.0.0.0/16\"\n  enable_dns_hostnames = true\n  enable_dns_support   = true\n\n  tags = {\n    Name = \"dealsphere-vpc\"\n    Environment = \"production\"\n  }\n}\n\n# Public subnets for load balancers\nresource \"aws_subnet\" \"public_subnets\" {\n  count = 3\n\n  vpc_id            = aws_vpc.dealsphere_vpc.id\n  cidr_block        = \"10.0.${count.index + 1}.0/24\"\n  availability_zone = data.aws_availability_zones.available.names[count.index]\n\n  map_public_ip_on_launch = true\n\n  tags = {\n    Name = \"dealsphere-public-${count.index + 1}\"\n    Type = \"public\"\n  }\n}\n\n# Private subnets for application servers\nresource \"aws_subnet\" \"private_subnets\" {\n  count = 3\n\n  vpc_id            = aws_vpc.dealsphere_vpc.id\n  cidr_block        = \"10.0.${count.index + 10}.0/24\"\n  availability_zone = data.aws_availability_zones.available.names[count.index]\n\n  tags = {\n    Name = \"dealsphere-private-${count.index + 1}\"\n    Type = \"private\"\n  }\n}\n\n# Database subnets (isolated)\nresource \"aws_subnet\" \"database_subnets\" {\n  count = 3\n\n  vpc_id            = aws_vpc.dealsphere_vpc.id\n  cidr_block        = \"10.0.${count.index + 20}.0/24\"\n  availability_zone = data.aws_availability_zones.available.names[count.index]\n\n  tags = {\n    Name = \"dealsphere-database-${count.index + 1}\"\n    Type = \"database\"\n  }\n}\n\n# Security groups\nresource \"aws_security_group\" \"alb_sg\" {\n  name_prefix = \"dealsphere-alb-\"\n  vpc_id      = aws_vpc.dealsphere_vpc.id\n\n  ingress {\n    from_port   = 80\n    to_port     = 80\n    protocol    = \"tcp\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  ingress {\n    from_port   = 443\n    to_port     = 443\n    protocol    = \"tcp\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  egress {\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n}\n\nresource \"aws_security_group\" \"app_sg\" {\n  name_prefix = \"dealsphere-app-\"\n  vpc_id      = aws_vpc.dealsphere_vpc.id\n\n  ingress {\n    from_port       = 8080\n    to_port         = 8080\n    protocol        = \"tcp\"\n    security_groups = [aws_security_group.alb_sg.id]\n  }\n\n  ingress {\n    from_port   = 22\n    to_port     = 22\n    protocol    = \"tcp\"\n    cidr_blocks = [\"10.0.0.0/16\"]  # VPC only\n  }\n\n  egress {\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n}\n\nresource \"aws_security_group\" \"database_sg\" {\n  name_prefix = \"dealsphere-db-\"\n  vpc_id      = aws_vpc.dealsphere_vpc.id\n\n  ingress {\n    from_port       = 5432\n    to_port         = 5432\n    protocol        = \"tcp\"\n    security_groups = [aws_security_group.app_sg.id]\n  }\n\n  tags = {\n    Name = \"dealsphere-database-sg\"\n  }\n}\n</code></pre>"},{"location":"deployment/security-secrets/#web-application-firewall-waf","title":"Web Application Firewall (WAF)","text":"<pre><code># terraform/waf.tf\nresource \"aws_wafv2_web_acl\" \"dealsphere_waf\" {\n  name  = \"dealsphere-waf\"\n  scope = \"REGIONAL\"\n\n  default_action {\n    allow {}\n  }\n\n  # Rate limiting rule\n  rule {\n    name     = \"RateLimitRule\"\n    priority = 1\n\n    action {\n      block {}\n    }\n\n    statement {\n      rate_based_statement {\n        limit              = 2000\n        aggregate_key_type = \"IP\"\n      }\n    }\n\n    visibility_config {\n      cloudwatch_metrics_enabled = true\n      metric_name                = \"RateLimitRule\"\n      sampled_requests_enabled   = true\n    }\n  }\n\n  # SQL injection protection\n  rule {\n    name     = \"SQLInjectionRule\"\n    priority = 2\n\n    action {\n      block {}\n    }\n\n    statement {\n      sqli_match_statement {\n        field_to_match {\n          body {}\n        }\n        text_transformation {\n          priority = 0\n          type     = \"URL_DECODE\"\n        }\n        text_transformation {\n          priority = 1\n          type     = \"HTML_ENTITY_DECODE\"\n        }\n      }\n    }\n\n    visibility_config {\n      cloudwatch_metrics_enabled = true\n      metric_name                = \"SQLInjectionRule\"\n      sampled_requests_enabled   = true\n    }\n  }\n\n  # XSS protection\n  rule {\n    name     = \"XSSRule\"\n    priority = 3\n\n    action {\n      block {}\n    }\n\n    statement {\n      xss_match_statement {\n        field_to_match {\n          body {}\n        }\n        text_transformation {\n          priority = 0\n          type     = \"URL_DECODE\"\n        }\n        text_transformation {\n          priority = 1\n          type     = \"HTML_ENTITY_DECODE\"\n        }\n      }\n    }\n\n    visibility_config {\n      cloudwatch_metrics_enabled = true\n      metric_name                = \"XSSRule\"\n      sampled_requests_enabled   = true\n    }\n  }\n\n  # IP whitelist rule\n  rule {\n    name     = \"IPWhitelistRule\"\n    priority = 4\n\n    action {\n      allow {}\n    }\n\n    statement {\n      ip_set_reference_statement {\n        arn = aws_wafv2_ip_set.allowed_ips.arn\n      }\n    }\n\n    visibility_config {\n      cloudwatch_metrics_enabled = true\n      metric_name                = \"IPWhitelistRule\"\n      sampled_requests_enabled   = true\n    }\n  }\n\n  visibility_config {\n    cloudwatch_metrics_enabled = true\n    metric_name                = \"dealsphere-waf\"\n    sampled_requests_enabled   = true\n  }\n}\n\nresource \"aws_wafv2_ip_set\" \"allowed_ips\" {\n  name  = \"allowed-ips\"\n  scope = \"REGIONAL\"\n\n  ip_address_version = \"IPV4\"\n  addresses = [\n    \"203.0.113.0/24\",  # Office IP range\n    \"198.51.100.0/24\"  # Additional trusted IPs\n  ]\n}\n</code></pre>"},{"location":"deployment/security-secrets/#security-monitoring-and-compliance","title":"Security Monitoring and Compliance","text":""},{"location":"deployment/security-secrets/#security-event-logging","title":"Security Event Logging","text":"<pre><code>// Security audit logger\n@Component\npublic class SecurityAuditLogger {\n    private static final Logger securityLogger = LoggerFactory.getLogger(\"SECURITY\");\n    private final ObjectMapper objectMapper;\n\n    public void logLoginAttempt(String email, String ipAddress, boolean success, String reason) {\n        SecurityEvent event = SecurityEvent.builder()\n            .eventType(\"LOGIN_ATTEMPT\")\n            .timestamp(Instant.now())\n            .userId(email)\n            .ipAddress(ipAddress)\n            .success(success)\n            .reason(reason)\n            .userAgent(getCurrentUserAgent())\n            .sessionId(getCurrentSessionId())\n            .build();\n\n        logSecurityEvent(event);\n    }\n\n    public void logAccessViolation(String userId, String resource, String action, String reason) {\n        SecurityEvent event = SecurityEvent.builder()\n            .eventType(\"ACCESS_VIOLATION\")\n            .timestamp(Instant.now())\n            .userId(userId)\n            .resource(resource)\n            .action(action)\n            .success(false)\n            .reason(reason)\n            .ipAddress(getCurrentIpAddress())\n            .build();\n\n        logSecurityEvent(event);\n    }\n\n    public void logDataAccess(String userId, String dataType, String operation, int recordCount) {\n        SecurityEvent event = SecurityEvent.builder()\n            .eventType(\"DATA_ACCESS\")\n            .timestamp(Instant.now())\n            .userId(userId)\n            .dataType(dataType)\n            .operation(operation)\n            .recordCount(recordCount)\n            .success(true)\n            .ipAddress(getCurrentIpAddress())\n            .build();\n\n        logSecurityEvent(event);\n    }\n\n    private void logSecurityEvent(SecurityEvent event) {\n        try {\n            String jsonEvent = objectMapper.writeValueAsString(event);\n            securityLogger.info(jsonEvent);\n        } catch (Exception e) {\n            securityLogger.error(\"Failed to log security event\", e);\n        }\n    }\n}\n\n@Data\n@Builder\npublic class SecurityEvent {\n    private String eventType;\n    private Instant timestamp;\n    private String userId;\n    private String ipAddress;\n    private String userAgent;\n    private String sessionId;\n    private String resource;\n    private String action;\n    private String dataType;\n    private String operation;\n    private Integer recordCount;\n    private boolean success;\n    private String reason;\n}\n</code></pre>"},{"location":"deployment/security-secrets/#compliance-monitoring","title":"Compliance Monitoring","text":"<pre><code># CloudTrail for API audit logging\nresource \"aws_cloudtrail\" \"dealsphere_audit\" {\n  name                         = \"dealsphere-audit-trail\"\n  s3_bucket_name              = aws_s3_bucket.audit_logs.bucket\n  include_global_service_events = true\n  is_multi_region_trail       = true\n  enable_logging              = true\n\n  event_selector {\n    read_write_type           = \"All\"\n    include_management_events = true\n\n    data_resource {\n      type   = \"AWS::S3::Object\"\n      values = [\"${aws_s3_bucket.dealsphere_storage.arn}/*\"]\n    }\n  }\n\n  insight_selector {\n    insight_type = \"ApiCallRateInsight\"\n  }\n}\n\n# Config for compliance monitoring\nresource \"aws_config_configuration_recorder\" \"dealsphere_config\" {\n  name     = \"dealsphere-config-recorder\"\n  role_arn = aws_iam_role.config_role.arn\n\n  recording_group {\n    all_supported                 = true\n    include_global_resource_types = true\n  }\n}\n\nresource \"aws_config_config_rule\" \"s3_bucket_public_read_prohibited\" {\n  name = \"s3-bucket-public-read-prohibited\"\n\n  source {\n    owner             = \"AWS\"\n    source_identifier = \"S3_BUCKET_PUBLIC_READ_PROHIBITED\"\n  }\n\n  depends_on = [aws_config_configuration_recorder.dealsphere_config]\n}\n\nresource \"aws_config_config_rule\" \"encrypted_volumes\" {\n  name = \"encrypted-volumes\"\n\n  source {\n    owner             = \"AWS\"\n    source_identifier = \"ENCRYPTED_VOLUMES\"\n  }\n\n  depends_on = [aws_config_configuration_recorder.dealsphere_config]\n}\n</code></pre> <p>This comprehensive security guide ensures data protection at rest and in transit, secure secrets management, and compliance with industry security standards for the DealSphere platform.</p>"},{"location":"development/api-documentation/","title":"API Documentation","text":""},{"location":"development/api-documentation/#overview","title":"Overview","text":"<p>The DealSphere platform provides a comprehensive GraphQL API for authentication, user management, and business operations. This document covers the complete API specification, authentication mechanisms, and usage examples.</p>"},{"location":"development/api-documentation/#graphql-api-endpoint","title":"GraphQL API Endpoint","text":"<ul> <li>Production: <code>https://api.dealsphere.com/graphql</code></li> <li>Staging: <code>https://staging-api.dealsphere.com/graphql</code></li> <li>Development: <code>http://localhost:8080/graphql</code></li> </ul>"},{"location":"development/api-documentation/#authentication","title":"Authentication","text":""},{"location":"development/api-documentation/#jwt-token-based-authentication","title":"JWT Token-Based Authentication","text":"<p>All API requests (except login and public queries) require a valid JWT token in the Authorization header:</p> <pre><code>Authorization: Bearer &lt;jwt_token&gt;\n</code></pre>"},{"location":"development/api-documentation/#token-lifecycle","title":"Token Lifecycle","text":"<ol> <li>Obtain Token: Use <code>login</code> mutation with valid credentials</li> <li>Use Token: Include in Authorization header for protected operations</li> <li>Refresh Token: Use <code>refreshToken</code> mutation before expiration</li> <li>Token Expiration: Production tokens expire in 1 hour, development in 24 hours</li> </ol>"},{"location":"development/api-documentation/#schema-definition","title":"Schema Definition","text":""},{"location":"development/api-documentation/#core-types","title":"Core Types","text":"<pre><code># User Profile\ntype UserProfile {\n  id: ID!\n  email: String!\n  firstName: String!\n  lastName: String!\n  organization: Organization!\n  roles: [Role!]!\n  isActive: Boolean!\n  createdAt: DateTime!\n  updatedAt: DateTime!\n}\n\n# Organization\ntype Organization {\n  id: ID!\n  name: String!\n  description: String\n  isActive: Boolean!\n  createdAt: DateTime!\n  updatedAt: DateTime!\n}\n\n# Role\ntype Role {\n  id: ID!\n  name: String!\n  description: String\n  organization: Organization!\n  permissions: [String!]!\n  isActive: Boolean!\n  createdAt: DateTime!\n  updatedAt: DateTime!\n}\n\n# Authentication Payload\ntype AuthPayload {\n  token: String!\n  user: UserProfile!\n}\n\n# Invitation Payload\ntype InvitationPayload {\n  success: Boolean!\n  message: String!\n  invitationId: String\n}\n\n# Password Reset Payload\ntype PasswordResetPayload {\n  success: Boolean!\n  message: String!\n}\n</code></pre>"},{"location":"development/api-documentation/#input-types","title":"Input Types","text":"<pre><code># Login Input\ninput LoginInput {\n  email: String!\n  password: String!\n}\n\n# User Invitation Input\ninput InviteUserInput {\n  email: String!\n  firstName: String!\n  lastName: String!\n  organizationId: ID!\n}\n\n# Registration Completion Input\ninput CompleteRegistrationInput {\n  invitationToken: String!\n  password: String!\n}\n\n# Password Reset Request Input\ninput PasswordResetRequestInput {\n  email: String!\n}\n\n# Password Reset Confirmation Input\ninput PasswordResetConfirmInput {\n  resetToken: String!\n  newPassword: String!\n}\n\n# User Update Input\ninput UserUpdateInput {\n  firstName: String\n  lastName: String\n  isActive: Boolean\n}\n</code></pre>"},{"location":"development/api-documentation/#mutations","title":"Mutations","text":""},{"location":"development/api-documentation/#authentication-mutations","title":"Authentication Mutations","text":""},{"location":"development/api-documentation/#login","title":"Login","text":"<p>Authenticate user with email and password.</p> <pre><code>mutation Login($input: LoginInput!) {\n  login(input: $input) {\n    token\n    user {\n      id\n      email\n      firstName\n      lastName\n      organization {\n        id\n        name\n      }\n      roles {\n        id\n        name\n        permissions\n      }\n    }\n  }\n}\n</code></pre> <p>Variables:</p> <pre><code>{\n  \"input\": {\n    \"email\": \"user@example.com\",\n    \"password\": \"password123\"\n  }\n}\n</code></pre> <p>Response:</p> <pre><code>{\n  \"data\": {\n    \"login\": {\n      \"token\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...\",\n      \"user\": {\n        \"id\": \"user-123\",\n        \"email\": \"user@example.com\",\n        \"firstName\": \"John\",\n        \"lastName\": \"Doe\",\n        \"organization\": {\n          \"id\": \"org-456\",\n          \"name\": \"Acme Corp\"\n        },\n        \"roles\": [\n          {\n            \"id\": \"role-789\",\n            \"name\": \"USER\",\n            \"permissions\": [\"READ_PROFILE\", \"UPDATE_PROFILE\"]\n          }\n        ]\n      }\n    }\n  }\n}\n</code></pre> <p>Error Responses:</p> <pre><code>{\n  \"errors\": [\n    {\n      \"message\": \"Invalid email or password\",\n      \"extensions\": {\n        \"code\": \"AUTHENTICATION_ERROR\"\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"development/api-documentation/#refresh-token","title":"Refresh Token","text":"<p>Refresh an existing JWT token.</p> <pre><code>mutation RefreshToken {\n  refreshToken {\n    token\n    user {\n      id\n      email\n    }\n  }\n}\n</code></pre> <p>Headers:</p> <pre><code>Authorization: Bearer &lt;current_jwt_token&gt;\n</code></pre>"},{"location":"development/api-documentation/#logout","title":"Logout","text":"<p>Invalidate current session (client-side token removal).</p> <pre><code>mutation Logout {\n  logout\n}\n</code></pre>"},{"location":"development/api-documentation/#user-management-mutations","title":"User Management Mutations","text":""},{"location":"development/api-documentation/#invite-user","title":"Invite User","text":"<p>Send invitation email to new user (Admin only).</p> <pre><code>mutation InviteUser($input: InviteUserInput!) {\n  inviteUser(input: $input) {\n    success\n    message\n    invitationId\n  }\n}\n</code></pre> <p>Variables:</p> <pre><code>{\n  \"input\": {\n    \"email\": \"newuser@example.com\",\n    \"firstName\": \"Jane\",\n    \"lastName\": \"Smith\",\n    \"organizationId\": \"org-456\"\n  }\n}\n</code></pre> <p>Response:</p> <pre><code>{\n  \"data\": {\n    \"inviteUser\": {\n      \"success\": true,\n      \"message\": \"Invitation sent successfully\",\n      \"invitationId\": \"inv-789\"\n    }\n  }\n}\n</code></pre>"},{"location":"development/api-documentation/#complete-registration","title":"Complete Registration","text":"<p>Complete user registration from invitation.</p> <pre><code>mutation CompleteRegistration($input: CompleteRegistrationInput!) {\n  completeRegistration(input: $input) {\n    token\n    user {\n      id\n      email\n      firstName\n      lastName\n    }\n  }\n}\n</code></pre> <p>Variables:</p> <pre><code>{\n  \"input\": {\n    \"invitationToken\": \"inv-token-123\",\n    \"password\": \"newpassword123\"\n  }\n}\n</code></pre>"},{"location":"development/api-documentation/#update-user-profile","title":"Update User Profile","text":"<p>Update user profile information.</p> <pre><code>mutation UpdateUserProfile($id: ID!, $input: UserUpdateInput!) {\n  updateUserProfile(id: $id, input: $input) {\n    id\n    firstName\n    lastName\n    isActive\n    updatedAt\n  }\n}\n</code></pre>"},{"location":"development/api-documentation/#password-management-mutations","title":"Password Management Mutations","text":""},{"location":"development/api-documentation/#request-password-reset","title":"Request Password Reset","text":"<p>Send password reset email.</p> <pre><code>mutation RequestPasswordReset($input: PasswordResetRequestInput!) {\n  requestPasswordReset(input: $input) {\n    success\n    message\n  }\n}\n</code></pre> <p>Variables:</p> <pre><code>{\n  \"input\": {\n    \"email\": \"user@example.com\"\n  }\n}\n</code></pre>"},{"location":"development/api-documentation/#confirm-password-reset","title":"Confirm Password Reset","text":"<p>Complete password reset with token.</p> <pre><code>mutation ConfirmPasswordReset($input: PasswordResetConfirmInput!) {\n  confirmPasswordReset(input: $input)\n}\n</code></pre> <p>Variables:</p> <pre><code>{\n  \"input\": {\n    \"resetToken\": \"reset-token-123\",\n    \"newPassword\": \"newpassword123\"\n  }\n}\n</code></pre>"},{"location":"development/api-documentation/#validate-password-reset-token","title":"Validate Password Reset Token","text":"<p>Check if password reset token is valid.</p> <pre><code>mutation ValidatePasswordResetToken($resetToken: String!) {\n  validatePasswordResetToken(resetToken: $resetToken)\n}\n</code></pre>"},{"location":"development/api-documentation/#queries","title":"Queries","text":""},{"location":"development/api-documentation/#user-queries","title":"User Queries","text":""},{"location":"development/api-documentation/#get-current-user","title":"Get Current User","text":"<p>Get current authenticated user profile.</p> <pre><code>query GetCurrentUser {\n  me {\n    id\n    email\n    firstName\n    lastName\n    organization {\n      id\n      name\n      description\n    }\n    roles {\n      id\n      name\n      description\n      permissions\n    }\n    isActive\n    createdAt\n    updatedAt\n  }\n}\n</code></pre>"},{"location":"development/api-documentation/#get-user-by-id","title":"Get User by ID","text":"<p>Get specific user by ID (Admin only).</p> <pre><code>query GetUser($id: ID!) {\n  user(id: $id) {\n    id\n    email\n    firstName\n    lastName\n    organization {\n      id\n      name\n    }\n    roles {\n      id\n      name\n      permissions\n    }\n    isActive\n    createdAt\n    updatedAt\n  }\n}\n</code></pre>"},{"location":"development/api-documentation/#list-users","title":"List Users","text":"<p>Get paginated list of users (Admin only).</p> <pre><code>query ListUsers($first: Int, $after: String, $organizationId: ID) {\n  users(first: $first, after: $after, organizationId: $organizationId) {\n    edges {\n      node {\n        id\n        email\n        firstName\n        lastName\n        isActive\n        createdAt\n      }\n      cursor\n    }\n    pageInfo {\n      hasNextPage\n      hasPreviousPage\n      startCursor\n      endCursor\n    }\n    totalCount\n  }\n}\n</code></pre>"},{"location":"development/api-documentation/#organization-queries","title":"Organization Queries","text":""},{"location":"development/api-documentation/#get-organization","title":"Get Organization","text":"<p>Get organization details.</p> <pre><code>query GetOrganization($id: ID!) {\n  organization(id: $id) {\n    id\n    name\n    description\n    isActive\n    createdAt\n    updatedAt\n    userCount\n  }\n}\n</code></pre>"},{"location":"development/api-documentation/#list-organizations","title":"List Organizations","text":"<p>Get all organizations (Super Admin only).</p> <pre><code>query ListOrganizations {\n  organizations {\n    id\n    name\n    description\n    isActive\n    userCount\n    createdAt\n  }\n}\n</code></pre>"},{"location":"development/api-documentation/#role-queries","title":"Role Queries","text":""},{"location":"development/api-documentation/#list-roles","title":"List Roles","text":"<p>Get available roles for organization.</p> <pre><code>query ListRoles($organizationId: ID!) {\n  roles(organizationId: $organizationId) {\n    id\n    name\n    description\n    permissions\n    isActive\n    createdAt\n  }\n}\n</code></pre>"},{"location":"development/api-documentation/#error-handling","title":"Error Handling","text":""},{"location":"development/api-documentation/#error-types","title":"Error Types","text":"<p>The API uses standardized error codes and messages:</p> <pre><code>interface GraphQLError {\n  message: string;\n  locations?: Array&lt;{\n    line: number;\n    column: number;\n  }&gt;;\n  path?: Array&lt;string | number&gt;;\n  extensions: {\n    code: string;\n    details?: any;\n  };\n}\n</code></pre>"},{"location":"development/api-documentation/#common-error-codes","title":"Common Error Codes","text":"Code Description HTTP Status <code>AUTHENTICATION_ERROR</code> Invalid credentials or token 401 <code>AUTHORIZATION_ERROR</code> Insufficient permissions 403 <code>VALIDATION_ERROR</code> Input validation failed 400 <code>NOT_FOUND</code> Resource not found 404 <code>RATE_LIMITED</code> Too many requests 429 <code>INTERNAL_ERROR</code> Server error 500"},{"location":"development/api-documentation/#error-examples","title":"Error Examples","text":""},{"location":"development/api-documentation/#authentication-error","title":"Authentication Error","text":"<pre><code>{\n  \"errors\": [\n    {\n      \"message\": \"Invalid email or password\",\n      \"extensions\": {\n        \"code\": \"AUTHENTICATION_ERROR\"\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"development/api-documentation/#validation-error","title":"Validation Error","text":"<pre><code>{\n  \"errors\": [\n    {\n      \"message\": \"Validation failed\",\n      \"extensions\": {\n        \"code\": \"VALIDATION_ERROR\",\n        \"details\": {\n          \"email\": \"Invalid email format\",\n          \"password\": \"Password must be at least 8 characters\"\n        }\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"development/api-documentation/#rate-limiting-error","title":"Rate Limiting Error","text":"<pre><code>{\n  \"errors\": [\n    {\n      \"message\": \"Too many requests\",\n      \"extensions\": {\n        \"code\": \"RATE_LIMITED\",\n        \"details\": {\n          \"retryAfter\": 300,\n          \"limit\": 5,\n          \"window\": \"15m\"\n        }\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"development/api-documentation/#client-integration","title":"Client Integration","text":""},{"location":"development/api-documentation/#javascripttypescript","title":"JavaScript/TypeScript","text":"<p>Using Apollo Client:</p> <pre><code>import { ApolloClient, InMemoryCache, createHttpLink } from '@apollo/client';\nimport { setContext } from '@apollo/client/link/context';\n\n// HTTP link\nconst httpLink = createHttpLink({\n  uri: 'https://api.dealsphere.com/graphql',\n});\n\n// Auth link\nconst authLink = setContext((_, { headers }) =&gt; {\n  const token = localStorage.getItem('auth_token');\n  return {\n    headers: {\n      ...headers,\n      authorization: token ? `Bearer ${token}` : '',\n    }\n  };\n});\n\n// Apollo Client\nconst client = new ApolloClient({\n  link: authLink.concat(httpLink),\n  cache: new InMemoryCache(),\n});\n\n// Usage example\nimport { gql } from '@apollo/client';\n\nconst LOGIN_MUTATION = gql`\n  mutation Login($input: LoginInput!) {\n    login(input: $input) {\n      token\n      user {\n        id\n        email\n        firstName\n        lastName\n      }\n    }\n  }\n`;\n\n// Execute mutation\nconst [login] = useMutation(LOGIN_MUTATION);\n\nconst handleLogin = async (email: string, password: string) =&gt; {\n  try {\n    const result = await login({\n      variables: { input: { email, password } }\n    });\n\n    const { token, user } = result.data.login;\n    localStorage.setItem('auth_token', token);\n\n    console.log('Login successful:', user);\n  } catch (error) {\n    console.error('Login failed:', error);\n  }\n};\n</code></pre>"},{"location":"development/api-documentation/#curl-examples","title":"cURL Examples","text":""},{"location":"development/api-documentation/#login_1","title":"Login","text":"<pre><code>curl -X POST \\\n  https://api.dealsphere.com/graphql \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n    \"query\": \"mutation Login($input: LoginInput!) { login(input: $input) { token user { id email } } }\",\n    \"variables\": {\n      \"input\": {\n        \"email\": \"user@example.com\",\n        \"password\": \"password123\"\n      }\n    }\n  }'\n</code></pre>"},{"location":"development/api-documentation/#authenticated-request","title":"Authenticated Request","text":"<pre><code>curl -X POST \\\n  https://api.dealsphere.com/graphql \\\n  -H 'Content-Type: application/json' \\\n  -H 'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...' \\\n  -d '{\n    \"query\": \"query GetCurrentUser { me { id email firstName lastName } }\"\n  }'\n</code></pre>"},{"location":"development/api-documentation/#rate-limiting","title":"Rate Limiting","text":""},{"location":"development/api-documentation/#limits-by-endpoint","title":"Limits by Endpoint","text":"Endpoint Limit Window Login 5 requests 15 minutes Password Reset 3 requests 1 hour General API 100 requests 1 hour GraphQL Introspection 10 requests 1 minute"},{"location":"development/api-documentation/#rate-limit-headers","title":"Rate Limit Headers","text":"<pre><code>X-RateLimit-Limit: 100\nX-RateLimit-Remaining: 95\nX-RateLimit-Reset: 1640995200\nRetry-After: 3600\n</code></pre>"},{"location":"development/api-documentation/#handling-rate-limits","title":"Handling Rate Limits","text":"<pre><code>const handleRateLimit = (error: ApolloError) =&gt; {\n  if (error.graphQLErrors.some(e =&gt; e.extensions.code === 'RATE_LIMITED')) {\n    const retryAfter = error.graphQLErrors[0].extensions.details.retryAfter;\n\n    // Wait and retry\n    setTimeout(() =&gt; {\n      // Retry the request\n    }, retryAfter * 1000);\n  }\n};\n</code></pre>"},{"location":"development/api-documentation/#security-considerations","title":"Security Considerations","text":""},{"location":"development/api-documentation/#input-validation","title":"Input Validation","text":"<p>All inputs are validated on the server side:</p> <ul> <li>XSS Prevention: HTML content is sanitized</li> <li>SQL Injection: Parameterized queries prevent injection</li> <li>Input Length: Maximum field lengths enforced</li> <li>Format Validation: Email, phone, URL format validation</li> </ul>"},{"location":"development/api-documentation/#cors-policy","title":"CORS Policy","text":"<pre><code>Access-Control-Allow-Origin: https://app.dealsphere.com, https://admin.dealsphere.com\nAccess-Control-Allow-Methods: GET, POST, OPTIONS\nAccess-Control-Allow-Headers: Content-Type, Authorization\nAccess-Control-Allow-Credentials: true\n</code></pre>"},{"location":"development/api-documentation/#https-only","title":"HTTPS Only","text":"<p>All API endpoints require HTTPS in production. HTTP requests are automatically redirected to HTTPS.</p>"},{"location":"development/api-documentation/#websocket-subscriptions","title":"WebSocket Subscriptions","text":""},{"location":"development/api-documentation/#real-time-user-status","title":"Real-time User Status","text":"<pre><code>subscription UserStatusUpdates($organizationId: ID!) {\n  userStatusUpdates(organizationId: $organizationId) {\n    user {\n      id\n      email\n      isActive\n    }\n    status\n    timestamp\n  }\n}\n</code></pre>"},{"location":"development/api-documentation/#security-events","title":"Security Events","text":"<pre><code>subscription SecurityEvents {\n  securityEvents {\n    eventType\n    severity\n    message\n    timestamp\n    userAgent\n    ipAddress\n  }\n}\n</code></pre>"},{"location":"development/api-documentation/#api-versioning","title":"API Versioning","text":""},{"location":"development/api-documentation/#current-version-v1","title":"Current Version: v1","text":"<p>The API follows semantic versioning. Breaking changes will result in a new major version.</p>"},{"location":"development/api-documentation/#version-headers","title":"Version Headers","text":"<pre><code>API-Version: v1\n</code></pre>"},{"location":"development/api-documentation/#deprecation-policy","title":"Deprecation Policy","text":"<ul> <li>Deprecation Notice: 6 months before removal</li> <li>Migration Guide: Provided for breaking changes</li> <li>Backward Compatibility: Maintained for minor versions</li> </ul>"},{"location":"development/api-documentation/#testing-development","title":"Testing &amp; Development","text":""},{"location":"development/api-documentation/#graphql-playground","title":"GraphQL Playground","text":"<p>Available at: - Development: <code>http://localhost:8080/graphql-playground</code> - Staging: <code>https://staging-api.dealsphere.com/graphql-playground</code></p>"},{"location":"development/api-documentation/#schema-introspection","title":"Schema Introspection","text":"<pre><code>query IntrospectionQuery {\n  __schema {\n    queryType {\n      name\n      fields {\n        name\n        type {\n          name\n        }\n      }\n    }\n    mutationType {\n      name\n      fields {\n        name\n        args {\n          name\n          type {\n            name\n          }\n        }\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"development/api-documentation/#mock-data","title":"Mock Data","text":"<p>For development and testing, mock data is available:</p> <pre><code># Start with mock data\ndocker-compose -f docker-compose.dev.yml up -d\n\n# Import test data\nnpm run db:seed\n</code></pre> <p>This comprehensive API documentation provides all the information needed to integrate with the DealSphere platform's authentication and user management system.</p>"},{"location":"development/authentication-system/","title":"Authentication System","text":""},{"location":"development/authentication-system/#overview","title":"Overview","text":"<p>The DealSphere platform implements a comprehensive, security-first authentication system using JWT tokens, invitation-based user registration, and external observability for security auditing.</p>"},{"location":"development/authentication-system/#architecture","title":"Architecture","text":""},{"location":"development/authentication-system/#components","title":"Components","text":"<pre><code>graph TB\n    A[Frontend React App] --&gt; B[GraphQL API]\n    B --&gt; C[AuthService]\n    C --&gt; D[JwtService]\n    C --&gt; E[InvitationService]\n    C --&gt; F[PasswordResetService]\n    C --&gt; G[SecurityAuditService]\n\n    H[Admin User] --&gt; I[InviteUser Mutation]\n    I --&gt; E\n    E --&gt; J[Email Service]\n    J --&gt; K[SMTP Server]\n\n    L[New User] --&gt; M[CompleteRegistration]\n    M --&gt; E\n\n    N[User] --&gt; O[Login Mutation]\n    O --&gt; C\n\n    C --&gt; P[(PostgreSQL)]\n    G --&gt; Q[External Observability]\n\n    R[nginx] --&gt; B\n    R --&gt; S[Rate Limiting]\n    R --&gt; T[Security Headers]\n</code></pre>"},{"location":"development/authentication-system/#core-features","title":"Core Features","text":""},{"location":"development/authentication-system/#1-jwt-based-authentication","title":"1. JWT-Based Authentication","text":"<p>Location: <code>backend/commons/auth/src/main/java/com/dealsphere/backend/commons/auth/service/JwtServiceImpl.java</code></p> <ul> <li>Token Generation: Creates secure JWT tokens with user claims</li> <li>Token Validation: Validates token signature and expiration</li> <li>Automatic Refresh: Frontend automatically refreshes tokens before expiration</li> <li>Secure Storage: Tokens stored in localStorage with proper cleanup</li> </ul> <pre><code>@Service\npublic class JwtServiceImpl implements JwtService {\n\n    public String generateToken(UserProfile userProfile) {\n        return Jwts.builder()\n            .setSubject(userProfile.getEmail())\n            .claim(\"userId\", userProfile.getId())\n            .setIssuedAt(new Date())\n            .setExpiration(new Date(System.currentTimeMillis() + jwtExpirationMs))\n            .signWith(getSigningKey())\n            .compact();\n    }\n}\n</code></pre>"},{"location":"development/authentication-system/#2-invitation-based-registration","title":"2. Invitation-Based Registration","text":"<p>Flow: 1. Admin invites user via email through <code>InviteUserForm</code> 2. System generates secure invitation token 3. Email sent with registration link 4. User completes registration with temporary password 5. Account activated and user can log in</p> <p>Key Files: - Backend: <code>InvitationServiceImpl.java</code> - Frontend: <code>InviteUserForm.tsx</code>, <code>CompleteRegistrationForm.tsx</code></p>"},{"location":"development/authentication-system/#3-password-reset-system","title":"3. Password Reset System","text":"<p>Flow: 1. User requests password reset via email 2. System generates time-limited reset token 3. Reset link sent via email 4. User confirms reset with new password 5. Old sessions invalidated</p> <p>Security Features: - Rate limiting (3 attempts per hour) - Token expiration (15 minutes) - Anti-enumeration protection - Secure token generation</p>"},{"location":"development/authentication-system/#4-security-auditing","title":"4. Security Auditing","text":"<p>Location: <code>SecurityAuditServiceImpl.java</code></p> <p>All security events are logged to external observability systems with structured data:</p> <pre><code>@Override\n@Async\npublic void logSecurityEvent(SecurityEvent event) {\n    Map&lt;String, Object&gt; logFields = createStructuredLogFields(event);\n\n    switch (event.getSeverity()) {\n        case CRITICAL:\n            log.error(\"SECURITY_EVENT: {}\", event.getMessage(),\n                StructuredArguments.entries(logFields));\n            break;\n        // ... other severity levels\n    }\n}\n</code></pre> <p>Event Types: - Login success/failure - Password changes - Account modifications - Access denied events - XSS/SQL injection attempts - Privilege escalation attempts - Configuration changes</p>"},{"location":"development/authentication-system/#frontend-implementation","title":"Frontend Implementation","text":""},{"location":"development/authentication-system/#authentication-hook","title":"Authentication Hook","text":"<p>Location: <code>frontend/src/hooks/useAuth.ts</code></p> <pre><code>export const useAuth = () =&gt; {\n  const dispatch = useAppDispatch();\n  const auth = useAppSelector(state =&gt; state.auth);\n\n  const login = useCallback(async (email: string, password: string) =&gt; {\n    dispatch(loginStart());\n    try {\n      const result = await loginMutation({ variables: { input: { email, password } } });\n      const { token, user } = result.data.login;\n\n      localStorage.setItem('auth_token', token);\n      dispatch(loginSuccess({ user, token }));\n\n      return { user, token };\n    } catch (error) {\n      dispatch(loginFailure(error.message));\n      throw error;\n    }\n  }, [dispatch, loginMutation]);\n\n  // ... other auth methods\n};\n</code></pre>"},{"location":"development/authentication-system/#form-validation-security","title":"Form Validation &amp; Security","text":"<p>Location: <code>frontend/src/utils/validation.ts</code></p> <p>All forms include comprehensive validation:</p> <pre><code>export const sanitizeXSS = (input: string): string =&gt; {\n  if (!input) return input;\n  let sanitized = input;\n  XSS_PATTERNS.forEach(pattern =&gt; {\n    sanitized = sanitized.replace(pattern, '');\n  });\n  // HTML encode special characters\n  return sanitized\n    .replace(/&amp;/g, '&amp;amp;')\n    .replace(/&lt;/g, '&amp;lt;')\n    .replace(/&gt;/g, '&amp;gt;')\n    .replace(/\"/g, '&amp;quot;')\n    .replace(/'/g, '&amp;#x27;')\n    .replace(/\\//g, '&amp;#x2F;');\n};\n\nexport const detectSQLInjection = (input: string): boolean =&gt; {\n  if (!input) return false;\n  const sqlPatterns = [\n    /(\\b(union|select|insert|update|delete|drop|create|alter|exec|execute)\\b)/i,\n    /(\\bor\\b.*\\b=\\b.*\\bor\\b)/i,\n    /(;|\\-\\-|\\*|\\/\\*)/,\n    // ... more patterns\n  ];\n  return sqlPatterns.some(pattern =&gt; pattern.test(input));\n};\n</code></pre>"},{"location":"development/authentication-system/#security-features","title":"Security Features","text":""},{"location":"development/authentication-system/#1-rate-limiting-nginx","title":"1. Rate Limiting (nginx)","text":"<p>Location: <code>nginx/nginx.conf</code></p> <pre><code># Rate limiting zones\nlimit_req_zone $binary_remote_addr zone=auth:10m rate=5r/m;\nlimit_req_zone $binary_remote_addr zone=api:10m rate=10r/m;\nlimit_req_zone $binary_remote_addr zone=reset:10m rate=1r/m;\n\nlocation /api/auth/ {\n    limit_req zone=auth burst=10 nodelay;\n    limit_req_status 429;\n    # ... proxy configuration\n}\n</code></pre>"},{"location":"development/authentication-system/#2-security-headers","title":"2. Security Headers","text":"<pre><code># Security headers\nadd_header X-Frame-Options \"SAMEORIGIN\" always;\nadd_header X-Content-Type-Options \"nosniff\" always;\nadd_header X-XSS-Protection \"1; mode=block\" always;\nadd_header Referrer-Policy \"strict-origin-when-cross-origin\" always;\nadd_header Permissions-Policy \"geolocation=(), microphone=(), camera=()\" always;\n\n# Content Security Policy\nadd_header Content-Security-Policy \"\n    default-src 'self';\n    script-src 'self' 'unsafe-inline' 'unsafe-eval' https://cdnjs.cloudflare.com;\n    style-src 'self' 'unsafe-inline' https://fonts.googleapis.com;\n    font-src 'self' https://fonts.gstatic.com;\n    img-src 'self' data: https:;\n    connect-src 'self' ws: wss: https://api.example.com;\n\" always;\n</code></pre>"},{"location":"development/authentication-system/#3-input-validation","title":"3. Input Validation","text":"<p>Backend (<code>ValidationConfig.java</code>): - XSS pattern detection and sanitization - SQL injection detection - Input length validation - Pattern matching validation</p> <p>Frontend: - Real-time validation with debouncing - XSS/SQL injection detection - Email format validation - Password strength requirements</p>"},{"location":"development/authentication-system/#4-cors-configuration","title":"4. CORS Configuration","text":"<pre><code># CORS headers\nadd_header 'Access-Control-Allow-Origin' '$allowed_origin' always;\nadd_header 'Access-Control-Allow-Methods' 'GET, POST, PUT, DELETE, OPTIONS' always;\nadd_header 'Access-Control-Allow-Headers' 'Origin, X-Requested-With, Content-Type, Accept, Authorization' always;\nadd_header 'Access-Control-Allow-Credentials' 'true' always;\nadd_header 'Access-Control-Max-Age' '86400' always;\n</code></pre>"},{"location":"development/authentication-system/#database-schema","title":"Database Schema","text":""},{"location":"development/authentication-system/#core-tables","title":"Core Tables","text":"<pre><code>-- User profiles\nCREATE TABLE user_profiles (\n    id VARCHAR(36) PRIMARY KEY,\n    email VARCHAR(255) UNIQUE NOT NULL,\n    first_name VARCHAR(100) NOT NULL,\n    last_name VARCHAR(100) NOT NULL,\n    organization_id VARCHAR(36) NOT NULL,\n    is_active BOOLEAN DEFAULT true,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    roles TEXT[] -- Array of role IDs\n);\n\n-- User credentials\nCREATE TABLE user_credentials (\n    user_id VARCHAR(36) PRIMARY KEY,\n    username VARCHAR(255) UNIQUE NOT NULL,\n    password_hash VARCHAR(255) NOT NULL,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    FOREIGN KEY (user_id) REFERENCES user_profiles(id)\n);\n\n-- User invitations\nCREATE TABLE user_invitations (\n    id VARCHAR(36) PRIMARY KEY,\n    email VARCHAR(255) NOT NULL,\n    first_name VARCHAR(100) NOT NULL,\n    last_name VARCHAR(100) NOT NULL,\n    organization_id VARCHAR(36) NOT NULL,\n    invited_by_user_id VARCHAR(36) NOT NULL,\n    invitation_token VARCHAR(255) UNIQUE NOT NULL,\n    temporary_password VARCHAR(255) NOT NULL,\n    expires_at TIMESTAMP NOT NULL,\n    is_used BOOLEAN DEFAULT false,\n    used_at TIMESTAMP,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\n\n-- Password reset tokens\nCREATE TABLE password_reset_tokens (\n    id VARCHAR(36) PRIMARY KEY,\n    user_id VARCHAR(36) NOT NULL,\n    reset_token VARCHAR(255) UNIQUE NOT NULL,\n    expires_at TIMESTAMP NOT NULL,\n    is_used BOOLEAN DEFAULT false,\n    used_at TIMESTAMP,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    FOREIGN KEY (user_id) REFERENCES user_profiles(id)\n);\n\n-- Security events (for external observability reference)\nCREATE TABLE security_events (\n    id VARCHAR(36) PRIMARY KEY,\n    event_type VARCHAR(50) NOT NULL,\n    severity VARCHAR(20) NOT NULL,\n    user_id VARCHAR(36),\n    session_id VARCHAR(100),\n    ip_address VARCHAR(45),\n    user_agent VARCHAR(500),\n    endpoint VARCHAR(200),\n    message VARCHAR(1000) NOT NULL,\n    risk_score INTEGER,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\n</code></pre>"},{"location":"development/authentication-system/#graphql-api","title":"GraphQL API","text":""},{"location":"development/authentication-system/#mutations","title":"Mutations","text":"<pre><code>type Mutation {\n    # Authentication\n    login(input: LoginInput!): AuthPayload!\n    refreshToken: AuthPayload!\n\n    # User Management\n    inviteUser(input: InviteUserInput!): InvitationPayload!\n    completeRegistration(input: CompleteRegistrationInput!): AuthPayload!\n\n    # Password Management\n    requestPasswordReset(input: PasswordResetRequestInput!): PasswordResetPayload!\n    confirmPasswordReset(input: PasswordResetConfirmInput!): String!\n    validatePasswordResetToken(resetToken: String!): Boolean!\n}\n\ntype AuthPayload {\n    token: String!\n    user: UserProfile!\n}\n\ntype InvitationPayload {\n    success: Boolean!\n    message: String!\n    invitationId: String\n}\n</code></pre>"},{"location":"development/authentication-system/#testing","title":"Testing","text":""},{"location":"development/authentication-system/#backend-tests","title":"Backend Tests","text":"<p>Coverage: 90%+</p> <ul> <li>AuthServiceImplTest: Unit tests for authentication flows</li> <li>JwtServiceImplTest: Token generation/validation tests</li> <li>SecurityAuditServiceImplTest: Security logging tests</li> <li>Integration Tests: End-to-end authentication flows</li> </ul>"},{"location":"development/authentication-system/#frontend-tests","title":"Frontend Tests","text":"<p>Coverage: 85%+</p> <ul> <li>Login.test.tsx: Login form and validation tests</li> <li>InviteUserForm.test.tsx: User invitation tests</li> <li>PasswordReset.test.tsx: Password reset flow tests</li> <li>useAuth.test.ts: Authentication hook tests</li> <li>validation.test.ts: Security validation tests</li> <li>Integration Tests: Complete authentication flows</li> </ul>"},{"location":"development/authentication-system/#test-commands","title":"Test Commands","text":"<pre><code># Backend tests\ncd backend\n./gradlew test\n\n# Frontend tests\ncd frontend\npnpm test                    # Unit tests\npnpm test:coverage          # Coverage report\npnpm test:e2e              # End-to-end tests\n</code></pre>"},{"location":"development/authentication-system/#deployment-considerations","title":"Deployment Considerations","text":""},{"location":"development/authentication-system/#environment-variables","title":"Environment Variables","text":"<pre><code># JWT Configuration\nJWT_SECRET=your-super-secure-secret-key-here\nJWT_EXPIRATION_MS=86400000  # 24 hours\n\n# Database\nDATABASE_URL=postgresql://user:pass@host:5432/dealsphere\n\n# Email Configuration\nSMTP_HOST=smtp.example.com\nSMTP_PORT=587\nSMTP_USER=noreply@dealsphere.com\nSMTP_PASS=smtp-password\n\n# Security\nBCRYPT_ROUNDS=12\nRATE_LIMIT_MAX_ATTEMPTS=5\nPASSWORD_RESET_EXPIRY_MINUTES=15\n</code></pre>"},{"location":"development/authentication-system/#security-checklist","title":"Security Checklist","text":"<ul> <li>[ ] JWT secrets are properly secured</li> <li>[ ] Database connections use SSL</li> <li>[ ] SMTP credentials are encrypted</li> <li>[ ] Rate limiting is configured</li> <li>[ ] Security headers are enabled</li> <li>[ ] Input validation is comprehensive</li> <li>[ ] Audit logging is functional</li> <li>[ ] CORS is properly configured</li> <li>[ ] SSL certificates are valid</li> <li>[ ] Backup and recovery tested</li> </ul>"},{"location":"development/authentication-system/#monitoring-observability","title":"Monitoring &amp; Observability","text":""},{"location":"development/authentication-system/#security-events","title":"Security Events","text":"<p>All security events are logged to external observability systems (ELK, Datadog, etc.) with structured data:</p> <pre><code>{\n  \"message\": \"SECURITY_EVENT: User logged in successfully\",\n  \"event_type\": \"LOGIN_SUCCESS\",\n  \"severity\": \"LOW\",\n  \"user_id\": \"user-123\",\n  \"ip_address\": \"192.168.1.100\",\n  \"session_id\": \"session-456\",\n  \"endpoint\": \"/api/auth/login\",\n  \"risk_score\": 10,\n  \"service\": \"dealsphere-auth\",\n  \"timestamp\": \"2025-01-16T10:30:00Z\"\n}\n</code></pre>"},{"location":"development/authentication-system/#key-metrics-to-monitor","title":"Key Metrics to Monitor","text":"<ol> <li>Authentication Metrics:</li> <li>Login success/failure rates</li> <li>Token validation failures</li> <li>Password reset requests</li> <li> <p>Account lockouts</p> </li> <li> <p>Security Metrics:</p> </li> <li>XSS/SQL injection attempts</li> <li>Rate limit violations</li> <li>Suspicious IP activity</li> <li> <p>Geographic anomalies</p> </li> <li> <p>Performance Metrics:</p> </li> <li>Authentication response times</li> <li>Token generation latency</li> <li>Database query performance</li> <li>Email delivery success rates</li> </ol>"},{"location":"development/authentication-system/#troubleshooting","title":"Troubleshooting","text":""},{"location":"development/authentication-system/#common-issues","title":"Common Issues","text":"<ol> <li>Token Validation Failures</li> <li>Check JWT secret configuration</li> <li>Verify token expiration settings</li> <li> <p>Ensure clock synchronization</p> </li> <li> <p>Email Delivery Issues</p> </li> <li>Verify SMTP configuration</li> <li>Check spam folder policies</li> <li> <p>Monitor email service quotas</p> </li> <li> <p>Rate Limiting False Positives</p> </li> <li>Review nginx rate limit zones</li> <li>Check IP whitelisting</li> <li> <p>Monitor legitimate traffic patterns</p> </li> <li> <p>Database Connection Issues</p> </li> <li>Verify connection pool settings</li> <li>Check SSL certificate validity</li> <li>Monitor connection timeouts</li> </ol>"},{"location":"development/authentication-system/#debug-commands","title":"Debug Commands","text":"<pre><code># Check JWT token validity\ncurl -H \"Authorization: Bearer &lt;token&gt;\" http://localhost:8080/api/auth/validate\n\n# Test email configuration\ncurl -X POST -d '{\"email\":\"test@example.com\"}' \\\n  -H \"Content-Type: application/json\" \\\n  http://localhost:8080/api/auth/request-password-reset\n\n# Monitor security events\ntail -f /var/log/dealsphere/security.log | jq '.severity==\"HIGH\"'\n</code></pre>"},{"location":"development/cypress-e2e-testing/","title":"Cypress E2E Testing Guide","text":"<p>This guide provides comprehensive documentation for the Cypress end-to-end testing setup in the DealSphere platform, covering test architecture, best practices, and CI/CD integration.</p>"},{"location":"development/cypress-e2e-testing/#overview","title":"Overview","text":"<p>The DealSphere platform uses Cypress for comprehensive E2E testing, focusing on:</p> <ul> <li>Authentication Flows - Login, JWT token management, Redux Saga integration</li> <li>User Interface - Form validation, navigation, error handling</li> <li>API Integration - GraphQL mutations and queries</li> <li>State Management - Redux store persistence and hydration</li> <li>Cross-Browser Testing - Consistent behavior across environments</li> </ul>"},{"location":"development/cypress-e2e-testing/#test-architecture","title":"Test Architecture","text":""},{"location":"development/cypress-e2e-testing/#directory-structure","title":"Directory Structure","text":"<pre><code>frontend/cypress/\n\u251c\u2500\u2500 e2e/                          # End-to-end test specs\n\u2502   \u2514\u2500\u2500 auth/\n\u2502       \u251c\u2500\u2500 login-flow.cy.ts      # Complete login workflow\n\u2502       \u251c\u2500\u2500 jwt-storage.cy.ts     # Token storage verification\n\u2502       \u2514\u2500\u2500 basic-login.cy.ts     # Basic functionality tests\n\u251c\u2500\u2500 support/                      # Cypress support files\n\u2502   \u251c\u2500\u2500 commands.ts               # Custom commands\n\u2502   \u2514\u2500\u2500 e2e.ts                   # Global configuration\n\u251c\u2500\u2500 fixtures/                     # Test data\n\u2502   \u2514\u2500\u2500 users.json               # User credentials\n\u251c\u2500\u2500 videos/                       # Test recordings (CI)\n\u251c\u2500\u2500 screenshots/                  # Failure screenshots\n\u2514\u2500\u2500 cypress.config.ts            # Cypress configuration\n</code></pre>"},{"location":"development/cypress-e2e-testing/#configuration","title":"Configuration","text":"<p>cypress.config.ts:</p> <pre><code>import { defineConfig } from 'cypress'\n\nexport default defineConfig({\n  e2e: {\n    baseUrl: 'http://localhost',\n    viewportWidth: 1280,\n    viewportHeight: 720,\n    video: true,\n    screenshotOnRunFailure: true,\n    defaultCommandTimeout: 10000,\n    requestTimeout: 10000,\n    responseTimeout: 10000,\n    pageLoadTimeout: 30000,\n    supportFile: 'cypress/support/e2e.ts',\n    specPattern: 'cypress/e2e/**/*.cy.{js,jsx,ts,tsx}',\n  },\n  env: {\n    VITE_API_URL: 'http://localhost/api',\n    VITE_GRAPHQL_URL: 'http://localhost/api/graphql',\n  }\n})\n</code></pre>"},{"location":"development/cypress-e2e-testing/#test-categories","title":"Test Categories","text":""},{"location":"development/cypress-e2e-testing/#1-authentication-flow-tests","title":"1. Authentication Flow Tests","text":"<p>File: <code>cypress/e2e/auth/login-flow.cy.ts</code></p> <p>Tests the complete authentication workflow including:</p>"},{"location":"development/cypress-e2e-testing/#login-form-validation","title":"Login Form Validation","text":"<pre><code>it('should display login form correctly', () =&gt; {\n  cy.visit('/login')\n\n  // Verify form elements\n  cy.get('input[name=\"email\"]').should('be.visible')\n  cy.get('input[name=\"password\"]').should('be.visible')\n  cy.get('button[type=\"submit\"]').should('contain.text', 'Sign In')\n})\n</code></pre>"},{"location":"development/cypress-e2e-testing/#redux-saga-integration","title":"Redux Saga Integration","text":"<pre><code>it('should successfully login and store JWT token', () =&gt; {\n  // Intercept GraphQL login mutation\n  cy.intercept('POST', '/api/graphql', (req) =&gt; {\n    if (req.body.query.includes('mutation Login')) {\n      req.alias = 'loginMutation'\n    }\n  })\n\n  // Perform login\n  cy.get('input[name=\"email\"]').type('admin@dealsphere.com')\n  cy.get('input[name=\"password\"]').type('password123')\n  cy.get('button[type=\"submit\"]').click()\n\n  // Verify API call and response\n  cy.wait('@loginMutation').then((interception) =&gt; {\n    expect(interception.response?.statusCode).to.eq(200)\n    expect(interception.response?.body?.data?.login.token).to.exist\n  })\n})\n</code></pre>"},{"location":"development/cypress-e2e-testing/#state-persistence","title":"State Persistence","text":"<pre><code>it('should persist auth state on page refresh', () =&gt; {\n  // Login first\n  cy.login('admin@dealsphere.com', 'password123')\n  cy.url().should('include', '/dashboard')\n\n  // Refresh page\n  cy.reload()\n\n  // Should still be authenticated\n  cy.url().should('include', '/dashboard')\n  cy.window().then((win) =&gt; {\n    expect(win.localStorage.getItem('authToken')).to.exist\n  })\n})\n</code></pre>"},{"location":"development/cypress-e2e-testing/#2-jwt-storage-tests","title":"2. JWT Storage Tests","text":"<p>File: <code>cypress/e2e/auth/jwt-storage.cy.ts</code></p> <p>Focuses specifically on token management:</p>"},{"location":"development/cypress-e2e-testing/#localstorage-verification","title":"LocalStorage Verification","text":"<pre><code>it('should store JWT token with correct key', () =&gt; {\n  cy.login('admin@dealsphere.com', 'password123')\n\n  cy.window().then((win) =&gt; {\n    const token = win.localStorage.getItem('authToken')\n    const userData = win.localStorage.getItem('userData')\n\n    // Verify token format (JWT structure)\n    expect(token).to.match(/^eyJ[A-Za-z0-9-_=]+\\.[A-Za-z0-9-_=]+\\.?[A-Za-z0-9-_.+/=]*$/)\n\n    // Verify user data structure\n    const user = JSON.parse(userData!)\n    expect(user).to.have.property('id')\n    expect(user).to.have.property('email', 'admin@dealsphere.com')\n  })\n})\n</code></pre>"},{"location":"development/cypress-e2e-testing/#token-cleanup","title":"Token Cleanup","text":"<pre><code>it('should clear tokens on logout', () =&gt; {\n  cy.login('admin@dealsphere.com', 'password123')\n\n  // Verify tokens exist\n  cy.window().then((win) =&gt; {\n    expect(win.localStorage.getItem('authToken')).to.exist\n  })\n\n  // Logout\n  cy.get('[data-testid=\"logout-button\"]').click()\n\n  // Verify tokens are cleared\n  cy.window().then((win) =&gt; {\n    expect(win.localStorage.getItem('authToken')).to.be.null\n    expect(win.localStorage.getItem('userData')).to.be.null\n  })\n})\n</code></pre>"},{"location":"development/cypress-e2e-testing/#3-basic-functionality-tests","title":"3. Basic Functionality Tests","text":"<p>File: <code>cypress/e2e/auth/basic-login.cy.ts</code></p> <p>Simplified tests for quick verification:</p> <pre><code>it('should test actual login with real backend', () =&gt; {\n  cy.visit('/login')\n\n  cy.get('input[name=\"email\"]').type('admin@dealsphere.com')\n  cy.get('input[name=\"password\"]').type('password123')\n  cy.get('button[type=\"submit\"]').click()\n\n  // Wait for processing\n  cy.wait(3000)\n\n  // Check success indicators\n  cy.window().then((win) =&gt; {\n    const token = win.localStorage.getItem('authToken')\n    if (token) {\n      expect(token).to.exist\n      cy.log('\u2705 Login successful - Token stored')\n    }\n  })\n})\n</code></pre>"},{"location":"development/cypress-e2e-testing/#custom-commands","title":"Custom Commands","text":""},{"location":"development/cypress-e2e-testing/#authentication-commands","title":"Authentication Commands","text":"<p>File: <code>cypress/support/commands.ts</code></p> <pre><code>// Login command for reusable authentication\nCypress.Commands.add('login', (email: string, password: string) =&gt; {\n  cy.visit('/login')\n\n  cy.get('input[name=\"email\"]').type(email)\n  cy.get('input[name=\"password\"]').type(password)\n\n  // Intercept login mutation\n  cy.intercept('POST', '/api/graphql', (req) =&gt; {\n    if (req.body.query.includes('mutation Login')) {\n      req.alias = 'loginMutation'\n    }\n  })\n\n  cy.get('button[type=\"submit\"]').click()\n  cy.wait('@loginMutation')\n})\n\n// Clear authentication state\nCypress.Commands.add('clearAuth', () =&gt; {\n  cy.window().then((win) =&gt; {\n    win.localStorage.removeItem('authToken')\n    win.localStorage.removeItem('userData')\n  })\n})\n</code></pre>"},{"location":"development/cypress-e2e-testing/#state-management-commands","title":"State Management Commands","text":"<pre><code>// Access Redux store (if exposed)\nCypress.Commands.add('getReduxState', () =&gt; {\n  cy.window().its('store').invoke('getState')\n})\n\n// Wait for specific Redux actions\nCypress.Commands.add('waitForAction', (actionType: string) =&gt; {\n  cy.window().then((win) =&gt; {\n    return new Cypress.Promise((resolve) =&gt; {\n      const store = (win as any).store\n      if (store) {\n        const unsubscribe = store.subscribe(() =&gt; {\n          const state = store.getState()\n          unsubscribe()\n          resolve(state)\n        })\n      }\n    })\n  })\n})\n</code></pre>"},{"location":"development/cypress-e2e-testing/#test-data-management","title":"Test Data Management","text":""},{"location":"development/cypress-e2e-testing/#user-fixtures","title":"User Fixtures","text":"<p>File: <code>cypress/fixtures/users.json</code></p> <pre><code>{\n  \"admin\": {\n    \"email\": \"admin@dealsphere.com\",\n    \"password\": \"password123\",\n    \"expectedData\": {\n      \"firstName\": \"Admin\",\n      \"lastName\": \"User\",\n      \"roles\": [\"ADMIN\"]\n    }\n  },\n  \"testUser\": {\n    \"email\": \"test@dealsphere.com\",\n    \"password\": \"testpass123\",\n    \"expectedData\": {\n      \"firstName\": \"Test\",\n      \"lastName\": \"User\",\n      \"roles\": [\"USER\"]\n    }\n  }\n}\n</code></pre>"},{"location":"development/cypress-e2e-testing/#dynamic-test-data","title":"Dynamic Test Data","text":"<pre><code>// Load fixtures in tests\ndescribe('User Management', () =&gt; {\n  let users: any\n\n  before(() =&gt; {\n    cy.fixture('users').then((userData) =&gt; {\n      users = userData\n    })\n  })\n\n  it('should login with admin user', () =&gt; {\n    cy.login(users.admin.email, users.admin.password)\n    // Test continues...\n  })\n})\n</code></pre>"},{"location":"development/cypress-e2e-testing/#running-tests","title":"Running Tests","text":""},{"location":"development/cypress-e2e-testing/#local-development","title":"Local Development","text":"<pre><code># Interactive mode (Cypress Test Runner)\ncd frontend\npnpm cy:open\n\n# Headless mode\npnpm cy:run\n\n# Specific test file\npnpm cy:run --spec \"cypress/e2e/auth/login-flow.cy.ts\"\n\n# With specific browser\npnpm cy:run --browser chrome\n\n# With environment variables\nCYPRESS_BASE_URL=http://localhost:3000 pnpm cy:run\n</code></pre>"},{"location":"development/cypress-e2e-testing/#cicd-environment","title":"CI/CD Environment","text":"<pre><code># Headless with artifacts\npnpm cy:run --config video=true,screenshotOnRunFailure=true\n\n# Multiple browsers (parallel)\npnpm cy:run --browser chrome &amp;\npnpm cy:run --browser firefox &amp;\nwait\n\n# Record to Cypress Dashboard\npnpm cy:run --record --key &lt;cypress-record-key&gt;\n</code></pre>"},{"location":"development/cypress-e2e-testing/#environment-configuration","title":"Environment Configuration","text":""},{"location":"development/cypress-e2e-testing/#development-environment","title":"Development Environment","text":"<pre><code># .env.development\nCYPRESS_BASE_URL=http://localhost\nCYPRESS_VIDEO=true\nCYPRESS_SCREENSHOTS=true\n</code></pre>"},{"location":"development/cypress-e2e-testing/#staging-environment","title":"Staging Environment","text":"<pre><code># .env.staging\nCYPRESS_BASE_URL=https://staging.dealsphere.com\nCYPRESS_VIDEO=true\nCYPRESS_SCREENSHOTS=true\nCYPRESS_VIDEO_COMPRESSION=32\n</code></pre>"},{"location":"development/cypress-e2e-testing/#production-environment","title":"Production Environment","text":"<pre><code># .env.production\nCYPRESS_BASE_URL=https://dealsphere.com\nCYPRESS_VIDEO=false\nCYPRESS_SCREENSHOTS=false\n</code></pre>"},{"location":"development/cypress-e2e-testing/#best-practices","title":"Best Practices","text":""},{"location":"development/cypress-e2e-testing/#1-test-design-principles","title":"1. Test Design Principles","text":""},{"location":"development/cypress-e2e-testing/#atomic-tests","title":"Atomic Tests","text":"<pre><code>// \u2705 Good - Single responsibility\nit('should store JWT token in localStorage', () =&gt; {\n  cy.login('admin@dealsphere.com', 'password123')\n  cy.window().then((win) =&gt; {\n    expect(win.localStorage.getItem('authToken')).to.exist\n  })\n})\n\n// \u274c Bad - Multiple responsibilities\nit('should login and navigate and check profile', () =&gt; {\n  // Too many assertions in one test\n})\n</code></pre>"},{"location":"development/cypress-e2e-testing/#reliable-selectors","title":"Reliable Selectors","text":"<pre><code>// \u2705 Good - Data attributes\ncy.get('[data-testid=\"login-button\"]').click()\n\n// \u2705 Good - Semantic selectors\ncy.get('button[type=\"submit\"]').click()\n\n// \u274c Bad - Fragile selectors\ncy.get('.css-1234567').click()\n</code></pre>"},{"location":"development/cypress-e2e-testing/#2-network-management","title":"2. Network Management","text":""},{"location":"development/cypress-e2e-testing/#graphql-interception","title":"GraphQL Interception","text":"<pre><code>// Intercept specific GraphQL operations\ncy.intercept('POST', '/api/graphql', (req) =&gt; {\n  if (req.body.query.includes('mutation Login')) {\n    req.alias = 'loginMutation'\n  }\n  if (req.body.query.includes('query GetUser')) {\n    req.alias = 'getUserQuery'\n  }\n})\n</code></pre>"},{"location":"development/cypress-e2e-testing/#mock-responses","title":"Mock Responses","text":"<pre><code>// Mock failed login\ncy.intercept('POST', '/api/graphql', {\n  statusCode: 200,\n  body: {\n    errors: [{ message: 'Invalid credentials' }]\n  }\n}).as('failedLogin')\n</code></pre>"},{"location":"development/cypress-e2e-testing/#3-wait-strategies","title":"3. Wait Strategies","text":""},{"location":"development/cypress-e2e-testing/#explicit-waits","title":"Explicit Waits","text":"<pre><code>// Wait for API calls\ncy.wait('@loginMutation')\n\n// Wait for elements\ncy.get('[data-testid=\"dashboard\"]', { timeout: 10000 })\n\n// Wait for conditions\ncy.window().then((win) =&gt; {\n  cy.waitUntil(() =&gt; win.localStorage.getItem('authToken'))\n})\n</code></pre>"},{"location":"development/cypress-e2e-testing/#custom-wait-commands","title":"Custom Wait Commands","text":"<pre><code>// Wait for application to be ready\nCypress.Commands.add('waitForApp', () =&gt; {\n  cy.visit('/')\n  cy.get('[data-testid=\"app-loaded\"]').should('exist')\n  cy.window().its('store').should('exist')\n})\n</code></pre>"},{"location":"development/cypress-e2e-testing/#4-error-handling","title":"4. Error Handling","text":""},{"location":"development/cypress-e2e-testing/#graceful-failures","title":"Graceful Failures","text":"<pre><code>it('should handle network errors gracefully', () =&gt; {\n  // Simulate network failure\n  cy.intercept('POST', '/api/graphql', { forceNetworkError: true })\n\n  cy.get('input[name=\"email\"]').type('admin@dealsphere.com')\n  cy.get('input[name=\"password\"]').type('password123')\n  cy.get('button[type=\"submit\"]').click()\n\n  // Should show error message\n  cy.get('.error-message').should('be.visible')\n})\n</code></pre>"},{"location":"development/cypress-e2e-testing/#debugging-and-troubleshooting","title":"Debugging and Troubleshooting","text":""},{"location":"development/cypress-e2e-testing/#debug-mode","title":"Debug Mode","text":"<pre><code># Run with debug output\nDEBUG=cypress:* pnpm cy:run\n\n# Specific debug channels\nDEBUG=cypress:server:* pnpm cy:run\n</code></pre>"},{"location":"development/cypress-e2e-testing/#test-debugging","title":"Test Debugging","text":"<pre><code>// Add debug breakpoints\ncy.debug()\n\n// Log values\ncy.get('input[name=\"email\"]').then(($el) =&gt; {\n  cy.log('Email input value:', $el.val())\n})\n\n// Pause test execution\ncy.pause()\n</code></pre>"},{"location":"development/cypress-e2e-testing/#common-issues","title":"Common Issues","text":""},{"location":"development/cypress-e2e-testing/#1-element-not-found","title":"1. Element Not Found","text":"<pre><code>// Solution: Use proper waits\ncy.get('[data-testid=\"element\"]', { timeout: 10000 })\n  .should('be.visible')\n  .click()\n</code></pre>"},{"location":"development/cypress-e2e-testing/#2-race-conditions","title":"2. Race Conditions","text":"<pre><code>// Solution: Wait for API calls\ncy.intercept('POST', '/api/graphql').as('apiCall')\ncy.get('button').click()\ncy.wait('@apiCall')\n</code></pre>"},{"location":"development/cypress-e2e-testing/#3-state-management-issues","title":"3. State Management Issues","text":"<pre><code>// Solution: Clear state between tests\nbeforeEach(() =&gt; {\n  cy.clearAuth()\n  cy.window().then((win) =&gt; {\n    win.localStorage.clear()\n    win.sessionStorage.clear()\n  })\n})\n</code></pre>"},{"location":"development/cypress-e2e-testing/#performance-optimization","title":"Performance Optimization","text":""},{"location":"development/cypress-e2e-testing/#test-execution-speed","title":"Test Execution Speed","text":"<pre><code>// Minimize DOM queries\ncy.get('[data-testid=\"form\"]').within(() =&gt; {\n  cy.get('input[name=\"email\"]').type('test@example.com')\n  cy.get('input[name=\"password\"]').type('password')\n  cy.get('button[type=\"submit\"]').click()\n})\n\n// Use aliases for reused elements\ncy.get('[data-testid=\"login-form\"]').as('loginForm')\ncy.get('@loginForm').find('input[name=\"email\"]').type('test@example.com')\n</code></pre>"},{"location":"development/cypress-e2e-testing/#parallel-execution","title":"Parallel Execution","text":"<pre><code># GitHub Actions parallel execution\n- name: Run Cypress tests\n  uses: cypress-io/github-action@v6\n  with:\n    record: true\n    parallel: true\n    group: 'UI - Chrome'\n</code></pre>"},{"location":"development/cypress-e2e-testing/#integration-with-cicd","title":"Integration with CI/CD","text":""},{"location":"development/cypress-e2e-testing/#github-actions","title":"GitHub Actions","text":"<pre><code>- name: Run Cypress E2E tests\n  uses: cypress-io/github-action@v6\n  with:\n    working-directory: frontend\n    install: false\n    start: echo \"Services already running\"\n    wait-on: 'http://localhost'\n    wait-on-timeout: 120\n    config: baseUrl=http://localhost,video=true\n  env:\n    CYPRESS_BASE_URL: http://localhost\n</code></pre>"},{"location":"development/cypress-e2e-testing/#artifact-collection","title":"Artifact Collection","text":"<pre><code>- name: Upload Cypress videos\n  uses: actions/upload-artifact@v4\n  if: failure()\n  with:\n    name: cypress-videos-${{ github.run_number }}\n    path: frontend/cypress/videos\n    retention-days: 7\n</code></pre>"},{"location":"development/cypress-e2e-testing/#monitoring-and-reporting","title":"Monitoring and Reporting","text":""},{"location":"development/cypress-e2e-testing/#test-results-dashboard","title":"Test Results Dashboard","text":"<ul> <li>Cypress Dashboard - Record test runs for team visibility</li> <li>GitHub Actions - Built-in test reporting</li> <li>Allure Reports - Comprehensive test reporting (optional)</li> </ul>"},{"location":"development/cypress-e2e-testing/#metrics-to-track","title":"Metrics to Track","text":"<ul> <li>Test Execution Time - Monitor for performance degradation</li> <li>Flaky Test Rate - Identify unstable tests</li> <li>Code Coverage - E2E coverage mapping</li> <li>Failure Patterns - Common failure points</li> </ul>"},{"location":"development/cypress-e2e-testing/#related-documentation","title":"Related Documentation","text":"<ul> <li>Local CI/CD Setup</li> <li>GitHub Actions Guide</li> <li>Environment Configuration</li> <li>Frontend Testing Strategy</li> </ul>"},{"location":"development/functional-test-driven-development/","title":"Functional Test-Driven Development Guide","text":""},{"location":"development/functional-test-driven-development/#overview","title":"Overview","text":"<p>This guide explains how to use the DealSphere Phase 1 Functional Test Suite for Test-Driven Development (TDD) at the functional level. The comprehensive test suite was designed upfront to guide development and ensure 100% coverage of business requirements.</p>"},{"location":"development/functional-test-driven-development/#quick-start","title":"Quick Start","text":""},{"location":"development/functional-test-driven-development/#1-understanding-the-test-suite-structure","title":"1. Understanding the Test Suite Structure","text":"<pre><code>cypress/e2e/\n\u251c\u2500\u2500 epic-1-core-auth/         # Weeks 1-2: Authentication &amp; RBAC\n\u251c\u2500\u2500 epic-2-users-documents/   # Weeks 3-4: User Management &amp; Documents\n\u251c\u2500\u2500 epic-3-capital-waterfall/ # Weeks 5-6: Capital Calls &amp; Waterfalls\n\u2514\u2500\u2500 epic-4-workflows-ai/      # Weeks 7-8: Workflows &amp; AI Integration\n</code></pre>"},{"location":"development/functional-test-driven-development/#2-current-development-status","title":"2. Current Development Status","text":"<p>All tests are initially failing - this is by design! The failing tests serve as your development roadmap and executable specifications.</p>"},{"location":"development/functional-test-driven-development/#using-tests-to-guide-development","title":"Using Tests to Guide Development","text":""},{"location":"development/functional-test-driven-development/#step-1-identify-your-development-epic","title":"Step 1: Identify Your Development Epic","text":"<p>Based on the current development timeline:</p> Weeks Epic Focus Area Test Directory 1-2 Epic 1 Core Framework &amp; Auth <code>epic-1-core-auth/</code> 3-4 Epic 2 User Management &amp; Documents <code>epic-2-users-documents/</code> 5-6 Epic 3 Capital Call &amp; Waterfall <code>epic-3-capital-waterfall/</code> 7-8 Epic 4 Workflow Automation &amp; AI <code>epic-4-workflows-ai/</code>"},{"location":"development/functional-test-driven-development/#step-2-run-epic-specific-tests","title":"Step 2: Run Epic-Specific Tests","text":"<pre><code># Run tests for your current epic\nnpx cypress run --spec \"cypress/e2e/epic-1-core-auth/**\"\n\n# Run a specific test case\nnpx cypress run --spec \"cypress/e2e/epic-1-core-auth/1.1.1-basic-login-authentication.cy.ts\"\n</code></pre>"},{"location":"development/functional-test-driven-development/#step-3-read-the-test-requirements","title":"Step 3: Read the Test Requirements","text":"<p>Each test includes detailed requirement information:</p> <pre><code>/**\n * Epic: Core Framework &amp; Auth\n * Official Test Case: 1.1.1\n * Business Requirements: User authentication (Login/Logout)\n * Development Timeline: Weeks 1-2\n */\ndescribe('Epic 1: Core Auth - Test Case 1.1.1', () =&gt; {\n  before(() =&gt; {\n    cy.logEpicRequirement(\n      'Core Framework &amp; Auth',\n      '1.1.1',\n      'User authentication with valid credentials',\n      'HIGH'\n    )\n  })\n\n  it('should authenticate users with valid credentials', () =&gt; {\n    cy.log('\ud83e\uddea TESTING: Basic login functionality')\n    cy.log('\u2705 ACCEPTANCE CRITERIA: User can login and access dashboard')\n\n    // Implementation guidance through test expectations\n    cy.visit('/login')\n    cy.get('[data-testid=\"email-input\"]').type('admin@dealsphere.com')\n    cy.get('[data-testid=\"password-input\"]').type('password123')\n    cy.get('[data-testid=\"login-submit\"]').click()\n\n    // This will fail until you implement authentication\n    cy.url().should('include', '/dashboard')\n    cy.get('[data-testid=\"user-welcome\"]').should('contain', 'Welcome')\n  })\n})\n</code></pre>"},{"location":"development/functional-test-driven-development/#step-4-implement-to-make-tests-pass","title":"Step 4: Implement to Make Tests Pass","text":"<ol> <li>Read the test failure message - It tells you exactly what's missing</li> <li>Implement the minimum code to make the test pass</li> <li>Re-run the test to verify it passes</li> <li>Move to the next test in the epic</li> </ol>"},{"location":"development/functional-test-driven-development/#step-5-verify-epic-completion","title":"Step 5: Verify Epic Completion","text":"<pre><code># Verify all tests in an epic are passing\nnpx cypress run --spec \"cypress/e2e/epic-1-core-auth/**\"\n\n# Check overall progress\nnpm run test:coverage\n</code></pre>"},{"location":"development/functional-test-driven-development/#development-workflow","title":"Development Workflow","text":""},{"location":"development/functional-test-driven-development/#daily-development-cycle","title":"Daily Development Cycle","text":"<pre><code>graph TD\n    A[Pick next failing test] --&gt; B[Read requirement &amp; acceptance criteria]\n    B --&gt; C[Implement minimum code to pass test]\n    C --&gt; D[Run test]\n    D --&gt; E{Test passing?}\n    E --&gt;|No| F[Debug and fix implementation]\n    F --&gt; D\n    E --&gt;|Yes| G[Refactor if needed]\n    G --&gt; H[Commit changes]\n    H --&gt; I{More tests in epic?}\n    I --&gt;|Yes| A\n    I --&gt;|No| J[Epic complete!]\n</code></pre>"},{"location":"development/functional-test-driven-development/#epic-development-cycle","title":"Epic Development Cycle","text":"<ol> <li>Start Epic - Run all tests in epic directory (all should fail)</li> <li>Iterative Development - Work through tests one by one</li> <li>Epic Completion - All tests in epic pass</li> <li>Integration Testing - Run full test suite to ensure no regressions</li> </ol>"},{"location":"development/functional-test-driven-development/#understanding-test-categories","title":"Understanding Test Categories","text":""},{"location":"development/functional-test-driven-development/#authentication-tests-epic-1","title":"Authentication Tests (Epic 1)","text":"<pre><code>// Example: 1.1.1-basic-login-authentication.cy.ts\n// WHAT IT TESTS: User can authenticate with valid credentials\n// WHEN TO IMPLEMENT: Week 1-2, when building login system\n// SUCCESS CRITERIA: User reaches dashboard after login\n\nit('should authenticate users with valid credentials', () =&gt; {\n  // Test expects login form, authentication API, and dashboard redirect\n})\n</code></pre>"},{"location":"development/functional-test-driven-development/#document-management-tests-epic-2","title":"Document Management Tests (Epic 2)","text":"<pre><code>// Example: 2.1.1-document-upload-class-isolation.cy.ts\n// WHAT IT TESTS: Documents are isolated by class membership\n// WHEN TO IMPLEMENT: Week 3-4, when building document system\n// SUCCESS CRITERIA: Users only see documents for their class\n\nit('should isolate documents by class membership', () =&gt; {\n  // Test expects class-based document filtering\n})\n</code></pre>"},{"location":"development/functional-test-driven-development/#financial-operations-tests-epic-3","title":"Financial Operations Tests (Epic 3)","text":"<pre><code>// Example: 4.1.1-european-waterfall-model.cy.ts\n// WHAT IT TESTS: European waterfall calculation model\n// WHEN TO IMPLEMENT: Week 5-6, when building financial calculations\n// SUCCESS CRITERIA: Accurate waterfall distributions per class\n\nit('should calculate European waterfall distributions correctly', () =&gt; {\n  // Test expects accurate financial calculations\n})\n</code></pre>"},{"location":"development/functional-test-driven-development/#best-practices","title":"Best Practices","text":""},{"location":"development/functional-test-driven-development/#1-read-tests-before-coding","title":"1. Read Tests Before Coding","text":"<ul> <li>Understand the business requirement from the test description</li> <li>Review acceptance criteria in the test logs</li> <li>Check epic documentation for additional context</li> </ul>"},{"location":"development/functional-test-driven-development/#2-implement-incrementally","title":"2. Implement Incrementally","text":"<ul> <li>Start with the simplest test in each epic</li> <li>Implement minimal code to make tests pass</li> <li>Refactor when multiple tests are passing</li> </ul>"},{"location":"development/functional-test-driven-development/#3-maintain-test-integrity","title":"3. Maintain Test Integrity","text":"<ul> <li>Never modify test expectations to make implementation easier</li> <li>Fix implementation to match test requirements</li> <li>Tests represent business requirements - they are the source of truth</li> </ul>"},{"location":"development/functional-test-driven-development/#4-use-test-feedback","title":"4. Use Test Feedback","text":"<ul> <li>Test failure messages guide implementation</li> <li>Console logs show requirement traceability</li> <li>Coverage reports show progress</li> </ul>"},{"location":"development/functional-test-driven-development/#epic-specific-guidance","title":"Epic-Specific Guidance","text":""},{"location":"development/functional-test-driven-development/#epic-1-core-framework-auth-weeks-1-2","title":"Epic 1: Core Framework &amp; Auth (Weeks 1-2)","text":"<p>Priority Order: 1. <code>1.1.1</code> - Basic login authentication 2. <code>1.1.2</code> - Logout functionality 3. <code>1.1.3</code> - Role-based access control 4. <code>1.1.5</code> - Session management 5. <code>1.2.1-1.2.5</code> - Error scenarios</p> <p>Key Implementation Areas: - JWT authentication system - Role-based permission checking - Session management - Security audit trails</p>"},{"location":"development/functional-test-driven-development/#epic-2-user-management-documents-weeks-3-4","title":"Epic 2: User Management &amp; Documents (Weeks 3-4)","text":"<p>Priority Order: 1. <code>1.3.2</code> - User management CRUD 2. <code>2.1.1-2.1.4</code> - Document upload/download with class isolation 3. <code>2.2.1-2.2.4</code> - Document versioning 4. <code>2.3.1-2.3.3</code> - AI document categorization</p> <p>Key Implementation Areas: - User management APIs - Document storage with class boundaries - Version control system - AI integration for document processing</p>"},{"location":"development/functional-test-driven-development/#epic-3-capital-call-waterfall-weeks-5-6","title":"Epic 3: Capital Call &amp; Waterfall (Weeks 5-6)","text":"<p>Priority Order: 1. <code>3.1.1-3.1.4</code> - Capital call management 2. <code>4.1.1-4.1.3</code> - Waterfall models 3. <code>4.2.1-4.2.4</code> - Calculation accuracy 4. <code>4.3.1-4.3.4</code> - Distribution algorithms</p> <p>Key Implementation Areas: - Capital call workflow engine - Financial calculation models - Payment processing integration - Distribution algorithms</p>"},{"location":"development/functional-test-driven-development/#epic-4-workflow-automation-ai-weeks-7-8","title":"Epic 4: Workflow Automation &amp; AI (Weeks 7-8)","text":"<p>Priority Order: 1. Workflow approval systems 2. AI-assisted features 3. Integration validations 4. Performance optimizations</p> <p>Key Implementation Areas: - Workflow engine - AI service integrations - External system connectors - Performance optimization</p>"},{"location":"development/functional-test-driven-development/#troubleshooting","title":"Troubleshooting","text":""},{"location":"development/functional-test-driven-development/#common-issues","title":"Common Issues","text":"<p>Tests not running:</p> <pre><code># Check Cypress installation\nnpx cypress verify\n\n# Install dependencies\nnpm install\n</code></pre> <p>All tests failing: This is expected! Tests were written before implementation begins.</p> <p>Test data issues:</p> <pre><code># Reset test database\nnpm run test:db:reset\n\n# Check test fixtures\ncypress/fixtures/\n</code></pre> <p>Authentication errors: Make sure test users exist in your database: - admin@dealsphere.com - gp@dealsphere.com - lp-a@dealsphere.com - lp-b@dealsphere.com - auditor@dealsphere.com - manager@dealsphere.com</p>"},{"location":"development/functional-test-driven-development/#success-metrics","title":"Success Metrics","text":""},{"location":"development/functional-test-driven-development/#epic-completion-criteria","title":"Epic Completion Criteria","text":"<p>\u2705 All tests in epic pass \u2705 No regressions in previous epics \u2705 Integration tests pass \u2705 Performance benchmarks met</p>"},{"location":"development/functional-test-driven-development/#overall-project-success","title":"Overall Project Success","text":"<ul> <li>47 functional tests passing</li> <li>100% epic coverage</li> <li>All business requirements validated</li> <li>Production-ready quality</li> </ul>"},{"location":"development/functional-test-driven-development/#getting-help","title":"Getting Help","text":""},{"location":"development/functional-test-driven-development/#documentation-references","title":"Documentation References","text":"<ul> <li>Technical Specification - Complete test suite specification</li> <li>Phase 1 Epics - Epic definitions and timelines</li> <li>Functional Test Cases - Official test case documentation</li> </ul>"},{"location":"development/functional-test-driven-development/#team-support","title":"Team Support","text":"<ul> <li>QA Team - Test interpretation and requirements clarification</li> <li>Product Team - Business requirement questions</li> <li>Architecture Team - Technical implementation guidance</li> </ul> <p>Remember: The tests are your specification. Trust them to guide your implementation toward the correct business outcomes! \ud83c\udfaf</p>"},{"location":"development/github-actions/","title":"GitHub Actions CI/CD Pipeline","text":"<p>This document provides comprehensive coverage of the GitHub Actions workflows used in the DealSphere platform, including configuration, customization, and troubleshooting.</p>"},{"location":"development/github-actions/#pipeline-overview","title":"Pipeline Overview","text":"<p>The DealSphere platform uses multiple GitHub Actions workflows for comprehensive CI/CD:</p> <pre><code>graph TD\n    A[Push/PR] --&gt; B[Backend Tests]\n    A --&gt; C[Frontend Tests]\n    A --&gt; D[Code Quality]\n\n    B --&gt; E[Docker Build Test]\n    C --&gt; E\n    D --&gt; E\n\n    E --&gt; F[E2E Tests]\n    F --&gt; G[Integration Tests]\n\n    G --&gt; H{Environment}\n    H --&gt;|Development| I[Notify Success/Failure]\n    H --&gt;|Main Branch| J[Deploy to Staging]\n\n    J --&gt; K[E2E Tests - Staging]\n    K --&gt; L[Deploy to Production]\n</code></pre>"},{"location":"development/github-actions/#workflow-files","title":"Workflow Files","text":""},{"location":"development/github-actions/#main-ci-pipeline","title":"Main CI Pipeline","text":"<p>File: <code>.github/workflows/ci.yml</code></p> <p>Triggers: - Push to <code>main</code> or <code>develop</code> branches - Pull requests to <code>main</code> or <code>develop</code> - Manual workflow dispatch</p> <p>Jobs Sequence: 1. backend-test - Spring Boot tests with PostgreSQL 2. frontend-test - React/TypeScript tests and build 3. code-quality - SonarCloud analysis and security scanning 4. docker-build-test - Docker Compose integration testing 5. e2e-test - Cypress end-to-end testing 6. integration-test - API integration tests (main branch only) 7. notify-success/failure - Slack notifications</p>"},{"location":"development/github-actions/#stagingproduction-e2e-tests","title":"Staging/Production E2E Tests","text":"<p>File: <code>.github/workflows/e2e-staging.yml</code></p> <p>Triggers: - Manual workflow dispatch (environment selection) - Scheduled daily runs against staging (6 AM UTC)</p> <p>Purpose: - Validate deployed applications - Smoke testing after deployments - Scheduled health checks</p>"},{"location":"development/github-actions/#detailed-job-configuration","title":"Detailed Job Configuration","text":""},{"location":"development/github-actions/#backend-tests","title":"Backend Tests","text":"<pre><code>backend-test:\n  name: Backend Tests\n  runs-on: ubuntu-latest\n\n  services:\n    postgres:\n      image: postgres:16-alpine\n      env:\n        POSTGRES_DB: dealsphere_test\n        POSTGRES_USER: test_user\n        POSTGRES_PASSWORD: test_password\n      ports:\n        - 5432:5432\n      options: &gt;-\n        --health-cmd pg_isready\n        --health-interval 10s\n        --health-timeout 5s\n        --health-retries 5\n\n  steps:\n    - name: Checkout code\n      uses: actions/checkout@v4\n\n    - name: Set up JDK 17\n      uses: actions/setup-java@v4\n      with:\n        java-version: '17'\n        distribution: 'temurin'\n\n    - name: Cache Gradle packages\n      uses: actions/cache@v4\n      with:\n        path: |\n          ~/.gradle/caches\n          ~/.gradle/wrapper\n        key: ${{ runner.os }}-gradle-${{ hashFiles('**/*.gradle*') }}\n\n    - name: Run backend tests\n      run: ./gradlew test\n      working-directory: ./backend\n      env:\n        SPRING_DATASOURCE_URL: jdbc:postgresql://localhost:5432/dealsphere_test\n        SPRING_DATASOURCE_USERNAME: test_user\n        SPRING_DATASOURCE_PASSWORD: test_password\n        JWT_SECRET: test-secret-key-for-ci-cd-pipeline-minimum-256-bits-long\n</code></pre> <p>Key Features: - PostgreSQL Service - Real database for integration tests - Gradle Caching - Speeds up dependency resolution - Test Reports - JUnit XML output for GitHub - Environment Variables - Test-specific configuration</p>"},{"location":"development/github-actions/#frontend-tests","title":"Frontend Tests","text":"<pre><code>frontend-test:\n  name: Frontend Tests\n  runs-on: ubuntu-latest\n\n  steps:\n    - name: Set up Node.js 20\n      uses: actions/setup-node@v4\n      with:\n        node-version: '20'\n\n    - name: Install pnpm\n      uses: pnpm/action-setup@v3\n      with:\n        version: 8\n\n    - name: Install dependencies\n      run: pnpm install\n      working-directory: ./frontend\n\n    - name: Run linter\n      run: pnpm run lint\n      working-directory: ./frontend\n\n    - name: Run frontend tests\n      run: pnpm run test\n      working-directory: ./frontend\n\n    - name: Build frontend\n      run: pnpm run build\n      working-directory: ./frontend\n</code></pre> <p>Key Features: - pnpm Package Manager - Faster, more efficient installs - Multi-step Validation - Linting, testing, building - Build Artifact Verification - Ensures production readiness</p>"},{"location":"development/github-actions/#e2e-tests-with-cypress","title":"E2E Tests with Cypress","text":"<pre><code>e2e-test:\n  name: E2E Tests (Cypress)\n  runs-on: ubuntu-latest\n  needs: [docker-build-test]\n\n  steps:\n    - name: Start application stack\n      run: |\n        cp .env.development .env\n        docker compose up -d --build\n\n        # Wait for backend health check\n        timeout 180 bash -c 'until curl -f http://localhost/actuator/health &gt; /dev/null 2&gt;&amp;1; do sleep 5; done'\n\n    - name: Run Cypress E2E tests\n      uses: cypress-io/github-action@v6\n      with:\n        working-directory: frontend\n        install: false\n        wait-on: 'http://localhost'\n        wait-on-timeout: 120\n        config: baseUrl=http://localhost,video=true\n      env:\n        CYPRESS_BASE_URL: http://localhost\n\n    - name: Upload artifacts on failure\n      uses: actions/upload-artifact@v4\n      if: failure()\n      with:\n        name: cypress-videos-${{ github.run_number }}\n        path: frontend/cypress/videos\n        retention-days: 7\n</code></pre> <p>Key Features: - Full Stack Testing - Real application environment - Service Health Checks - Ensures readiness before testing - Failure Artifacts - Videos and screenshots for debugging - Cypress Dashboard Integration - Test result recording</p>"},{"location":"development/github-actions/#environment-variables-and-secrets","title":"Environment Variables and Secrets","text":""},{"location":"development/github-actions/#repository-secrets","title":"Repository Secrets","text":"<p>Configure these in GitHub repository settings:</p> <pre><code># Required Secrets\nSONAR_TOKEN=&lt;sonarcloud-token&gt;\nSLACK_WEBHOOK_URL=&lt;slack-webhook-url&gt;\n\n# Optional Secrets\nCYPRESS_RECORD_KEY=&lt;cypress-dashboard-key&gt;\nDOCKER_REGISTRY_TOKEN=&lt;docker-registry-token&gt;\n</code></pre>"},{"location":"development/github-actions/#environment-variables","title":"Environment Variables","text":"<p>Development:</p> <pre><code>env:\n  NODE_VERSION: '20'\n  JAVA_VERSION: '17'\n  POSTGRES_VERSION: '16'\n</code></pre> <p>Test-specific:</p> <pre><code>env:\n  SPRING_PROFILES_ACTIVE: test\n  JWT_SECRET: test-secret-key-for-ci-cd-pipeline-minimum-256-bits-long\n  CYPRESS_BASE_URL: http://localhost\n</code></pre>"},{"location":"development/github-actions/#caching-strategy","title":"Caching Strategy","text":""},{"location":"development/github-actions/#gradle-cache","title":"Gradle Cache","text":"<pre><code>- name: Cache Gradle packages\n  uses: actions/cache@v4\n  with:\n    path: |\n      ~/.gradle/caches\n      ~/.gradle/wrapper\n    key: ${{ runner.os }}-gradle-${{ hashFiles('**/*.gradle*', '**/gradle-wrapper.properties') }}\n    restore-keys: |\n      ${{ runner.os }}-gradle-\n</code></pre>"},{"location":"development/github-actions/#pnpm-cache","title":"pnpm Cache","text":"<pre><code>- name: Get pnpm store directory\n  shell: bash\n  run: |\n    echo \"STORE_PATH=$(pnpm store path --silent)\" &gt;&gt; $GITHUB_ENV\n\n- name: Setup pnpm cache\n  uses: actions/cache@v4\n  with:\n    path: ${{ env.STORE_PATH }}\n    key: ${{ runner.os }}-pnpm-store-${{ hashFiles('**/pnpm-lock.yaml') }}\n    restore-keys: |\n      ${{ runner.os }}-pnpm-store-\n</code></pre>"},{"location":"development/github-actions/#docker-layer-cache","title":"Docker Layer Cache","text":"<pre><code>- name: Set up Docker Buildx\n  uses: docker/setup-buildx-action@v3\n  with:\n    driver-opts: image=moby/buildkit:master\n\n- name: Build with cache\n  uses: docker/build-push-action@v5\n  with:\n    context: .\n    cache-from: type=gha\n    cache-to: type=gha,mode=max\n</code></pre>"},{"location":"development/github-actions/#parallelization-and-optimization","title":"Parallelization and Optimization","text":""},{"location":"development/github-actions/#job-dependencies","title":"Job Dependencies","text":"<pre><code>jobs:\n  # Independent jobs (run in parallel)\n  backend-test:\n  frontend-test:\n  code-quality:\n\n  # Dependent jobs (run after dependencies complete)\n  docker-build-test:\n    needs: [backend-test, frontend-test]\n\n  e2e-test:\n    needs: [docker-build-test]\n</code></pre>"},{"location":"development/github-actions/#matrix-builds","title":"Matrix Builds","text":"<pre><code>strategy:\n  matrix:\n    os: [ubuntu-latest, windows-latest, macos-latest]\n    node-version: [18, 20]\n    exclude:\n      - os: windows-latest\n        node-version: 18\n</code></pre>"},{"location":"development/github-actions/#conditional-execution","title":"Conditional Execution","text":"<pre><code># Only run on main branch\nif: github.ref == 'refs/heads/main'\n\n# Only run on pull requests\nif: github.event_name == 'pull_request'\n\n# Skip on draft PRs\nif: github.event.pull_request.draft == false\n\n# Run on schedule\nif: github.event_name == 'schedule'\n</code></pre>"},{"location":"development/github-actions/#security-and-best-practices","title":"Security and Best Practices","text":""},{"location":"development/github-actions/#secret-management","title":"Secret Management","text":"<pre><code># \u2705 Good - Use repository secrets\nenv:\n  JWT_SECRET: ${{ secrets.JWT_SECRET }}\n\n# \u274c Bad - Hardcoded secrets\nenv:\n  JWT_SECRET: my-secret-key\n</code></pre>"},{"location":"development/github-actions/#permissions","title":"Permissions","text":"<pre><code>permissions:\n  contents: read\n  security-events: write\n  actions: read\n  id-token: write\n</code></pre>"},{"location":"development/github-actions/#supply-chain-security","title":"Supply Chain Security","text":"<pre><code>- name: Run Trivy vulnerability scanner\n  uses: aquasecurity/trivy-action@master\n  with:\n    scan-type: 'fs'\n    scan-ref: '.'\n    format: 'sarif'\n    output: 'trivy-results.sarif'\n\n- name: Upload to GitHub Security tab\n  uses: github/codeql-action/upload-sarif@v3\n  with:\n    sarif_file: 'trivy-results.sarif'\n</code></pre>"},{"location":"development/github-actions/#monitoring-and-notifications","title":"Monitoring and Notifications","text":""},{"location":"development/github-actions/#slack-integration","title":"Slack Integration","text":"<pre><code>- name: Slack notification on success\n  uses: 8398a7/action-slack@v3\n  with:\n    status: success\n    channel: '#ci-cd'\n    text: |\n      \u2705 CI Pipeline passed for commit ${{ github.sha }}\n      Branch: ${{ github.ref_name }}\n      Author: ${{ github.actor }}\n  env:\n    SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}\n</code></pre>"},{"location":"development/github-actions/#failure-handling","title":"Failure Handling","text":"<pre><code>- name: Show Docker logs on failure\n  if: failure()\n  run: |\n    echo \"=== Docker Compose Services ===\"\n    docker compose ps\n    echo \"=== Backend Logs ===\"\n    docker compose logs backend --tail=100\n</code></pre>"},{"location":"development/github-actions/#workflow-customization","title":"Workflow Customization","text":""},{"location":"development/github-actions/#adding-new-tests","title":"Adding New Tests","text":"<ol> <li>Create test job:</li> </ol> <pre><code>new-test-type:\n  name: New Test Type\n  runs-on: ubuntu-latest\n  needs: [existing-job]\n\n  steps:\n    - name: Run new tests\n      run: |\n        # Your test commands\n</code></pre> <ol> <li>Update dependencies:</li> </ol> <pre><code>notify-success:\n  needs: [backend-test, frontend-test, new-test-type]\n</code></pre>"},{"location":"development/github-actions/#environment-specific-workflows","title":"Environment-Specific Workflows","text":"<pre><code># .github/workflows/staging-deploy.yml\nname: Deploy to Staging\n\non:\n  push:\n    branches: [develop]\n\njobs:\n  deploy-staging:\n    environment: staging\n    runs-on: ubuntu-latest\n\n    steps:\n      # Deployment steps\n</code></pre>"},{"location":"development/github-actions/#custom-actions","title":"Custom Actions","text":"<p>Create reusable actions:</p> <pre><code># .github/actions/setup-app/action.yml\nname: 'Setup Application'\ndescription: 'Setup Node.js, pnpm, and dependencies'\n\ninputs:\n  node-version:\n    description: 'Node.js version'\n    required: false\n    default: '20'\n\nruns:\n  using: 'composite'\n  steps:\n    - name: Setup Node.js\n      uses: actions/setup-node@v4\n      with:\n        node-version: ${{ inputs.node-version }}\n</code></pre>"},{"location":"development/github-actions/#troubleshooting","title":"Troubleshooting","text":""},{"location":"development/github-actions/#common-issues","title":"Common Issues","text":""},{"location":"development/github-actions/#1-test-timeouts","title":"1. Test Timeouts","text":"<pre><code># Increase timeouts\n- name: Run tests with extended timeout\n  run: pnpm test\n  timeout-minutes: 15\n</code></pre>"},{"location":"development/github-actions/#2-service-health-checks","title":"2. Service Health Checks","text":"<pre><code># Add better health checks\n- name: Wait for services\n  run: |\n    timeout 300 bash -c 'until docker compose ps | grep -q \"healthy\"; do sleep 10; done'\n</code></pre>"},{"location":"development/github-actions/#3-cache-issues","title":"3. Cache Issues","text":"<pre><code># Clear cache on failures\n- name: Clear cache\n  if: failure()\n  run: |\n    rm -rf ~/.gradle/caches\n    rm -rf ~/.pnpm-store\n</code></pre>"},{"location":"development/github-actions/#debug-mode","title":"Debug Mode","text":"<pre><code># Enable debug logging\n- name: Enable debug\n  run: echo \"ACTIONS_STEP_DEBUG=true\" &gt;&gt; $GITHUB_ENV\n\n# Add debug information\n- name: Debug information\n  run: |\n    echo \"Runner OS: ${{ runner.os }}\"\n    echo \"GitHub workspace: ${{ github.workspace }}\"\n    docker version\n    docker compose version\n</code></pre>"},{"location":"development/github-actions/#performance-issues","title":"Performance Issues","text":""},{"location":"development/github-actions/#optimize-job-execution","title":"Optimize Job Execution","text":"<pre><code># Use faster runners for critical paths\nruns-on: ubuntu-latest-4-cores\n\n# Optimize Docker builds\n- name: Build with BuildKit\n  run: |\n    export DOCKER_BUILDKIT=1\n    export COMPOSE_DOCKER_CLI_BUILD=1\n    docker compose build\n</code></pre>"},{"location":"development/github-actions/#reduce-test-execution-time","title":"Reduce Test Execution Time","text":"<pre><code># Run tests in parallel\nstrategy:\n  matrix:\n    test-group: [unit, integration, e2e]\n\n# Skip unnecessary steps\n- name: Skip build on docs changes\n  if: contains(github.event.head_commit.message, '[skip ci]')\n  run: echo \"Skipping CI\"\n</code></pre>"},{"location":"development/github-actions/#advanced-features","title":"Advanced Features","text":""},{"location":"development/github-actions/#workflow-artifacts","title":"Workflow Artifacts","text":"<pre><code>- name: Upload test results\n  uses: actions/upload-artifact@v4\n  with:\n    name: test-results-${{ github.run_number }}\n    path: |\n      backend/core/build/test-results/\n      frontend/coverage/\n    retention-days: 30\n</code></pre>"},{"location":"development/github-actions/#dynamic-configuration","title":"Dynamic Configuration","text":"<pre><code>- name: Set environment variables\n  run: |\n    if [[ \"${{ github.ref }}\" == \"refs/heads/main\" ]]; then\n      echo \"ENVIRONMENT=production\" &gt;&gt; $GITHUB_ENV\n    else\n      echo \"ENVIRONMENT=development\" &gt;&gt; $GITHUB_ENV\n    fi\n</code></pre>"},{"location":"development/github-actions/#workflow-templates","title":"Workflow Templates","text":"<p>Create organization-wide templates:</p> <pre><code># .github/workflow-templates/ci-template.yml\nname: CI Template\n\non:\n  push:\n    branches: [ $default-branch ]\n\njobs:\n  ci:\n    runs-on: ubuntu-latest\n    steps:\n      # Template steps\n</code></pre>"},{"location":"development/github-actions/#related-documentation","title":"Related Documentation","text":"<ul> <li>Local CI/CD Setup</li> <li>Cypress E2E Testing</li> <li>Docker Development</li> <li>Environment Configuration</li> </ul>"},{"location":"development/local-cicd-setup/","title":"Local CI/CD Setup Guide","text":"<p>This guide covers how to run the complete CI/CD pipeline locally, including Docker setup, testing workflows, and Cypress E2E tests.</p>"},{"location":"development/local-cicd-setup/#overview","title":"Overview","text":"<p>The DealSphere platform uses a comprehensive CI/CD pipeline that includes:</p> <ul> <li>Backend Tests - Spring Boot unit and integration tests</li> <li>Frontend Tests - React/TypeScript unit tests and linting</li> <li>E2E Tests - Cypress browser automation testing</li> <li>Code Quality - SonarCloud analysis and security scanning</li> <li>Docker Integration - Full stack deployment testing</li> </ul>"},{"location":"development/local-cicd-setup/#prerequisites","title":"Prerequisites","text":"<p>Before running the CI/CD setup locally, ensure you have:</p>"},{"location":"development/local-cicd-setup/#required-software","title":"Required Software","text":"<pre><code># Package Managers\n\u2705 Node.js 20+\n\u2705 pnpm 8+\n\u2705 Java 17+\n\u2705 Docker &amp; Docker Compose\n\n# Development Tools\n\u2705 Git\n\u2705 curl (for health checks)\n</code></pre>"},{"location":"development/local-cicd-setup/#installation-commands","title":"Installation Commands","text":"<pre><code># Node.js &amp; pnpm\ncurl -fsSL https://get.pnpm.io/install.sh | sh\npnpm env use --global 20\n\n# Java 17 (using SDKMAN)\ncurl -s \"https://get.sdkman.io\" | bash\nsdk install java 17.0.7-tem\n\n# Docker\n# Install Docker Desktop from: https://docker.com/products/docker-desktop\n</code></pre>"},{"location":"development/local-cicd-setup/#quick-start","title":"Quick Start","text":""},{"location":"development/local-cicd-setup/#1-clone-and-setup","title":"1. Clone and Setup","text":"<pre><code># Clone the repository\ngit clone &lt;repository-url&gt;\ncd dealsphere-platform\n\n# Copy environment configuration\ncp .env.development .env\n\n# Verify Docker is running\ndocker --version\ndocker-compose --version\n</code></pre>"},{"location":"development/local-cicd-setup/#2-run-full-cicd-pipeline-locally","title":"2. Run Full CI/CD Pipeline Locally","text":"<pre><code># Start the complete application stack\ndocker-compose up -d --build\n\n# Wait for services to be ready (this mimics CI behavior)\n./scripts/wait-for-services.sh\n\n# Run all tests in sequence (like CI)\n./scripts/run-local-ci.sh\n</code></pre>"},{"location":"development/local-cicd-setup/#detailed-cicd-components","title":"Detailed CI/CD Components","text":""},{"location":"development/local-cicd-setup/#backend-testing","title":"Backend Testing","text":"<p>The backend uses Spring Boot with comprehensive test coverage:</p> <pre><code>cd backend\n\n# Run unit tests\n./gradlew test\n\n# Run with coverage\n./gradlew test jacocoTestReport\n\n# Run integration tests\n./gradlew integrationTest\n\n# Test with real database\n./gradlew test -Dspring.profiles.active=test\n</code></pre> <p>Test Configuration: - Unit Tests: Fast, mocked dependencies - Integration Tests: Real database, Docker Testcontainers - Test Data: DataInitializer with service classes only</p>"},{"location":"development/local-cicd-setup/#frontend-testing","title":"Frontend Testing","text":"<p>The frontend uses Vitest and Cypress for comprehensive testing:</p> <pre><code>cd frontend\n\n# Install dependencies\npnpm install\n\n# Run unit tests\npnpm test\n\n# Run with coverage\npnpm test:coverage\n\n# Linting and type checking\npnpm lint\npnpm type-check\n\n# Build verification\npnpm build\n</code></pre>"},{"location":"development/local-cicd-setup/#e2e-testing-with-cypress","title":"E2E Testing with Cypress","text":"<p>Cypress tests run against the full application stack:</p>"},{"location":"development/local-cicd-setup/#local-development-testing","title":"Local Development Testing","text":"<pre><code># Ensure application is running\ndocker-compose up -d\n\n# Wait for services (backend health check)\ncurl -f http://localhost/actuator/health\n\n# Run Cypress tests\ncd frontend\npnpm cy:run\n\n# Or run interactively\npnpm cy:open\n</code></pre>"},{"location":"development/local-cicd-setup/#test-configuration","title":"Test Configuration","text":"<p>The E2E tests verify: - \u2705 Login Flow - Complete authentication workflow - \u2705 JWT Storage - Token persistence in localStorage - \u2705 Redux Saga - State management integration - \u2705 Navigation - Dashboard redirects and routing - \u2705 Error Handling - Network failures and invalid credentials</p> <p>Test Files:</p> <pre><code>cypress/\n\u251c\u2500\u2500 e2e/\n\u2502   \u2514\u2500\u2500 auth/\n\u2502       \u251c\u2500\u2500 login-flow.cy.ts      # Complete login workflow\n\u2502       \u251c\u2500\u2500 jwt-storage.cy.ts     # Token storage verification\n\u2502       \u2514\u2500\u2500 basic-login.cy.ts     # Basic functionality\n\u251c\u2500\u2500 support/\n\u2502   \u251c\u2500\u2500 commands.ts               # Custom Cypress commands\n\u2502   \u2514\u2500\u2500 e2e.ts                   # Global configuration\n\u2514\u2500\u2500 fixtures/\n    \u2514\u2500\u2500 users.json               # Test user data\n</code></pre>"},{"location":"development/local-cicd-setup/#environment-configuration","title":"Environment Configuration","text":""},{"location":"development/local-cicd-setup/#environment-files","title":"Environment Files","text":"<p>The project uses environment-specific configuration:</p> <pre><code>.env.development    # Local development (http://localhost)\n.env.staging       # Staging environment\n.env.production    # Production environment\n</code></pre> <p>Key Variables:</p> <pre><code># Backend Configuration\nSPRING_PROFILES_ACTIVE=docker\nPOSTGRES_DB=dealsphere_dev\nJWT_SECRET=&lt;secure-key&gt;\n\n# Frontend Configuration\nVITE_API_URL=http://localhost/api\nVITE_GRAPHQL_URL=http://localhost/api/graphql\n\n# Cypress Testing\nCYPRESS_BASE_URL=http://localhost\nCYPRESS_VIDEO=true\nCYPRESS_SCREENSHOTS=true\n</code></pre>"},{"location":"development/local-cicd-setup/#docker-configuration","title":"Docker Configuration","text":"<pre><code># docker-compose.yml structure\nservices:\n  db:          # PostgreSQL 16 database\n  backend:     # Spring Boot application\n  frontend:    # React/Vite development server\n  nginx:       # Reverse proxy (port 80)\n</code></pre>"},{"location":"development/local-cicd-setup/#local-cicd-workflows","title":"Local CI/CD Workflows","text":""},{"location":"development/local-cicd-setup/#1-full-pipeline-simulation","title":"1. Full Pipeline Simulation","text":"<p>Create this script to simulate the complete CI/CD pipeline:</p> <pre><code>#!/bin/bash\n# scripts/run-local-ci.sh\n\nset -e\n\necho \"\ud83d\ude80 Starting Local CI/CD Pipeline\"\n\n# 1. Backend Tests\necho \"\ud83d\udcca Running Backend Tests...\"\ncd backend\n./gradlew clean test\ncd ..\n\n# 2. Frontend Tests\necho \"\u269b\ufe0f Running Frontend Tests...\"\ncd frontend\npnpm install\npnpm lint\npnpm test\npnpm build\ncd ..\n\n# 3. Docker Build Test\necho \"\ud83d\udc33 Testing Docker Build...\"\ndocker-compose build --no-cache\ndocker-compose up -d\n\n# 4. Wait for Services\necho \"\u23f3 Waiting for services to be ready...\"\ntimeout 120 bash -c 'until curl -f http://localhost/actuator/health &gt; /dev/null 2&gt;&amp;1; do sleep 5; done'\n\n# 5. E2E Tests\necho \"\ud83e\uddea Running E2E Tests...\"\ncd frontend\npnpm cy:run\ncd ..\n\n# 6. Cleanup\necho \"\ud83e\uddf9 Cleaning up...\"\ndocker-compose down -v\n\necho \"\u2705 Local CI/CD Pipeline Complete!\"\n</code></pre>"},{"location":"development/local-cicd-setup/#2-service-health-checks","title":"2. Service Health Checks","text":"<p>Create a health check script:</p> <pre><code>#!/bin/bash\n# scripts/wait-for-services.sh\n\nset -e\n\necho \"\u23f3 Waiting for services to be ready...\"\n\n# Check PostgreSQL\necho \"\ud83d\uddc4\ufe0f Checking PostgreSQL...\"\ntimeout 60 bash -c 'until docker-compose exec db pg_isready -U dealsphere_dev &gt; /dev/null 2&gt;&amp;1; do sleep 2; done'\n\n# Check Backend\necho \"\ud83c\udf10 Checking Backend...\"\ntimeout 120 bash -c 'until curl -f http://localhost/actuator/health &gt; /dev/null 2&gt;&amp;1; do sleep 5; done'\n\n# Check GraphQL\necho \"\ud83d\udce1 Checking GraphQL...\"\ntimeout 60 bash -c 'until curl -f http://localhost/api/graphql -H \"Content-Type: application/json\" -d \"{\\\"query\\\":\\\"query{__typename}\\\"}\" &gt; /dev/null 2&gt;&amp;1; do sleep 2; done'\n\n# Check Frontend\necho \"\u269b\ufe0f Checking Frontend...\"\ntimeout 60 bash -c 'until curl -f http://localhost &gt; /dev/null 2&gt;&amp;1; do sleep 2; done'\n\necho \"\u2705 All services are ready!\"\n</code></pre>"},{"location":"development/local-cicd-setup/#troubleshooting","title":"Troubleshooting","text":""},{"location":"development/local-cicd-setup/#common-issues","title":"Common Issues","text":""},{"location":"development/local-cicd-setup/#1-port-conflicts","title":"1. Port Conflicts","text":"<pre><code># Check if ports are in use\nlsof -i :80    # Nginx\nlsof -i :5432  # PostgreSQL\nlsof -i :5173  # Vite dev server\n\n# Kill processes if needed\nsudo lsof -ti:80 | xargs kill -9\n</code></pre>"},{"location":"development/local-cicd-setup/#2-docker-issues","title":"2. Docker Issues","text":"<pre><code># Clean Docker state\ndocker-compose down -v\ndocker system prune -f\ndocker volume prune -f\n\n# Rebuild from scratch\ndocker-compose build --no-cache\n</code></pre>"},{"location":"development/local-cicd-setup/#3-database-connection-issues","title":"3. Database Connection Issues","text":"<pre><code># Check PostgreSQL logs\ndocker-compose logs db\n\n# Connect to database manually\ndocker-compose exec db psql -U dealsphere_dev -d dealsphere_dev\n\n# Reset database\ndocker-compose down -v\ndocker-compose up -d db\n</code></pre>"},{"location":"development/local-cicd-setup/#4-cypress-test-failures","title":"4. Cypress Test Failures","text":"<pre><code># Run with debug output\ncd frontend\nDEBUG=cypress:* pnpm cy:run\n\n# Check video recordings\nopen cypress/videos/\n\n# Run specific test\npnpm cy:run --spec \"cypress/e2e/auth/login-flow.cy.ts\"\n</code></pre>"},{"location":"development/local-cicd-setup/#performance-optimization","title":"Performance Optimization","text":""},{"location":"development/local-cicd-setup/#speed-up-local-development","title":"Speed Up Local Development","text":"<pre><code># Use Docker layer caching\nexport DOCKER_BUILDKIT=1\nexport COMPOSE_DOCKER_CLI_BUILD=1\n\n# Pre-pull images\ndocker-compose pull\n\n# Use pnpm store for faster installs\npnpm config set store-dir ~/.pnpm-store\n</code></pre>"},{"location":"development/local-cicd-setup/#parallel-testing","title":"Parallel Testing","text":"<pre><code># Run tests in parallel (requires multiple environments)\ndocker-compose -f docker-compose.yml -f docker-compose.test.yml up -d\n\n# Run Cypress tests in parallel\npnpm cy:run --record --parallel --key &lt;cypress-record-key&gt;\n</code></pre>"},{"location":"development/local-cicd-setup/#integration-with-ide","title":"Integration with IDE","text":""},{"location":"development/local-cicd-setup/#vs-code-setup","title":"VS Code Setup","text":"<p>.vscode/settings.json:</p> <pre><code>{\n  \"docker.host\": \"unix:///var/run/docker.sock\",\n  \"typescript.preferences.importModuleSpecifier\": \"relative\",\n  \"jest.jestCommandLine\": \"pnpm test\",\n  \"cypress.showActionsInCommandPalette\": true\n}\n</code></pre> <p>.vscode/tasks.json:</p> <pre><code>{\n  \"version\": \"2.0.0\",\n  \"tasks\": [\n    {\n      \"label\": \"Start Local CI/CD\",\n      \"type\": \"shell\",\n      \"command\": \"./scripts/run-local-ci.sh\",\n      \"group\": \"test\",\n      \"presentation\": {\n        \"echo\": true,\n        \"reveal\": \"always\",\n        \"focus\": false,\n        \"panel\": \"new\"\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"development/local-cicd-setup/#next-steps","title":"Next Steps","text":"<ol> <li>Set up GitHub Actions - See GitHub Actions Guide</li> <li>Configure SonarCloud - See Code Quality Guide</li> <li>Deploy to Staging - See Deployment Guide</li> <li>Monitor Production - See Monitoring Guide</li> </ol>"},{"location":"development/local-cicd-setup/#related-documentation","title":"Related Documentation","text":"<ul> <li>GitHub Actions Workflows</li> <li>Cypress E2E Testing</li> <li>Docker Development</li> <li>Environment Configuration</li> </ul>"},{"location":"development/security-best-practices/","title":"Security Best Practices","text":""},{"location":"development/security-best-practices/#overview","title":"Overview","text":"<p>This document outlines the comprehensive security measures implemented in the DealSphere platform, covering authentication, authorization, input validation, and security monitoring.</p>"},{"location":"development/security-best-practices/#authentication-authorization","title":"Authentication &amp; Authorization","text":""},{"location":"development/security-best-practices/#jwt-token-security","title":"JWT Token Security","text":""},{"location":"development/security-best-practices/#best-practices-implemented","title":"Best Practices Implemented","text":"<ol> <li> <p>Secure Token Generation <code>java    // Use cryptographically secure random keys    private Key getSigningKey() {        byte[] keyBytes = Decoders.BASE64.decode(jwtSecret);        return Keys.hmacShaKeyFor(keyBytes);    }</code></p> </li> <li> <p>Token Expiration</p> </li> <li>Short-lived access tokens (24 hours)</li> <li>Automatic refresh mechanism</li> <li> <p>Proper cleanup on logout</p> </li> <li> <p>Token Validation <code>java    public boolean validateToken(String token) {        try {            Jwts.parserBuilder()                .setSigningKey(getSigningKey())                .build()                .parseClaimsJws(token);            return true;        } catch (JwtException | IllegalArgumentException e) {            return false;        }    }</code></p> </li> </ol>"},{"location":"development/security-best-practices/#security-considerations","title":"Security Considerations","text":"<ul> <li>Secret Management: JWT secrets stored in environment variables</li> <li>Algorithm Security: Using HS256 with secure key length (&gt;256 bits)</li> <li>Token Transmission: Always use HTTPS in production</li> <li>Storage: Tokens stored in localStorage with automatic cleanup</li> </ul>"},{"location":"development/security-best-practices/#password-security","title":"Password Security","text":""},{"location":"development/security-best-practices/#implementation","title":"Implementation","text":"<ol> <li> <p>Hashing Algorithm    ```java    @Configuration    public class SecurityConfig {</p> <p>@Bean    public PasswordEncoder passwordEncoder() {        return new BCryptPasswordEncoder(12); // High cost factor    }    }    ```</p> </li> <li> <p>Password Requirements</p> </li> <li>Minimum 6 characters (configurable)</li> <li>XSS/SQL injection detection</li> <li> <p>Input sanitization</p> </li> <li> <p>Password Reset Security</p> </li> <li>Time-limited tokens (15 minutes)</li> <li>Single-use tokens</li> <li>Rate limiting (3 attempts per hour)</li> </ol>"},{"location":"development/security-best-practices/#input-validation-sanitization","title":"Input Validation &amp; Sanitization","text":""},{"location":"development/security-best-practices/#backend-validation","title":"Backend Validation","text":"<p>Location: <code>backend/commons/storage/src/main/java/com/dealsphere/backend/commons/storage/config/ValidationConfig.java</code></p> <pre><code>@Component\npublic class ValidationConfig {\n\n    // XSS Pattern Detection\n    private static final Pattern[] XSS_PATTERNS = {\n        Pattern.compile(\"&lt;script[^&gt;]*&gt;.*?&lt;/script&gt;\", Pattern.CASE_INSENSITIVE),\n        Pattern.compile(\"javascript:\", Pattern.CASE_INSENSITIVE),\n        Pattern.compile(\"vbscript:\", Pattern.CASE_INSENSITIVE),\n        Pattern.compile(\"on\\\\w+\\\\s*=\", Pattern.CASE_INSENSITIVE)\n    };\n\n    // SQL Injection Detection\n    private static final Pattern[] SQL_PATTERNS = {\n        Pattern.compile(\"(union|select|insert|update|delete|drop)\", Pattern.CASE_INSENSITIVE),\n        Pattern.compile(\"(;|--|#)\", Pattern.CASE_INSENSITIVE),\n        Pattern.compile(\"'\\\\s*(or|and)\\\\s*'\", Pattern.CASE_INSENSITIVE)\n    };\n\n    public boolean containsXSS(String input) {\n        if (input == null) return false;\n        return Arrays.stream(XSS_PATTERNS)\n            .anyMatch(pattern -&gt; pattern.matcher(input).find());\n    }\n\n    public boolean containsSQLInjection(String input) {\n        if (input == null) return false;\n        return Arrays.stream(SQL_PATTERNS)\n            .anyMatch(pattern -&gt; pattern.matcher(input).find());\n    }\n}\n</code></pre>"},{"location":"development/security-best-practices/#frontend-validation","title":"Frontend Validation","text":"<p>Location: <code>frontend/src/utils/validation.ts</code></p> <pre><code>export const sanitizeXSS = (input: string): string =&gt; {\n  if (!input) return input;\n\n  let sanitized = input;\n  XSS_PATTERNS.forEach(pattern =&gt; {\n    sanitized = sanitized.replace(pattern, '');\n  });\n\n  // HTML encode special characters\n  return sanitized\n    .replace(/&amp;/g, '&amp;amp;')\n    .replace(/&lt;/g, '&amp;lt;')\n    .replace(/&gt;/g, '&amp;gt;')\n    .replace(/\"/g, '&amp;quot;')\n    .replace(/'/g, '&amp;#x27;')\n    .replace(/\\//g, '&amp;#x2F;');\n};\n\nexport const validateEmail = (email: string): boolean =&gt; {\n  if (!email) return false;\n\n  // Check for XSS/SQL injection first\n  if (detectXSS(email) || detectSQLInjection(email)) {\n    return false;\n  }\n\n  const emailRegex = /^[^\\s@]+@[^\\s@]+\\.[^\\s@]+$/;\n  return emailRegex.test(email);\n};\n</code></pre>"},{"location":"development/security-best-practices/#network-security","title":"Network Security","text":""},{"location":"development/security-best-practices/#nginx-security-configuration","title":"nginx Security Configuration","text":"<p>Location: <code>nginx/nginx.conf</code></p>"},{"location":"development/security-best-practices/#rate-limiting","title":"Rate Limiting","text":"<pre><code># Rate limiting zones\nlimit_req_zone $binary_remote_addr zone=auth:10m rate=5r/m;\nlimit_req_zone $binary_remote_addr zone=api:10m rate=10r/m;\nlimit_req_zone $binary_remote_addr zone=reset:10m rate=1r/m;\n\n# Apply rate limiting\nlocation /api/auth/login {\n    limit_req zone=auth burst=10 nodelay;\n    limit_req_status 429;\n    proxy_pass http://backend;\n}\n\nlocation /api/auth/request-password-reset {\n    limit_req zone=reset burst=2 nodelay;\n    limit_req_status 429;\n    proxy_pass http://backend;\n}\n</code></pre>"},{"location":"development/security-best-practices/#security-headers","title":"Security Headers","text":"<pre><code># Security headers\nadd_header X-Frame-Options \"SAMEORIGIN\" always;\nadd_header X-Content-Type-Options \"nosniff\" always;\nadd_header X-XSS-Protection \"1; mode=block\" always;\nadd_header Referrer-Policy \"strict-origin-when-cross-origin\" always;\nadd_header Permissions-Policy \"geolocation=(), microphone=(), camera=()\" always;\n\n# Strict Transport Security (HTTPS only)\nadd_header Strict-Transport-Security \"max-age=31536000; includeSubDomains\" always;\n\n# Content Security Policy\nadd_header Content-Security-Policy \"\n    default-src 'self';\n    script-src 'self' 'unsafe-inline' 'unsafe-eval' https://cdnjs.cloudflare.com;\n    style-src 'self' 'unsafe-inline' https://fonts.googleapis.com;\n    font-src 'self' https://fonts.gstatic.com;\n    img-src 'self' data: https:;\n    connect-src 'self' ws: wss: https://api.example.com;\n    frame-ancestors 'none';\n    base-uri 'self';\n    form-action 'self';\n\" always;\n</code></pre>"},{"location":"development/security-best-practices/#cors-configuration","title":"CORS Configuration","text":"<pre><code># CORS for specific origins\nmap $http_origin $allowed_origin {\n    default \"\";\n    \"~^https?://(localhost|127\\.0\\.0\\.1):(3000|5173|8080)$\" $http_origin;\n    \"https://app.dealsphere.com\" $http_origin;\n    \"https://admin.dealsphere.com\" $http_origin;\n}\n\nlocation /api/ {\n    # CORS headers\n    add_header 'Access-Control-Allow-Origin' '$allowed_origin' always;\n    add_header 'Access-Control-Allow-Methods' 'GET, POST, PUT, DELETE, OPTIONS' always;\n    add_header 'Access-Control-Allow-Headers' 'Origin, X-Requested-With, Content-Type, Accept, Authorization' always;\n    add_header 'Access-Control-Allow-Credentials' 'true' always;\n    add_header 'Access-Control-Max-Age' '86400' always;\n\n    # Handle preflight requests\n    if ($request_method = OPTIONS) {\n        return 204;\n    }\n\n    proxy_pass http://backend;\n}\n</code></pre>"},{"location":"development/security-best-practices/#security-monitoring-auditing","title":"Security Monitoring &amp; Auditing","text":""},{"location":"development/security-best-practices/#comprehensive-event-logging","title":"Comprehensive Event Logging","text":"<p>Location: <code>backend/commons/auth/src/main/java/com/dealsphere/backend/commons/auth/service/SecurityAuditServiceImpl.java</code></p>"},{"location":"development/security-best-practices/#event-types-monitored","title":"Event Types Monitored","text":"<pre><code>public enum SecurityEventType {\n    // Authentication Events\n    LOGIN_SUCCESS,\n    LOGIN_FAILURE,\n    LOGIN_SUSPICIOUS,\n    LOGOUT,\n\n    // Password Events\n    PASSWORD_CHANGE,\n    PASSWORD_RESET_REQUEST,\n    PASSWORD_RESET_COMPLETE,\n\n    // Account Events\n    ACCOUNT_LOCKED,\n    ACCOUNT_UNLOCKED,\n    USER_CREATED,\n    USER_DELETED,\n    USER_MODIFIED,\n\n    // Security Threats\n    ACCESS_DENIED,\n    PRIVILEGE_ESCALATION_ATTEMPT,\n    SQL_INJECTION_ATTEMPT,\n    XSS_ATTEMPT,\n    CSRF_ATTEMPT,\n    BRUTE_FORCE_ATTEMPT,\n    RATE_LIMIT_EXCEEDED,\n\n    // System Events\n    CONFIGURATION_CHANGE,\n    ADMIN_ACTION,\n    COMPLIANCE_VIOLATION,\n    SUSPICIOUS_ACTIVITY\n}\n</code></pre>"},{"location":"development/security-best-practices/#structured-logging","title":"Structured Logging","text":"<pre><code>@Override\n@Async\npublic void logSecurityEvent(SecurityEvent event) {\n    Map&lt;String, Object&gt; logFields = createStructuredLogFields(event);\n\n    switch (event.getSeverity()) {\n        case CRITICAL:\n            log.error(\"SECURITY_EVENT: {}\", event.getMessage(),\n                StructuredArguments.entries(logFields));\n            break;\n        case HIGH:\n            log.warn(\"SECURITY_EVENT: {}\", event.getMessage(),\n                StructuredArguments.entries(logFields));\n            break;\n        case MEDIUM:\n            log.info(\"SECURITY_EVENT: {}\", event.getMessage(),\n                StructuredArguments.entries(logFields));\n            break;\n        case LOW:\n        default:\n            log.debug(\"SECURITY_EVENT: {}\", event.getMessage(),\n                StructuredArguments.entries(logFields));\n            break;\n    }\n}\n</code></pre>"},{"location":"development/security-best-practices/#external-observability-integration","title":"External Observability Integration","text":""},{"location":"development/security-best-practices/#log-format-for-external-systems","title":"Log Format for External Systems","text":"<pre><code>{\n  \"timestamp\": \"2025-01-16T10:30:00Z\",\n  \"level\": \"ERROR\",\n  \"message\": \"SECURITY_EVENT: SQL injection attempt detected\",\n  \"event_type\": \"SQL_INJECTION_ATTEMPT\",\n  \"severity\": \"CRITICAL\",\n  \"user_id\": \"user-123\",\n  \"session_id\": \"session-456\",\n  \"ip_address\": \"192.168.1.100\",\n  \"user_agent\": \"Mozilla/5.0...\",\n  \"endpoint\": \"/api/auth/login\",\n  \"http_method\": \"POST\",\n  \"status_code\": 400,\n  \"risk_score\": 95,\n  \"location_country\": \"US\",\n  \"service\": \"dealsphere-auth\",\n  \"log_type\": \"security_audit\",\n  \"details\": {\n    \"payload\": \"'; DROP TABLE users; --\",\n    \"blocked\": true,\n    \"detection_method\": \"pattern_matching\"\n  }\n}\n</code></pre>"},{"location":"development/security-best-practices/#data-protection","title":"Data Protection","text":""},{"location":"development/security-best-practices/#database-security","title":"Database Security","text":""},{"location":"development/security-best-practices/#connection-security","title":"Connection Security","text":"<pre><code># application-production.yml\nspring:\n  datasource:\n    url: jdbc:postgresql://localhost:5432/dealsphere?sslmode=require\n    username: ${DB_USERNAME}\n    password: ${DB_PASSWORD}\n    hikari:\n      connection-timeout: 30000\n      idle-timeout: 600000\n      max-lifetime: 1800000\n      maximum-pool-size: 20\n</code></pre>"},{"location":"development/security-best-practices/#data-encryption","title":"Data Encryption","text":"<ul> <li>At Rest: Database encryption enabled</li> <li>In Transit: SSL/TLS for all connections</li> <li>Application Level: Sensitive fields encrypted before storage</li> </ul>"},{"location":"development/security-best-practices/#email-security","title":"Email Security","text":""},{"location":"development/security-best-practices/#smtp-configuration","title":"SMTP Configuration","text":"<pre><code>spring:\n  mail:\n    host: ${SMTP_HOST}\n    port: ${SMTP_PORT}\n    username: ${SMTP_USERNAME}\n    password: ${SMTP_PASSWORD}\n    properties:\n      mail.smtp:\n        auth: true\n        starttls.enable: true\n        starttls.required: true\n        ssl.trust: ${SMTP_HOST}\n</code></pre>"},{"location":"development/security-best-practices/#email-content-security","title":"Email Content Security","text":"<pre><code>@Service\npublic class EmailService {\n\n    public void sendInvitationEmail(String to, String firstName, String invitationLink) {\n        // Validate email address\n        if (!isValidEmail(to)) {\n            throw new InvalidEmailException(\"Invalid email address\");\n        }\n\n        // Sanitize template variables\n        String sanitizedFirstName = sanitizeForEmail(firstName);\n        String sanitizedLink = validateInvitationLink(invitationLink);\n\n        // Send with secure template\n        emailSender.send(createInvitationEmail(to, sanitizedFirstName, sanitizedLink));\n    }\n}\n</code></pre>"},{"location":"development/security-best-practices/#vulnerability-prevention","title":"Vulnerability Prevention","text":""},{"location":"development/security-best-practices/#common-attack-vectors","title":"Common Attack Vectors","text":""},{"location":"development/security-best-practices/#1-cross-site-scripting-xss","title":"1. Cross-Site Scripting (XSS)","text":"<p>Prevention Measures: - Input sanitization on both frontend and backend - Content Security Policy (CSP) headers - Output encoding - DOM XSS prevention</p> <pre><code>// Frontend XSS prevention\nexport const useFormValidation = (schema: ValidationSchema) =&gt; {\n  const validateField = (name: string, value: string) =&gt; {\n    // Check for XSS patterns\n    if (detectXSS(value)) {\n      return \"Potentially malicious content detected\";\n    }\n\n    // Sanitize input\n    const sanitized = sanitizeXSS(value);\n    return schema[name]?.validate(sanitized);\n  };\n};\n</code></pre>"},{"location":"development/security-best-practices/#2-sql-injection","title":"2. SQL Injection","text":"<p>Prevention Measures: - Parameterized queries (JPA/Hibernate) - Input validation and sanitization - Principle of least privilege for database access</p> <pre><code>// Using JPA prevents SQL injection\n@Query(\"SELECT u FROM UserProfile u WHERE u.email = :email\")\nOptional&lt;UserProfile&gt; findByEmail(@Param(\"email\") String email);\n</code></pre>"},{"location":"development/security-best-practices/#3-cross-site-request-forgery-csrf","title":"3. Cross-Site Request Forgery (CSRF)","text":"<p>Prevention Measures: - SameSite cookie attributes - CORS policy enforcement - JWT tokens in Authorization headers (not cookies)</p>"},{"location":"development/security-best-practices/#4-brute-force-attacks","title":"4. Brute Force Attacks","text":"<p>Prevention Measures: - Rate limiting at nginx level - Account lockout policies - CAPTCHA integration (future enhancement) - Monitoring and alerting</p>"},{"location":"development/security-best-practices/#security-testing","title":"Security Testing","text":""},{"location":"development/security-best-practices/#automated-security-tests","title":"Automated Security Tests","text":"<pre><code>@Test\nvoid loginForm_ShouldPreventSQLInjection() {\n    // Given\n    LoginInput maliciousInput = new LoginInput();\n    maliciousInput.setEmail(\"'; DROP TABLE users; --\");\n    maliciousInput.setPassword(\"password\");\n\n    // When &amp; Then\n    BadCredentialsException exception = assertThrows(\n        BadCredentialsException.class,\n        () -&gt; authService.login(maliciousInput)\n    );\n\n    verify(securityAuditService).logSqlInjectionAttempt(\n        anyString(),\n        eq(\"'; DROP TABLE users; --\"),\n        any(HttpServletRequest.class)\n    );\n}\n</code></pre>"},{"location":"development/security-best-practices/#security-configuration-management","title":"Security Configuration Management","text":""},{"location":"development/security-best-practices/#environment-specific-security","title":"Environment-Specific Security","text":""},{"location":"development/security-best-practices/#development-environment","title":"Development Environment","text":"<pre><code># application-dev.yml\nsecurity:\n  jwt:\n    expiration-ms: 86400000  # 24 hours\n  rate-limiting:\n    enabled: false\n  cors:\n    allowed-origins: \"*\"\n</code></pre>"},{"location":"development/security-best-practices/#production-environment","title":"Production Environment","text":"<pre><code># application-prod.yml\nsecurity:\n  jwt:\n    expiration-ms: 3600000   # 1 hour\n  rate-limiting:\n    enabled: true\n    max-attempts: 5\n  cors:\n    allowed-origins: \"https://app.dealsphere.com,https://admin.dealsphere.com\"\n</code></pre>"},{"location":"development/security-best-practices/#secret-management","title":"Secret Management","text":""},{"location":"development/security-best-practices/#environment-variables","title":"Environment Variables","text":"<pre><code># Security secrets\nJWT_SECRET=&lt;256-bit-secure-random-key&gt;\nDB_PASSWORD=&lt;strong-database-password&gt;\nSMTP_PASSWORD=&lt;smtp-service-password&gt;\n\n# Encryption keys\nENCRYPTION_KEY=&lt;aes-256-key&gt;\nSIGNING_KEY=&lt;hmac-256-key&gt;\n</code></pre>"},{"location":"development/security-best-practices/#docker-secrets-production","title":"Docker Secrets (Production)","text":"<pre><code># docker-compose.prod.yml\nservices:\n  backend:\n    secrets:\n      - jwt_secret\n      - db_password\n      - smtp_password\n\nsecrets:\n  jwt_secret:\n    external: true\n  db_password:\n    external: true\n  smtp_password:\n    external: true\n</code></pre>"},{"location":"development/security-best-practices/#compliance-standards","title":"Compliance &amp; Standards","text":""},{"location":"development/security-best-practices/#security-standards-compliance","title":"Security Standards Compliance","text":"<ol> <li>OWASP Top 10 - All vulnerabilities addressed</li> <li>NIST Cybersecurity Framework - Controls implemented</li> <li>ISO 27001 - Information security management</li> <li>SOC 2 Type II - Security controls audit ready</li> </ol>"},{"location":"development/security-best-practices/#data-privacy-compliance","title":"Data Privacy Compliance","text":"<ol> <li>GDPR Compliance:</li> <li>Data minimization</li> <li>Right to erasure</li> <li>Consent management</li> <li> <p>Data portability</p> </li> <li> <p>CCPA Compliance:</p> </li> <li>Consumer data rights</li> <li>Privacy policy transparency</li> <li>Data deletion requests</li> </ol>"},{"location":"development/security-best-practices/#audit-requirements","title":"Audit Requirements","text":""},{"location":"development/security-best-practices/#security-event-retention","title":"Security Event Retention","text":"<ul> <li>Critical Events: 7 years</li> <li>High Severity: 3 years</li> <li>Medium/Low: 1 year</li> <li>Debug Events: 90 days</li> </ul>"},{"location":"development/security-best-practices/#compliance-reporting","title":"Compliance Reporting","text":"<pre><code>@Override\npublic Map&lt;String, Object&gt; generateSecurityReport(LocalDateTime startDate, LocalDateTime endDate) {\n    Map&lt;String, Object&gt; report = new HashMap&lt;&gt;();\n    report.put(\"period_start\", startDate.toString());\n    report.put(\"period_end\", endDate.toString());\n    report.put(\"message\", \"Security reports available in external observability system\");\n    report.put(\"generated_at\", LocalDateTime.now().toString());\n\n    return report;\n}\n</code></pre>"},{"location":"development/security-best-practices/#incident-response","title":"Incident Response","text":""},{"location":"development/security-best-practices/#security-incident-classification","title":"Security Incident Classification","text":"<ol> <li>Critical (P1): Active breach, system compromise</li> <li>High (P2): Attempted breach, vulnerability exploited</li> <li>Medium (P3): Suspicious activity, policy violation</li> <li>Low (P4): Security warning, configuration issue</li> </ol>"},{"location":"development/security-best-practices/#response-procedures","title":"Response Procedures","text":""},{"location":"development/security-best-practices/#immediate-response-p1p2","title":"Immediate Response (P1/P2)","text":"<ol> <li>Alert: Automated alerts to security team</li> <li>Isolate: Disable affected accounts/systems</li> <li>Investigate: Gather evidence and logs</li> <li>Contain: Prevent further damage</li> <li>Communicate: Notify stakeholders</li> </ol>"},{"location":"development/security-best-practices/#investigation-tools","title":"Investigation Tools","text":"<pre><code># Query security events\ngrep \"SECURITY_EVENT\" /var/log/dealsphere/security.log | \\\n  jq 'select(.severity == \"CRITICAL\")'\n\n# Check failed login attempts\ngrep \"LOGIN_FAILURE\" /var/log/dealsphere/security.log | \\\n  jq 'select(.ip_address == \"192.168.1.100\")'\n\n# Monitor real-time security events\ntail -f /var/log/dealsphere/security.log | \\\n  jq 'select(.risk_score &gt; 70)'\n</code></pre>"},{"location":"development/security-best-practices/#security-monitoring-dashboard","title":"Security Monitoring Dashboard","text":""},{"location":"development/security-best-practices/#key-metrics","title":"Key Metrics","text":"<ol> <li>Authentication Metrics</li> <li>Login success/failure rates</li> <li>Token validation errors</li> <li>Password reset frequency</li> <li> <p>Geographic login patterns</p> </li> <li> <p>Threat Detection</p> </li> <li>XSS/SQL injection attempts</li> <li>Brute force attack patterns</li> <li>Rate limiting violations</li> <li> <p>Suspicious IP activity</p> </li> <li> <p>System Health</p> </li> <li>Security service uptime</li> <li>Log processing latency</li> <li>Alert response times</li> <li>Compliance status</li> </ol>"},{"location":"development/security-best-practices/#alerting-rules","title":"Alerting Rules","text":"<pre><code># Example alerting configuration\nalerts:\n  - name: \"High Security Event Rate\"\n    condition: \"rate(security_events{severity='HIGH'}[5m]) &gt; 10\"\n    action: \"immediate_notification\"\n\n  - name: \"SQL Injection Attempt\"\n    condition: \"security_events{event_type='SQL_INJECTION_ATTEMPT'}\"\n    action: \"critical_alert\"\n\n  - name: \"Multiple Failed Logins\"\n    condition: \"rate(security_events{event_type='LOGIN_FAILURE'}[1m]) &gt; 5\"\n    action: \"investigate\"\n</code></pre>"},{"location":"development/security-best-practices/#future-security-enhancements","title":"Future Security Enhancements","text":""},{"location":"development/security-best-practices/#planned-improvements","title":"Planned Improvements","text":"<ol> <li>Multi-Factor Authentication (MFA)</li> <li>TOTP support</li> <li>SMS backup codes</li> <li> <p>Hardware token support</p> </li> <li> <p>Advanced Threat Detection</p> </li> <li>Machine learning anomaly detection</li> <li>Behavioral analysis</li> <li> <p>Geographic risk scoring</p> </li> <li> <p>Zero Trust Architecture</p> </li> <li>Micro-segmentation</li> <li>Device trust verification</li> <li> <p>Continuous authentication</p> </li> <li> <p>Enhanced Monitoring</p> </li> <li>Real-time threat intelligence</li> <li>Automated incident response</li> <li>Security orchestration</li> </ol>"},{"location":"development/security-best-practices/#security-roadmap","title":"Security Roadmap","text":"<ul> <li>Q1 2025: MFA implementation</li> <li>Q2 2025: Advanced threat detection</li> <li>Q3 2025: Zero trust migration</li> <li>Q4 2025: AI-powered security monitoring</li> </ul>"},{"location":"development/testing-strategy/","title":"Testing Strategy","text":""},{"location":"development/testing-strategy/#overview","title":"Overview","text":"<p>The DealSphere platform implements a comprehensive testing strategy covering unit tests, integration tests, end-to-end tests, and security tests. This document outlines our testing approach, tools, and best practices.</p>"},{"location":"development/testing-strategy/#testing-pyramid","title":"Testing Pyramid","text":"<pre><code>graph TD\n    A[E2E Tests&lt;br/&gt;Cypress] --&gt; B[Integration Tests&lt;br/&gt;TestContainers + Vitest]\n    B --&gt; C[Unit Tests&lt;br/&gt;JUnit + Vitest]\n    C --&gt; D[Static Analysis&lt;br/&gt;ESLint + Checkstyle]\n\n    style A fill:#ff9999\n    style B fill:#ffcc99\n    style C fill:#99ff99\n    style D fill:#9999ff\n</code></pre>"},{"location":"development/testing-strategy/#backend-testing","title":"Backend Testing","text":""},{"location":"development/testing-strategy/#unit-tests","title":"Unit Tests","text":"<p>Framework: JUnit 5 + Mockito Location: <code>backend/**/src/test/java/</code> Coverage Target: 85%+</p>"},{"location":"development/testing-strategy/#authentication-service-tests","title":"Authentication Service Tests","text":"<p>File: <code>AuthServiceImplTest.java</code></p> <pre><code>@ExtendWith(MockitoExtension.class)\nclass AuthServiceImplTest {\n\n    @Mock private UserProfileRepository userProfileRepository;\n    @Mock private UserCredentialsRepository userCredentialsRepository;\n    @Mock private PasswordEncoder passwordEncoder;\n    @Mock private JwtService jwtService;\n    @Mock private SecurityAuditService securityAuditService;\n\n    @InjectMocks private AuthServiceImpl authService;\n\n    @Test\n    void login_WithValidCredentials_ShouldReturnAuthPayload() {\n        // Given\n        when(userProfileRepository.findByEmail(\"test@example.com\"))\n            .thenReturn(Optional.of(testUserProfile));\n        when(passwordEncoder.matches(\"password123\", \"hashedPassword\"))\n            .thenReturn(true);\n        when(jwtService.generateToken(testUserProfile))\n            .thenReturn(\"jwt-token\");\n\n        // When\n        AuthPayload result = authService.login(validLoginInput);\n\n        // Then\n        assertThat(result.getToken()).isEqualTo(\"jwt-token\");\n        verify(securityAuditService).logLoginSuccess(eq(\"user-123\"), any());\n    }\n}\n</code></pre>"},{"location":"development/testing-strategy/#jwt-service-tests","title":"JWT Service Tests","text":"<p>File: <code>JwtServiceImplTest.java</code></p> <pre><code>class JwtServiceImplTest {\n\n    @Test\n    void generateToken_ShouldCreateValidToken() {\n        // When\n        String token = jwtService.generateToken(testUser);\n\n        // Then\n        assertThat(token).isNotNull();\n        assertTrue(jwtService.validateToken(token));\n        assertThat(jwtService.extractUserId(token)).isEqualTo(\"user-123\");\n    }\n\n    @Test\n    void validateToken_WithExpiredToken_ShouldReturnFalse() {\n        // Given - create expired token\n        String expiredToken = createExpiredToken();\n\n        // When\n        boolean isValid = jwtService.validateToken(expiredToken);\n\n        // Then\n        assertFalse(isValid);\n    }\n}\n</code></pre>"},{"location":"development/testing-strategy/#security-audit-tests","title":"Security Audit Tests","text":"<p>File: <code>SecurityAuditServiceImplTest.java</code></p> <pre><code>class SecurityAuditServiceImplTest {\n\n    @Test\n    void logLoginFailure_ShouldLogStructuredEvent() {\n        // Given\n        String email = \"test@example.com\";\n        String reason = \"Invalid password\";\n\n        // When\n        securityAuditService.logLoginFailure(email, reason, request);\n\n        // Then - Verify structured logging would occur\n        // In production, this verifies external observability integration\n        assertThat(email).isEqualTo(\"test@example.com\");\n        assertThat(reason).isEqualTo(\"Invalid password\");\n    }\n\n    @Test\n    void checkComplianceViolations_WithSensitiveDataExport_ShouldLogViolation() {\n        // Given\n        Map&lt;String, Object&gt; context = Map.of(\"sensitive_data\", true);\n\n        // When\n        securityAuditService.checkComplianceViolations(\"user-123\", \"export_user_data\", context);\n\n        // Then\n        assertThat(context).containsKey(\"sensitive_data\");\n    }\n}\n</code></pre>"},{"location":"development/testing-strategy/#integration-tests","title":"Integration Tests","text":"<p>Framework: Spring Boot Test + TestContainers Location: <code>backend/core/src/test/java/integration/</code></p>"},{"location":"development/testing-strategy/#database-integration","title":"Database Integration","text":"<pre><code>@SpringBootTest\n@TestPropertySource(properties = \"spring.jpa.hibernate.ddl-auto=create-drop\")\n@Testcontainers\nclass AuthIntegrationTest {\n\n    @Container\n    static PostgreSQLContainer&lt;?&gt; postgres = new PostgreSQLContainer&lt;&gt;(\"postgres:14\")\n            .withDatabaseName(\"testdb\")\n            .withUsername(\"test\")\n            .withPassword(\"test\");\n\n    @DynamicPropertySource\n    static void configureProperties(DynamicPropertyRegistry registry) {\n        registry.add(\"spring.datasource.url\", postgres::getJdbcUrl);\n        registry.add(\"spring.datasource.username\", postgres::getUsername);\n        registry.add(\"spring.datasource.password\", postgres::getPassword);\n    }\n\n    @Test\n    @Transactional\n    void completeAuthenticationFlow_ShouldWork() {\n        // Test complete flow: invite \u2192 register \u2192 login \u2192 access protected resource\n\n        // 1. Admin invites user\n        InvitationPayload invitation = authService.inviteUser(inviteInput, adminId);\n        assertThat(invitation.getSuccess()).isTrue();\n\n        // 2. User completes registration\n        CompleteRegistrationInput regInput = new CompleteRegistrationInput();\n        regInput.setInvitationToken(invitation.getInvitationId());\n        regInput.setPassword(\"newpassword123\");\n\n        AuthPayload authResult = authService.completeRegistration(regInput);\n        assertThat(authResult.getToken()).isNotNull();\n\n        // 3. User can login with new credentials\n        LoginInput loginInput = new LoginInput();\n        loginInput.setEmail(\"newuser@example.com\");\n        loginInput.setPassword(\"newpassword123\");\n\n        AuthPayload loginResult = authService.login(loginInput);\n        assertThat(loginResult.getToken()).isNotNull();\n    }\n}\n</code></pre>"},{"location":"development/testing-strategy/#graphql-integration-tests","title":"GraphQL Integration Tests","text":"<pre><code>@SpringBootTest(webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT)\n@AutoConfigureTestDatabase(replace = AutoConfigureTestDatabase.Replace.NONE)\nclass GraphQLAuthIntegrationTest {\n\n    @Test\n    void loginMutation_WithValidCredentials_ShouldReturnToken() throws Exception {\n        String query = \"\"\"\n            mutation Login($input: LoginInput!) {\n                login(input: $input) {\n                    token\n                    user {\n                        id\n                        email\n                        firstName\n                        lastName\n                    }\n                }\n            }\n        \"\"\";\n\n        mockMvc.perform(post(\"/graphql\")\n                .contentType(MediaType.APPLICATION_JSON)\n                .content(createGraphQLRequest(query, loginVariables)))\n                .andExpect(status().isOk())\n                .andExpect(jsonPath(\"$.data.login.token\").exists())\n                .andExpect(jsonPath(\"$.data.login.user.email\").value(\"test@example.com\"));\n    }\n}\n</code></pre>"},{"location":"development/testing-strategy/#performance-tests","title":"Performance Tests","text":"<p>Framework: JMeter + Gatling (planned) Target: 1000 concurrent users, &lt;200ms response time</p> <pre><code>@Test\n@Timeout(value = 2, unit = TimeUnit.SECONDS)\nvoid loginEndpoint_ShouldHandleHighLoad() {\n    // Simulate concurrent login attempts\n    CompletableFuture&lt;?&gt;[] futures = IntStream.range(0, 100)\n        .mapToObj(i -&gt; CompletableFuture.runAsync(() -&gt; {\n            try {\n                authService.login(createUniqueLoginInput(i));\n            } catch (Exception e) {\n                // Expected for some invalid attempts\n            }\n        }))\n        .toArray(CompletableFuture[]::new);\n\n    CompletableFuture.allOf(futures).join();\n\n    // Verify system remains responsive\n    assertTrue(authService.login(validLoginInput).getToken() != null);\n}\n</code></pre>"},{"location":"development/testing-strategy/#frontend-testing","title":"Frontend Testing","text":""},{"location":"development/testing-strategy/#unit-tests_1","title":"Unit Tests","text":"<p>Framework: Vitest + Testing Library Location: <code>frontend/src/**/__tests__/</code> Coverage Target: 85%+</p>"},{"location":"development/testing-strategy/#component-tests","title":"Component Tests","text":"<p>File: <code>Login.test.tsx</code></p> <pre><code>describe('Login Component', () =&gt; {\n  it('should validate email format', async () =&gt; {\n    renderWithProviders(&lt;Login /&gt;);\n\n    const emailInput = screen.getByLabelText(/email/i);\n    fireEvent.change(emailInput, { target: { value: 'invalid-email' } });\n    fireEvent.blur(emailInput);\n\n    await waitFor(() =&gt; {\n      expect(screen.getByText(/please enter a valid email address/i)).toBeInTheDocument();\n    });\n  });\n\n  it('should prevent XSS attacks', async () =&gt; {\n    renderWithProviders(&lt;Login /&gt;);\n\n    const emailInput = screen.getByLabelText(/email/i);\n    fireEvent.change(emailInput, { target: { value: '&lt;script&gt;alert(\"xss\")&lt;/script&gt;' } });\n    fireEvent.blur(emailInput);\n\n    await waitFor(() =&gt; {\n      expect(screen.getByText(/potentially malicious content detected/i)).toBeInTheDocument();\n    });\n  });\n\n  it('should handle login success', async () =&gt; {\n    const loginMock = {\n      request: { query: LOGIN_MUTATION, variables: { input: validCredentials } },\n      result: { data: { login: { token: 'mock-token', user: mockUser } } }\n    };\n\n    renderWithProviders(&lt;Login /&gt;, [loginMock]);\n\n    // Fill form and submit\n    fireEvent.change(screen.getByLabelText(/email/i), { target: { value: 'test@example.com' } });\n    fireEvent.change(screen.getByLabelText(/password/i), { target: { value: 'password123' } });\n    fireEvent.click(screen.getByRole('button', { name: /sign in/i }));\n\n    await waitFor(() =&gt; {\n      expect(mockNavigate).toHaveBeenCalledWith('/dashboard');\n    });\n  });\n});\n</code></pre>"},{"location":"development/testing-strategy/#hook-tests","title":"Hook Tests","text":"<p>File: <code>useAuth.test.ts</code></p> <pre><code>describe('useAuth Hook', () =&gt; {\n  it('should handle successful login', async () =&gt; {\n    const loginMock = createLoginMock();\n    const { result } = renderHook(() =&gt; useAuth(), {\n      wrapper: createWrapper([loginMock])\n    });\n\n    await act(async () =&gt; {\n      await result.current.login('test@example.com', 'password123');\n    });\n\n    expect(result.current.isAuthenticated).toBe(true);\n    expect(result.current.user).toEqual(mockUser);\n    expect(localStorage.setItem).toHaveBeenCalledWith('auth_token', 'mock-token');\n  });\n\n  it('should handle token refresh', async () =&gt; {\n    const refreshMock = createRefreshMock();\n    const { result } = renderHook(() =&gt; useAuth(), {\n      wrapper: createWrapper([refreshMock])\n    });\n\n    await act(async () =&gt; {\n      await result.current.refreshToken();\n    });\n\n    expect(result.current.token).toBe('refreshed-token');\n  });\n});\n</code></pre>"},{"location":"development/testing-strategy/#validation-utilities-tests","title":"Validation Utilities Tests","text":"<p>File: <code>validation.test.ts</code></p> <pre><code>describe('Validation Utilities', () =&gt; {\n  describe('sanitizeXSS', () =&gt; {\n    it('should sanitize script tags', () =&gt; {\n      const malicious = '&lt;script&gt;alert(\"xss\")&lt;/script&gt;';\n      const sanitized = sanitizeXSS(malicious);\n\n      expect(sanitized).not.toContain('&lt;script&gt;');\n      expect(sanitized).not.toContain('alert');\n    });\n\n    it('should preserve safe content', () =&gt; {\n      const safe = 'This is safe content with numbers 123';\n      const result = sanitizeXSS(safe);\n\n      expect(result).toContain('This is safe content');\n      expect(result).toContain('123');\n    });\n  });\n\n  describe('detectSQLInjection', () =&gt; {\n    it('should detect SQL injection patterns', () =&gt; {\n      expect(detectSQLInjection(\"'; DROP TABLE users; --\")).toBe(true);\n      expect(detectSQLInjection(\"' OR '1'='1\")).toBe(true);\n      expect(detectSQLInjection(\"admin'--\")).toBe(true);\n    });\n\n    it('should not flag safe content', () =&gt; {\n      expect(detectSQLInjection('user@example.com')).toBe(false);\n      expect(detectSQLInjection('password123')).toBe(false);\n    });\n  });\n});\n</code></pre>"},{"location":"development/testing-strategy/#integration-tests_1","title":"Integration Tests","text":"<p>File: <code>auth-flow.integration.test.tsx</code></p> <pre><code>describe('Authentication Flow Integration', () =&gt; {\n  it('should complete full login flow', async () =&gt; {\n    const loginMock = createLoginMock();\n    render(&lt;TestApp mocks={[loginMock]} /&gt;);\n\n    // Navigate to login\n    window.history.pushState({}, 'Login', '/login');\n\n    // Fill and submit form\n    fireEvent.change(screen.getByLabelText(/email/i), { target: { value: 'test@example.com' } });\n    fireEvent.change(screen.getByLabelText(/password/i), { target: { value: 'password123' } });\n    fireEvent.click(screen.getByRole('button', { name: /sign in/i }));\n\n    // Verify success\n    await waitFor(() =&gt; {\n      expect(localStorage.setItem).toHaveBeenCalledWith('auth_token', 'mock-token');\n    });\n  });\n\n  it('should complete invitation flow', async () =&gt; {\n    const inviteMock = createInviteMock();\n    const completeMock = createCompleteMock();\n\n    render(&lt;TestApp mocks={[inviteMock, completeMock]} /&gt;);\n\n    // Admin sends invitation\n    window.history.pushState({}, 'Invite', '/invite');\n    fillInvitationForm();\n    fireEvent.click(screen.getByRole('button', { name: /send invitation/i }));\n\n    await waitFor(() =&gt; {\n      expect(screen.getByText(/invitation sent successfully/i)).toBeInTheDocument();\n    });\n\n    // User completes registration\n    window.history.pushState({}, 'Complete', '/complete-registration?token=invitation-123');\n    fillRegistrationForm();\n    fireEvent.click(screen.getByRole('button', { name: /complete registration/i }));\n\n    await waitFor(() =&gt; {\n      expect(localStorage.setItem).toHaveBeenCalledWith('auth_token', 'new-user-token');\n    });\n  });\n});\n</code></pre>"},{"location":"development/testing-strategy/#end-to-end-tests","title":"End-to-End Tests","text":"<p>Framework: Cypress Location: <code>frontend/cypress/e2e/</code></p>"},{"location":"development/testing-strategy/#authentication-e2e-tests","title":"Authentication E2E Tests","text":"<p>File: <code>auth-flow.cy.ts</code></p> <pre><code>describe('Authentication Flow', () =&gt; {\n  beforeEach(() =&gt; {\n    // Reset database state\n    cy.task('db:reset');\n    // Setup test data\n    cy.task('db:seed');\n  });\n\n  it('should login successfully with valid credentials', () =&gt; {\n    cy.visit('/login');\n\n    cy.get('[data-testid=\"email-input\"]').type('admin@example.com');\n    cy.get('[data-testid=\"password-input\"]').type('password123');\n    cy.get('[data-testid=\"login-button\"]').click();\n\n    cy.url().should('include', '/dashboard');\n    cy.get('[data-testid=\"user-menu\"]').should('contain', 'Admin User');\n  });\n\n  it('should handle invitation flow', () =&gt; {\n    // Login as admin\n    cy.login('admin@example.com', 'password123');\n\n    // Send invitation\n    cy.visit('/users/invite');\n    cy.get('[data-testid=\"email-input\"]').type('newuser@example.com');\n    cy.get('[data-testid=\"first-name-input\"]').type('New');\n    cy.get('[data-testid=\"last-name-input\"]').type('User');\n    cy.get('[data-testid=\"send-invitation-button\"]').click();\n\n    cy.get('[data-testid=\"success-message\"]').should('contain', 'Invitation sent');\n\n    // Get invitation token from email (mocked)\n    cy.task('getLastEmail').then((email: any) =&gt; {\n      const invitationToken = extractTokenFromEmail(email.content);\n\n      // Complete registration\n      cy.visit(`/complete-registration?token=${invitationToken}`);\n      cy.get('[data-testid=\"password-input\"]').type('newpassword123');\n      cy.get('[data-testid=\"confirm-password-input\"]').type('newpassword123');\n      cy.get('[data-testid=\"complete-button\"]').click();\n\n      cy.url().should('include', '/dashboard');\n    });\n  });\n\n  it('should handle password reset flow', () =&gt; {\n    cy.visit('/reset-password');\n\n    cy.get('[data-testid=\"email-input\"]').type('user@example.com');\n    cy.get('[data-testid=\"send-reset-button\"]').click();\n\n    cy.get('[data-testid=\"success-message\"]').should('contain', 'Reset instructions sent');\n\n    // Get reset token from email (mocked)\n    cy.task('getLastEmail').then((email: any) =&gt; {\n      const resetToken = extractTokenFromEmail(email.content);\n\n      cy.visit(`/reset-password/confirm?token=${resetToken}`);\n      cy.get('[data-testid=\"new-password-input\"]').type('newpassword123');\n      cy.get('[data-testid=\"confirm-password-input\"]').type('newpassword123');\n      cy.get('[data-testid=\"reset-button\"]').click();\n\n      cy.get('[data-testid=\"success-message\"]').should('contain', 'Password reset successful');\n    });\n  });\n});\n</code></pre>"},{"location":"development/testing-strategy/#security-e2e-tests","title":"Security E2E Tests","text":"<p>File: <code>security.cy.ts</code></p> <pre><code>describe('Security Tests', () =&gt; {\n  it('should prevent XSS attacks', () =&gt; {\n    cy.visit('/login');\n\n    const xssPayload = '&lt;script&gt;alert(\"xss\")&lt;/script&gt;';\n    cy.get('[data-testid=\"email-input\"]').type(xssPayload);\n    cy.get('[data-testid=\"email-input\"]').blur();\n\n    cy.get('[data-testid=\"error-message\"]').should('contain', 'malicious content detected');\n    cy.get('[data-testid=\"login-button\"]').should('be.disabled');\n  });\n\n  it('should prevent SQL injection', () =&gt; {\n    cy.visit('/login');\n\n    const sqlPayload = \"'; DROP TABLE users; --\";\n    cy.get('[data-testid=\"email-input\"]').type(sqlPayload);\n    cy.get('[data-testid=\"email-input\"]').blur();\n\n    cy.get('[data-testid=\"error-message\"]').should('contain', 'malicious content detected');\n  });\n\n  it('should enforce rate limiting', () =&gt; {\n    cy.visit('/login');\n\n    // Attempt multiple failed logins\n    for (let i = 0; i &lt; 6; i++) {\n      cy.get('[data-testid=\"email-input\"]').clear().type('test@example.com');\n      cy.get('[data-testid=\"password-input\"]').clear().type('wrongpassword');\n      cy.get('[data-testid=\"login-button\"]').click();\n\n      if (i &lt; 5) {\n        cy.get('[data-testid=\"error-message\"]').should('contain', 'Invalid credentials');\n      }\n    }\n\n    // 6th attempt should be rate limited\n    cy.get('[data-testid=\"error-message\"]').should('contain', 'Too many attempts');\n  });\n});\n</code></pre>"},{"location":"development/testing-strategy/#security-testing","title":"Security Testing","text":""},{"location":"development/testing-strategy/#penetration-testing","title":"Penetration Testing","text":""},{"location":"development/testing-strategy/#automated-security-scans","title":"Automated Security Scans","text":"<pre><code># OWASP ZAP automated scan\ndocker run -t owasp/zap2docker-stable zap-baseline.py \\\n  -t http://localhost:3000 \\\n  -g gen.conf \\\n  -r zap-report.html\n\n# Nmap port scan\nnmap -sV -sC localhost\n\n# SSL/TLS testing\ntestssl.sh localhost:443\n</code></pre>"},{"location":"development/testing-strategy/#manual-security-tests","title":"Manual Security Tests","text":"<pre><code>@Test\nclass SecurityTest {\n\n    @Test\n    void shouldPreventSQLInjection() {\n        // Test various SQL injection payloads\n        String[] payloads = {\n            \"'; DROP TABLE users; --\",\n            \"' OR '1'='1\",\n            \"'; INSERT INTO users VALUES('hacker', 'pass'); --\",\n            \"' UNION SELECT password FROM users WHERE '1'='1\"\n        };\n\n        for (String payload : payloads) {\n            LoginInput input = new LoginInput();\n            input.setEmail(payload);\n            input.setPassword(\"password\");\n\n            assertThrows(BadCredentialsException.class, () -&gt; authService.login(input));\n        }\n    }\n\n    @Test\n    void shouldPreventXSSAttacks() {\n        String[] xssPayloads = {\n            \"&lt;script&gt;alert('xss')&lt;/script&gt;\",\n            \"javascript:alert('xss')\",\n            \"&lt;img src=x onerror=alert('xss')&gt;\",\n            \"&lt;iframe src=javascript:alert('xss')&gt;&lt;/iframe&gt;\"\n        };\n\n        for (String payload : xssPayloads) {\n            InviteUserInput input = new InviteUserInput();\n            input.setEmail(\"test@example.com\");\n            input.setFirstName(payload);\n\n            boolean result = validationService.validateInput(input.getFirstName());\n            assertFalse(result, \"XSS payload should be detected: \" + payload);\n        }\n    }\n}\n</code></pre>"},{"location":"development/testing-strategy/#performance-testing","title":"Performance Testing","text":""},{"location":"development/testing-strategy/#load-testing","title":"Load Testing","text":"<p>Framework: Gatling Location: <code>performance-tests/</code></p> <pre><code>class AuthLoadTest extends Simulation {\n\n  val httpProtocol = http\n    .baseUrl(\"http://localhost:8080\")\n    .acceptHeader(\"application/json\")\n\n  val loginScenario = scenario(\"Login Load Test\")\n    .exec(http(\"login\")\n      .post(\"/graphql\")\n      .header(\"Content-Type\", \"application/json\")\n      .body(StringBody(\"\"\"\n        {\n          \"query\": \"mutation { login(input: { email: \\\"${email}\\\", password: \\\"${password}\\\" }) { token user { id } } }\"\n        }\n      \"\"\"))\n      .check(status.is(200))\n      .check(jsonPath(\"$.data.login.token\").exists))\n\n  setUp(\n    loginScenario.inject(\n      constantUsersPerSec(10) during (30 seconds),\n      rampUsersPerSec(10) to 50 during (60 seconds),\n      constantUsersPerSec(50) during (120 seconds)\n    )\n  ).protocols(httpProtocol)\n}\n</code></pre>"},{"location":"development/testing-strategy/#stress-testing","title":"Stress Testing","text":"<pre><code>// Frontend stress test\ndescribe('Frontend Performance', () =&gt; {\n  it('should handle rapid form submissions', async () =&gt; {\n    renderWithProviders(&lt;Login /&gt;);\n\n    const submitPromises = Array.from({ length: 100 }, () =&gt; {\n      return new Promise&lt;void&gt;((resolve) =&gt; {\n        setTimeout(() =&gt; {\n          fireEvent.click(screen.getByRole('button', { name: /sign in/i }));\n          resolve();\n        }, Math.random() * 100);\n      });\n    });\n\n    await Promise.all(submitPromises);\n\n    // Component should remain responsive\n    expect(screen.getByLabelText(/email/i)).toBeInTheDocument();\n  });\n});\n</code></pre>"},{"location":"development/testing-strategy/#test-data-management","title":"Test Data Management","text":""},{"location":"development/testing-strategy/#test-database-setup","title":"Test Database Setup","text":"<p>TestContainers Configuration:</p> <pre><code>@TestConfiguration\npublic class TestDatabaseConfig {\n\n    @Bean\n    @Primary\n    @ConfigurationProperties(\"spring.datasource\")\n    public DataSource testDataSource() {\n        return DataSourceBuilder.create()\n            .driverClassName(\"org.testcontainers.jdbc.ContainerDatabaseDriver\")\n            .url(\"jdbc:tc:postgresql:14:///testdb\")\n            .build();\n    }\n}\n</code></pre>"},{"location":"development/testing-strategy/#data-factories","title":"Data Factories","text":"<pre><code>@Component\npublic class TestDataFactory {\n\n    public UserProfile createTestUser(String email) {\n        return UserProfile.builder()\n            .id(UUID.randomUUID().toString())\n            .email(email)\n            .firstName(\"Test\")\n            .lastName(\"User\")\n            .isActive(true)\n            .createdAt(OffsetDateTime.now())\n            .build();\n    }\n\n    public UserCredentials createTestCredentials(UserProfile user, String password) {\n        return UserCredentials.builder()\n            .userId(user.getId())\n            .username(user.getEmail())\n            .passwordHash(passwordEncoder.encode(password))\n            .userProfile(user)\n            .build();\n    }\n}\n</code></pre>"},{"location":"development/testing-strategy/#test-automation-cicd","title":"Test Automation &amp; CI/CD","text":""},{"location":"development/testing-strategy/#github-actions-pipeline","title":"GitHub Actions Pipeline","text":"<pre><code>name: Test Suite\n\non: [push, pull_request]\n\njobs:\n  backend-tests:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Set up Java\n        uses: actions/setup-java@v3\n        with:\n          java-version: '17'\n\n      - name: Run unit tests\n        run: ./gradlew test\n\n      - name: Run integration tests\n        run: ./gradlew integrationTest\n\n      - name: Generate test report\n        run: ./gradlew jacocoTestReport\n\n      - name: Upload coverage to Codecov\n        uses: codecov/codecov-action@v3\n\n  frontend-tests:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Set up Node.js\n        uses: actions/setup-node@v3\n        with:\n          node-version: '18'\n\n      - name: Install dependencies\n        run: pnpm install\n\n      - name: Run unit tests\n        run: pnpm test:coverage\n\n      - name: Run E2E tests\n        run: pnpm test:e2e\n\n      - name: Upload coverage\n        uses: codecov/codecov-action@v3\n\n  security-tests:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Run security scan\n        uses: securecodewarrior/github-action-add-sarif@v1\n        with:\n          sarif-file: security-scan-results.sarif\n</code></pre>"},{"location":"development/testing-strategy/#test-reports","title":"Test Reports","text":""},{"location":"development/testing-strategy/#coverage-reports","title":"Coverage Reports","text":"<ul> <li>Backend: JaCoCo HTML reports</li> <li>Frontend: Vitest coverage reports</li> <li>Combined: SonarQube integration</li> </ul>"},{"location":"development/testing-strategy/#test-execution-reports","title":"Test Execution Reports","text":"<ul> <li>JUnit XML: For CI/CD integration</li> <li>Allure Reports: For detailed test documentation</li> <li>Performance Reports: Gatling HTML reports</li> </ul>"},{"location":"development/testing-strategy/#test-quality-gates","title":"Test Quality Gates","text":""},{"location":"development/testing-strategy/#coverage-thresholds","title":"Coverage Thresholds","text":"<pre><code># sonar-project.properties\nsonar.coverage.jacoco.xmlReportPaths=backend/build/reports/jacoco/test/jacocoTestReport.xml\nsonar.javascript.lcov.reportPaths=frontend/coverage/lcov.info\n\n# Quality gates\nsonar.coverage.threshold=80\nsonar.duplication.threshold=5\nsonar.maintainability.rating=A\nsonar.reliability.rating=A\nsonar.security.rating=A\n</code></pre>"},{"location":"development/testing-strategy/#test-execution-requirements","title":"Test Execution Requirements","text":"<ol> <li>All tests must pass before merge</li> <li>Coverage must be &gt;= 80% for new code</li> <li>No security vulnerabilities in dependencies</li> <li>Performance tests must meet SLA requirements</li> <li>E2E tests must pass in staging environment</li> </ol>"},{"location":"development/testing-strategy/#best-practices","title":"Best Practices","text":""},{"location":"development/testing-strategy/#test-organization","title":"Test Organization","text":"<pre><code>backend/src/test/java/\n\u251c\u2500\u2500 unit/                    # Fast, isolated unit tests\n\u2502   \u251c\u2500\u2500 service/\n\u2502   \u251c\u2500\u2500 controller/\n\u2502   \u2514\u2500\u2500 util/\n\u251c\u2500\u2500 integration/             # Component integration tests\n\u2502   \u251c\u2500\u2500 repository/\n\u2502   \u251c\u2500\u2500 service/\n\u2502   \u2514\u2500\u2500 graphql/\n\u2514\u2500\u2500 e2e/                     # End-to-end tests\n    \u251c\u2500\u2500 auth/\n    \u2514\u2500\u2500 user/\n\nfrontend/src/\n\u251c\u2500\u2500 components/__tests__/    # Component unit tests\n\u251c\u2500\u2500 hooks/__tests__/         # Hook tests\n\u251c\u2500\u2500 utils/__tests__/         # Utility tests\n\u251c\u2500\u2500 test/integration/        # Integration tests\n\u2514\u2500\u2500 cypress/e2e/            # E2E tests\n</code></pre>"},{"location":"development/testing-strategy/#test-naming-conventions","title":"Test Naming Conventions","text":"<pre><code>// Backend: Given_When_Then format\n@Test\nvoid login_WithInvalidPassword_ShouldThrowBadCredentialsException() {\n    // Test implementation\n}\n\n// Frontend: Should format\nit('should prevent XSS attacks in email field', () =&gt; {\n    // Test implementation\n});\n</code></pre>"},{"location":"development/testing-strategy/#test-data-management_1","title":"Test Data Management","text":"<ol> <li>Use builders for complex test objects</li> <li>Clean up after tests (database, files, etc.)</li> <li>Use factories for consistent test data</li> <li>Isolate test data between test cases</li> <li>Use realistic test data that resembles production</li> </ol>"},{"location":"development/testing-strategy/#mocking-guidelines","title":"Mocking Guidelines","text":"<ol> <li>Mock external dependencies (APIs, databases in unit tests)</li> <li>Don't mock value objects (DTOs, entities)</li> <li>Use TestContainers for integration tests</li> <li>Verify interactions on mocks when behavior matters</li> <li>Reset mocks between tests</li> </ol> <p>This comprehensive testing strategy ensures high-quality, secure, and reliable authentication functionality across the entire DealSphere platform.</p>"},{"location":"planning/delivery-plan-12weeks-tdd/","title":"12-Week MVP Delivery Plan (TDD Approach)","text":"<p>This plan breaks the MVP delivery into six 2-week sprints. Each sprint is defined by an epic, a set of stories (major tasks), and explicit deliverables that must be achieved for a sprint to be considered \u201cdone.\u201d All work must be validated by passing tests, demos, and CI/CD artefacts.</p>"},{"location":"planning/delivery-plan-12weeks-tdd/#sprint-1-weeks-12-core-framework-auth","title":"Sprint 1 (Weeks 1\u20132): Core Framework &amp; Auth","text":""},{"location":"planning/delivery-plan-12weeks-tdd/#stories","title":"Stories","text":"<ul> <li>Project repo setup (backend, frontend, Docker Compose, DB, initial CI/CD pipeline)</li> <li>Code style, linting, and TDD test framework (Java/React)</li> <li>User authentication (Login/Logout)</li> <li>Role/permission model setup and TDD</li> <li>Negative/abuse authentication and permission tests</li> <li>Dev/staging environments and build artefact validation</li> </ul>"},{"location":"planning/delivery-plan-12weeks-tdd/#deliverables","title":"Deliverables","text":"<ul> <li>CI pipeline running with all checks</li> <li>Docker Compose brings up all services in local/dev</li> <li>Passing unit/integration tests for authentication/RBAC</li> <li>Demo: User login/logout via UI and backend API</li> <li>\"Green\" RBAC/auth checks in test suite</li> </ul>"},{"location":"planning/delivery-plan-12weeks-tdd/#sprint-2-weeks-34-user-mgmt-documents","title":"Sprint 2 (Weeks 3\u20134): User Mgmt &amp; Documents","text":""},{"location":"planning/delivery-plan-12weeks-tdd/#stories_1","title":"Stories","text":"<ul> <li>Complete User CRUD (API &amp; UI) with full RBAC enforcement</li> <li>Document upload/download (S3/MinIO integration)</li> <li>Document metadata, versioning, and audit log</li> <li>Document access restrictions (class/role/ownership)</li> <li>Negative/edge document flows</li> <li>Doc AI/categorization prototype</li> </ul>"},{"location":"planning/delivery-plan-12weeks-tdd/#deliverables_1","title":"Deliverables","text":"<ul> <li>User management UI/API running and tested</li> <li>Document workflow (upload, version, access, audit) demoable</li> <li>Document access strictly enforced by RBAC</li> <li>Unit/integration tests green for user/document modules</li> <li>Audit logs and doc AI/categorization prototype in dev</li> <li>Demoable user and document features</li> </ul>"},{"location":"planning/delivery-plan-12weeks-tdd/#sprint-3-weeks-56-capital-call-waterfall","title":"Sprint 3 (Weeks 5\u20136): Capital Call &amp; Waterfall","text":""},{"location":"planning/delivery-plan-12weeks-tdd/#stories_2","title":"Stories","text":"<ul> <li>Capital call create/view/update (UI and API)</li> <li>Notification integration (email/in-app)</li> <li>Waterfall model design (algorithms, DB)</li> <li>Waterfall calculation/unit allocation features</li> <li>Negative/corner capital call and waterfall tests</li> </ul>"},{"location":"planning/delivery-plan-12weeks-tdd/#deliverables_2","title":"Deliverables","text":"<ul> <li>Capital call workflow (from create to notification) demoable</li> <li>Waterfall logic for PRD scenarios covered and tested</li> <li>Notifications firing in all intended scenarios</li> <li>Passing end-to-end/negative tests for capital call &amp; waterfall</li> <li>Demo of capital call + waterfall, start to finish</li> </ul>"},{"location":"planning/delivery-plan-12weeks-tdd/#sprint-4-weeks-78-workflow-automation-integrations","title":"Sprint 4 (Weeks 7\u20138): Workflow Automation &amp; Integrations","text":""},{"location":"planning/delivery-plan-12weeks-tdd/#stories_3","title":"Stories","text":"<ul> <li>Approval, reminders, SLA scheduler for workflow</li> <li>Workflow state transitions (approval \u2192 notification \u2192 escalation)</li> <li>AI-assisted capital call/doc query implementation</li> <li>R3 Corda integration stub/mock (main flows + error cases)</li> <li>Integration/edge tests for AI, Corda, bank API</li> </ul>"},{"location":"planning/delivery-plan-12weeks-tdd/#deliverables_3","title":"Deliverables","text":"<ul> <li>Automated workflow demo (with SLAs/triggers)</li> <li>Integration stubs working for all major paths</li> <li>E2E, workflow &amp; integration tests passing in CI</li> <li>Demo: approvals/escalation in test/stage</li> </ul>"},{"location":"planning/delivery-plan-12weeks-tdd/#sprint-5-weeks-910-accounting-analytics-portfolio","title":"Sprint 5 (Weeks 9\u201310): Accounting, Analytics, Portfolio","text":""},{"location":"planning/delivery-plan-12weeks-tdd/#stories_4","title":"Stories","text":"<ul> <li>Fund ledger, NAV calculation, reports UI</li> <li>Analytics dashboards, role-based views, CSV export</li> <li>Portfolio/company/investment tracking screens</li> <li>Data integrity/reporting edge tests</li> <li>Cross-role analytics validation</li> </ul>"},{"location":"planning/delivery-plan-12weeks-tdd/#deliverables_4","title":"Deliverables","text":"<ul> <li>Analytics/reporting UI shows real/test data</li> <li>Portfolio/accounting screens tested, working</li> <li>CSV export/bulk data tested for all grids</li> <li>Acceptance/unit/integration tests pass for metrics, portfolio</li> <li>Demo: analytics, reporting, and portfolio features</li> </ul>"},{"location":"planning/delivery-plan-12weeks-tdd/#sprint-6-weeks-1112-e2e-security-launch-ready","title":"Sprint 6 (Weeks 11\u201312): E2E, Security, Launch-Ready","text":""},{"location":"planning/delivery-plan-12weeks-tdd/#stories_5","title":"Stories","text":"<ul> <li>Full end-to-end UI automation (Cypress/Playwright)</li> <li>Security, RBAC bypass, and abuse/edge case tests</li> <li>Load/smoke/restore test scripts &amp; backup/restore process validation</li> <li>Performance &amp; non-functional: failover and basic regression</li> <li>Polishing, bug fixes, final checks, and code freeze</li> <li>Freeze/publish all architecture/release/deployment docs</li> </ul>"},{"location":"planning/delivery-plan-12weeks-tdd/#deliverables_5","title":"Deliverables","text":"<ul> <li>End-to-end automated test journeys \u201cgreen\u201d for all critical flows</li> <li>Security, load, failover, restore, and abuse tests pass</li> <li>All critical path test cases pass (functional, integration, security)</li> <li>Demo complete MVP user flows per persona</li> <li>Launch checklist and final documentation published</li> </ul>"},{"location":"planning/delivery-plan-12weeks-tdd/#usage-notes","title":"Usage Notes","text":"<ul> <li>Each sprint is \u201cdone\u201d only when all stories are completed and deliverables demonstrably met.</li> <li>Always validate by demo and passing CI/CD tests.</li> <li>If features spill to the next sprint, update scope and priorities in this document.</li> </ul> <p>Last updated: August 2025</p>"},{"location":"planning/phase1-epics/","title":"Phase 1 Epics: Weekly Tech Deliverables Guide","text":"<p>This document provides a week-by-week breakdown of all core tech deliverables for Phase 1 of DealSphere, ensuring that every business-critical capability from the PRD and all functional test cases are tracked and completed. Each Epic summarizes a vertical slice (major user-facing/integrated feature set) and links every deliverable to specific functional test cases. Use this guide as the master reference for sprint planning, tracking, and acceptance\u2014each Story or Deliverable is \u201cDone\u201d when all linked test cases are passing in CI.</p> Epic (Weeks) Story / Deliverable Linked Functional Test Cases Core Framework &amp; Auth (1\u20132) Repo, CI pipeline, Docker Compose setup -- User authentication (Login/Logout) 1.1.1, 1.1.2, 1.1.5, 1.2.5 Role/permission model setup, TDD tests 1.1.3, 1.1.4, 1.1.6, 1.1.7 Basic negative/abuse auth tests 1.2.1, 1.2.2, 1.2.3 User Mgmt &amp; Documents (3\u20134) User CRUD (API &amp; UI), RBAC enforcement 1.3.2 Document upload/download, S3/MinIO integration 2.1.1, 2.1.2, 2.1.4 Document metadata, versioning, audit log 2.1.3, 2.2.1\u20132.2.4 Doc access restriction tests 2.1.4 Basic doc AI/categorization test stub 2.3.1\u20132.3.3 Capital Call &amp; Waterfall (5\u20136) Capital call create/view/update 3.1.1\u20133.1.4, 3.2.1\u20133.2.4 Notification integration (email/in-app) 3.1.3, 3.2.3 Waterfall model scaffolding 4.1.1\u20134.1.5, 4.2.1\u20134.2.3 Waterfall calculation, unit allocation 4.3.1\u20134.3.4 Capital call/Waterfall negative/edge case tests 3.3.1\u20133.3.3, 4.2.4 Workflow Automation &amp; Integrations (7\u20138) Approval, reminder, SLA scheduler 5.1.1\u20135.1.4, 5.2.1\u20135.2.4, 5.3.1\u20135.3.3 AI-assisted capital call, doc query iteration 7.1.1\u20137.1.3, 7.2.1\u20137.2.3, 7.3.1\u20137.3.3 R3 Corda stub integration 1.3.1\u20131.3.3 Integration/edge tests for AI/Corda 8.2.1\u20138.2.3 Accounting, Analytics, Portfolio (9\u201310) Fund ledger, NAV, report UI &amp; export 6.1.1\u20136.1.3, 6.3.1\u20136.3.4, 9.1.1\u20139.1.3, 9.2.1\u20139.2.4 Analytics dashboards and role-based views 6.2.1\u20136.2.3, 10.1.1\u201310.1.3 Portfolio and company tracking 10.2.1\u201310.2.4 E2E, Security, Launch-Ready (11\u201312) End-to-end UI flow automation ALL major functional test cases Security/negative tests (abuse, failover, RBAC) 1.2.4, 8.1.1\u20138.1.3 Load/smoke/restore tests, backup-restore Performance and reliability testing Final non-functional and regression suite ALL <p>How to use this document:</p> <ul> <li>Sprint Planning: Assign stories/deliverables week by week, referencing test cases to ensure test-driven development and coverage.</li> <li>Tracking Progress: Check off epics and stories as their corresponding test cases pass\u2014all features are \u201cDone\u201d only when verified by passing tests.</li> <li>Review &amp; Adjust: Re-align deliverables or epics as priorities shift in the MVP build, ensuring that every functional and technical goal remains traceable.</li> <li>Traceability: If new features/test cases are added, extend the table and epics so the plan always aligns with current project reality.</li> </ul> <p>For questions, proposed changes, or refinement, update this doc and communicate with the DealSphere tech and QA teams.</p>"},{"location":"planning/brd/backend-core-framework-and-auth/","title":"Business Requirements Document (BRD)","text":""},{"location":"planning/brd/backend-core-framework-and-auth/#epic-core-framework-auth-weeks-12","title":"Epic: Core Framework &amp; Auth (Weeks 1\u20132)","text":"<p>Document Owner: Product Manager Stakeholders: DevOps, Backend, Frontend, Security, QA Teams Version: 1.0 Status: Draft</p>"},{"location":"planning/brd/backend-core-framework-and-auth/#1-executive-summary","title":"1. Executive Summary","text":"<p>The purpose of this initiative is to lay the technical foundation for the DealSphere Platform by delivering a robust core framework and secure authentication system. This core will support all upcoming features and will be essential for scalability, security, and maintainability.</p>"},{"location":"planning/brd/backend-core-framework-and-auth/#2-business-objectives","title":"2. Business Objectives","text":"<ul> <li>Accelerate subsequent feature development by establishing a production-grade development and deployment environment.</li> <li>Secure all user data and system access via a modern authentication and authorization framework.</li> <li>Ensure the platform\u2019s CI/CD process is automated, reliable, and enforces coding and testing standards.</li> <li>Provide high test coverage and automated security validation for all implemented modules.</li> </ul>"},{"location":"planning/brd/backend-core-framework-and-auth/#3-scope","title":"3. Scope","text":""},{"location":"planning/brd/backend-core-framework-and-auth/#in-scope","title":"In Scope","text":"<ul> <li>Setting up and validating repository structure for backend, frontend, and database.</li> <li>Implementation of Docker Compose to orchestrate multi-service setup.</li> <li>Establishment of a complete CI/CD pipeline with code quality enforcement and automated tests.</li> <li>Development of JWT-based authentication (login, logout, password reset, session management).</li> <li>Creation of a secure, extensible role-based access control (RBAC) system and role assignment workflows.</li> <li>Security hardening including rate limiting, security headers, input validation, and lockout protection.</li> <li>Deployment of distinct development and staging environments with all necessary configurations and artifact validations.</li> <li>Comprehensive unit, integration, and security testing.</li> </ul>"},{"location":"planning/brd/backend-core-framework-and-auth/#out-of-scope","title":"Out of Scope","text":"<ul> <li>Non-authenticated user flows (e.g., public pages).</li> <li>Non-core business features (e.g., deal management, user profile enhancements).</li> </ul>"},{"location":"planning/brd/backend-core-framework-and-auth/#4-requirements","title":"4. Requirements","text":""},{"location":"planning/brd/backend-core-framework-and-auth/#functional-requirements","title":"Functional Requirements","text":"ID Requirement Priority FR-01 Repository deploys via Docker Compose on all target hosts High FR-02 CI/CD pipeline (GitHub Actions) runs automated tests and builds High FR-03 Users can register, validate email, and login/logout securely High FR-04 System handles password resets and account lockouts High FR-05 JWT tokens are generated, validated, and refreshed properly High FR-06 Role assignment (RBAC) and immediate role/permission changes High FR-07 Each API endpoint and UI element is permission-protected High FR-08 Automated security and negative/abuse testing is in place High FR-09 All environments are fully operational and validated High"},{"location":"planning/brd/backend-core-framework-and-auth/#non-functional-requirements","title":"Non-Functional Requirements","text":"<ul> <li>System must meet or exceed 80% test coverage for all critical user flows.</li> <li>Enforce linting and code formatting pre-merge.</li> <li>All error messages must avoid leaking sensitive information.</li> <li>Security automations should validate against common vulnerabilities (e.g., OWASP Top 10).</li> </ul>"},{"location":"planning/brd/backend-core-framework-and-auth/#5-acceptance-criteria","title":"5. Acceptance Criteria","text":"<ul> <li>Repository and environments can be spun up via Docker Compose.</li> <li>CI/CD pipeline executes all stages (test, build, deploy).</li> <li>Minimum 80% test coverage for all code.</li> <li>User registration with email validation is verified.</li> <li>Successful login/logout and password reset flow with JWTs.</li> <li>Failed authentication attempts trigger account lockout rules.</li> <li>Role assignment/changes reflect immediately across the system.</li> <li>All API endpoints and UI elements are protected by the RBAC system.</li> <li>Penetration and negative tests report no critical vulnerabilities.</li> <li>Documentation for setup, deployment, and usage is complete.</li> </ul>"},{"location":"planning/brd/backend-core-framework-and-auth/#6-success-metrics","title":"6. Success Metrics","text":"<ul> <li>All tasks and acceptance criteria are met and validated through QA.</li> <li>100% functional and security test coverage on authentication and RBAC components.</li> <li>Successful deployment to development and staging, with use case test completion.</li> <li>No critical security findings in initial scans.</li> <li>Complete project documentation is delivered and reviewed.</li> </ul>"},{"location":"planning/brd/backend-core-framework-and-auth/#7-dependencies-risks","title":"7. Dependencies &amp; Risks","text":"<ul> <li>Database schema must be finalized for proper implementation of RBAC and authentication.</li> <li>Choice and configuration of JWT tokens will influence all future user/session management features.</li> <li>Delays or misconfigurations in environment setup may block the onboarding of parallel teams.</li> <li>Security approach taken will set the precedent for all future features\u2014must be carefully validated.</li> </ul>"},{"location":"planning/brd/backend-core-framework-and-auth/#8-out-of-scope-exclusions","title":"8. Out of Scope &amp; Exclusions","text":"<ul> <li>User interfaces beyond login/auth and basic RBAC display for the initial phase.</li> <li>Business workflows unrelated to core authentication, permissions, or deployment pipeline.</li> </ul>"},{"location":"planning/brd/backend-core-framework-and-auth/#9-stakeholder-sign-off","title":"9. Stakeholder Sign-Off","text":"<p>Stakeholders must review and sign off on: - Acceptance criteria alignment - Security control approach - Deployment and test automation readiness</p>"},{"location":"planning/tech-spec/backend-core-framework-and-auth/","title":"Technical Specification Document","text":""},{"location":"planning/tech-spec/backend-core-framework-and-auth/#epic-core-framework-auth","title":"Epic: Core Framework &amp; Auth","text":""},{"location":"planning/tech-spec/backend-core-framework-and-auth/#1-architecture-overview","title":"1. Architecture Overview","text":"<ul> <li>Backend: Java / Spring Boot microservices</li> <li>Frontend: React with TypeScript</li> <li>Database: PostgreSQL  </li> <li>Authentication: JWT token-based authentication and session management</li> <li>Infrastructure: Docker &amp; Docker Compose for orchestration</li> <li>CI/CD: GitHub Actions for builds, deployment, and security enforcement</li> </ul>"},{"location":"planning/tech-spec/backend-core-framework-and-auth/#2-infrastructure-repository","title":"2. Infrastructure &amp; Repository","text":"<ul> <li>Repository Structure:<ul> <li><code>/backend</code>: Spring Boot services, setup for modular architecture.</li> <li><code>/frontend</code>: React codebase with hooks and state management using Redux or Context API.</li> <li><code>/database</code>: SQL migration scripts handled by Flyway or Liquibase.</li> <li><code>/docker</code>: Service-specific Dockerfiles, one Docker Compose root.</li> </ul> </li> <li>Deployment: <ul> <li>All core services communicated via Docker Compose networks.</li> <li>Standard GitHub Actions used for building, linting, and deploying to development/staging.</li> </ul> </li> <li>Environment Variables:<ul> <li>Secure by using <code>.env</code> (for local) and CI/CD secret store (for deployment).</li> </ul> </li> <li>Build Artifacts Validation:<ul> <li>Each build generates reports for code coverage, test results, and security scan logs.</li> </ul> </li> </ul>"},{"location":"planning/tech-spec/backend-core-framework-and-auth/#3-authentication-system","title":"3. Authentication System","text":"<ul> <li>User Registration:<ul> <li>Endpoint for signup; requires unique username/email and password. Triggers email validation workflow (SMTP integration).</li> </ul> </li> <li>Login &amp; Logout:<ul> <li>Login endpoint issues secure JWT access &amp; refresh tokens.</li> <li>Logout endpoint invalidates session and rotates tokens.</li> </ul> </li> <li>Session Management:<ul> <li>JWTs have expiry (configurable, default 15 minutes for access, 7 days for refresh).</li> <li>Server validates tokens on every secured request; issues new access token on refresh.</li> </ul> </li> <li>Password Handling:<ul> <li>Passwords hashed with bcrypt.</li> <li>Password reset via secure one-time token sent to validated email.</li> </ul> </li> <li>Account Lockout:<ul> <li>Configurable maximum failed attempts (default: 5), with exponential back-off lockout policy.</li> </ul> </li> <li>Security Protections:<ul> <li>CSRF not required for APIs, but CORS configuration enforced.</li> <li>Security headers (CSP, X-Frame-Options, HSTS, etc.) set at load balancer/REST layer.</li> <li>Rate limiting with Redis (or similar) for sensitive endpoints.</li> </ul> </li> </ul>"},{"location":"planning/tech-spec/backend-core-framework-and-auth/#4-authorization-rbac","title":"4. Authorization &amp; RBAC","text":"<ul> <li>Roles &amp; Permissions:<ul> <li>User roles predefined (e.g., <code>admin</code>, <code>user</code>, <code>ops</code>), with expandable role sets.</li> <li>Permissions stored in DB and served as JWT claims.</li> <li>Role assignments are mutable by authorized admins in real-time; changes take effect immediately.</li> </ul> </li> <li>API and UI Controls:<ul> <li>Backend checks required roles/permissions for every endpoint using middleware/interceptor or Spring Security annotations.</li> <li>Frontend does permission-based rendering by inspecting JWT claims.</li> </ul> </li> <li>Role Hierarchy:<ul> <li>Support for parent/child role inheritance; granular, can stack permissions using config.</li> </ul> </li> </ul>"},{"location":"planning/tech-spec/backend-core-framework-and-auth/#5-security-testing","title":"5. Security &amp; Testing","text":"<ul> <li>Input Validation:<ul> <li>All user input sanitized using server-side middleware and frontend form validation.</li> </ul> </li> <li>Rate Limiting &amp; Abuse Protection:<ul> <li>Generic rate limiter for all endpoints, with stricter thresholds on auth-sensitive routes.</li> </ul> </li> <li>Error Handling:<ul> <li>All error messages log detailed traces server-side but always return generic, non-sensitive info to users.</li> </ul> </li> <li>Automated Tests:<ul> <li>Unit: JUnit, Jest (backend, frontend)</li> <li>Integration: RESTful API flows, DB migrations</li> <li>Security: Penetration tests on all endpoints, automated by tools such as OWASP ZAP or Snyk</li> <li>Code Quality: Pre-merge linting, code style checks, minimum 80% code coverage enforced via CI</li> </ul> </li> </ul>"},{"location":"planning/tech-spec/backend-core-framework-and-auth/#6-environments-deployment","title":"6. Environments &amp; Deployment","text":"<ul> <li>Development: <ul> <li>Local/dev setup with sample secrets, hot-reload, frequent deploys.</li> </ul> </li> <li>Staging: <ul> <li>Mimics production, using managed secrets, full external email, prod-like DB and access rules.</li> </ul> </li> <li>Database Migration: <ul> <li>Handled with consistent versioning scripts and CI-integrated checks to prevent drift.</li> </ul> </li> </ul>"},{"location":"planning/tech-spec/backend-core-framework-and-auth/#7-acceptance-criteria-mapping","title":"7. Acceptance Criteria Mapping","text":"Business Requirement Technical Implementation Repo deploys via Docker Compose Multi-container Docker Compose file CI/CD auto-runs tests GitHub Actions with integrated checks Secure Auth w/ JWT/Email/Login Spring Security config, JWT tokens setup Password reset, lockout Secure endpoints, expiring tokens RBAC enforced on all APIs/UIs Spring annotations, React guards Security headers, rate limits Global filters, NGINX/LB config All environments validated CI/CD deploys with test verification Test coverage &gt;=80% Test suites + pre-merge gates No sensitive error leakage Exception mapping &amp; logging discipline"},{"location":"planning/tech-spec/backend-core-framework-and-auth/#8-risks-mitigations","title":"8. Risks &amp; Mitigations","text":"<ul> <li>JWT Blacklist Unavailability:   Solution: Use short-lived access tokens; rotate refresh tokens and DB blacklist for critical operations.</li> <li>Role Drift:   Solution: All changes to roles/permissions are tracked and auditable.</li> <li>Misconfigurations in Environment Variables:   Solution: Template sample <code>.env</code>, lock down overrides, validate on CI deploys.</li> <li>Security Regression:   Solution: Run automated OWASP/Snyk scans on every CI/CD pipeline.</li> </ul>"},{"location":"planning/tech-spec/backend-core-framework-and-auth/#9-documentation","title":"9. Documentation","text":"<ul> <li>Auto-generate API documentation via Swagger/OpenAPI.</li> <li>README files for all setup (local, dev, staging).</li> <li>Architecture &amp; permission matrix docs stored in <code>/docs</code>.</li> </ul>"},{"location":"planning/tech-spec/backend-core-frameworks-and-auth-tasks/","title":"Technical Tasks for Core Framework &amp; Auth Epic","text":""},{"location":"planning/tech-spec/backend-core-frameworks-and-auth-tasks/#1-infrastructure-repository-setup","title":"1. Infrastructure &amp; Repository Setup","text":"<ul> <li>Create modular repository with <code>/backend</code>, <code>/frontend</code>, <code>/database</code>, <code>/docker</code> directories.</li> <li>Write Dockerfiles for backend, frontend, and database services.</li> <li>Implement a root Docker Compose file to orchestrate all services.</li> <li>Set up environment configuration management using <code>.env</code> files and CI/CD secret stores.</li> <li>Create initial README and repository documentation.</li> </ul>"},{"location":"planning/tech-spec/backend-core-frameworks-and-auth-tasks/#2-cicd-pipeline","title":"2. CI/CD Pipeline","text":"<ul> <li>Configure GitHub Actions workflow for:<ul> <li>Linting and static code checks (backend and frontend)</li> <li>Automated test execution (unit/integration/security)</li> <li>Code coverage reporting</li> <li>Build artifact publication and environment deployment (development &amp; staging)</li> <li>Security scans and linting as pre-merge gates</li> </ul> </li> </ul>"},{"location":"planning/tech-spec/backend-core-frameworks-and-auth-tasks/#3-backend-core-spring-boot-services","title":"3. Backend Core (Spring Boot Services)","text":"<ul> <li>Scaffold base Spring Boot microservice architecture.</li> <li>Integrate PostgreSQL and set up Flyway or Liquibase DB migration scripts.</li> <li>Implement core exception handling and logging framework.</li> <li>Create base entities and repositories (User, Role, Permission).</li> <li>Integrate environment variable/configuration management for secrets.</li> </ul>"},{"location":"planning/tech-spec/backend-core-frameworks-and-auth-tasks/#4-authentication-system","title":"4. Authentication System","text":"<ul> <li>Implement API endpoints for user registration, email verification, and login/logout.</li> <li>Integrate JWT-based access and refresh token generation/validation.</li> <li>Implement password hashing using bcrypt and password reset mechanism (email/token-based).</li> <li>Session management: enforce token expiry, implement secure refresh endpoint.</li> <li>Implement account lockout policy based on failed login attempts.</li> <li>Configure CORS and security headers at service entrypoint.</li> </ul>"},{"location":"planning/tech-spec/backend-core-frameworks-and-auth-tasks/#5-authorization-rbac","title":"5. Authorization &amp; RBAC","text":"<ul> <li>Design and create database schema for roles, permissions, and assignments.</li> <li>Implement role management API (add, modify, delete roles; assign permissions).</li> <li>Enforce RBAC via middleware/interceptors &amp; Spring Security annotations on endpoints.</li> <li>Ensure JWT claims correctly encode all roles/permissions of the user.</li> <li>Integrate role/permission refresh in real time for affected users.</li> <li>Develop initial role and permission matrix (admin, user, ops, etc.).</li> </ul>"},{"location":"planning/tech-spec/backend-core-frameworks-and-auth-tasks/#6-frontend-foundation","title":"6. Frontend Foundation","text":"<ul> <li>Scaffold React (TypeScript) app structure with routing and state management.</li> <li>Implement registration, login, logout, and password reset UI flows.</li> <li>Enable JWT storage and session management in the frontend (in-memory/token rotation).</li> <li>Implement RBAC-driven component rendering (hide/show UI elements by permission).</li> <li>Integrate form validation and error handling UX patterns.</li> </ul>"},{"location":"planning/tech-spec/backend-core-frameworks-and-auth-tasks/#7-security-hardening","title":"7. Security Hardening","text":"<ul> <li>Integrate security headers (CSP/Frame Options/HSTS, etc.) at NGINX or API gateway.</li> <li>Implement rate limiting logic for backend authentication endpoints (using Redis or similar).</li> <li>Validate and sanitize all input on backend APIs.</li> <li>Ensure generic error messages get returned for all API failures.</li> </ul>"},{"location":"planning/tech-spec/backend-core-frameworks-and-auth-tasks/#8-automated-testing","title":"8. Automated Testing","text":"<ul> <li>Write backend unit tests for all core modules (\u226580% coverage).</li> <li>Implement integration tests for end-to-end registration/authentication flows.</li> <li>Write frontend unit and integration tests for core UI/auth flows.</li> <li>Automate security scanning (OWASP ZAP, Snyk) in CI/CD pipeline.</li> <li>Penetration and abuse test coverage for all sensitive flows and endpoints.</li> </ul>"},{"location":"planning/tech-spec/backend-core-frameworks-and-auth-tasks/#9-deployment-environment-management","title":"9. Deployment &amp; Environment Management","text":"<ul> <li>Set up and validate local/dev environments for the team.</li> <li>Automate deployment and environment validation for staging.</li> <li>Create and manage secrets for dev/staging environments.</li> <li>Automate DB migrations in deploy pipeline.</li> </ul>"},{"location":"planning/tech-spec/backend-core-frameworks-and-auth-tasks/#10-documentation","title":"10. Documentation","text":"<ul> <li>Auto-generate API documentation (Swagger/OpenAPI) and publish to <code>/docs</code>.</li> <li>Document architecture, setup steps, and environment configurations.</li> <li>Maintain permission/role matrix in project documentation.</li> </ul>"},{"location":"product/Phase1_PRD/","title":"DealSphere Phase 1 (MVP) \u2014 Product Requirements Document","text":""},{"location":"product/Phase1_PRD/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Product Overview </li> <li>Target Users </li> <li>Core Use Cases </li> <li>Feature Requirements (Phase 1)      4.1. Platform &amp; Security     4.2. Document Management      4.3. Capital Calls      4.4. Waterfall Calculations (Multi-Class)      4.5. Workflow Automation (Per Class)      4.6. Basic Analytics      4.7. AI Integration (Initial)      4.8. Architecture Design      4.9. Fund Accounting      4.10. Portfolio Tracking </li> <li>Non-Functional Requirements </li> <li>Acceptance Criteria (Key) </li> <li>Success Metrics </li> <li>Risks &amp; Mitigation </li> <li>Timeline (Sprint Breakdown) </li> <li>QA Documentation </li> </ol> <p>Related Documents:</p>"},{"location":"product/Phase1_PRD/#1-product-overview","title":"1. Product Overview","text":"<ul> <li>Product Name: DealSphere</li> <li>Description: Secure, DLT-backed fund management platform for PE/VC with class-specific workflows and automated waterfalls, built on R3 Corda.</li> <li>Objective: Deliver an MVP that supports multi-class fund operations (permissions, capital calls, workflows, waterfalls), basic analytics, fund accounting, and portfolio tracking with AI-assisted experiences and a finalized architecture for scale.</li> </ul>"},{"location":"product/Phase1_PRD/#2-target-users","title":"2. Target Users","text":"<ul> <li>General Partners (GP), Limited Partners (LP) by class (A, B, etc.)</li> <li>Fund Managers and Administrators</li> <li>Auditors and Compliance users</li> <li>Investment/Portfolio Analysts</li> <li>Investors (read-only class-specific views)</li> <li>AI Assistant (virtual role for automated tasks)</li> </ul>"},{"location":"product/Phase1_PRD/#3-core-use-cases","title":"3. Core Use Cases","text":"<ul> <li>Role-based, class-segregated access and views</li> <li>Document management with on-ledger metadata, versioning, and audit logs</li> <li>Capital call lifecycle per class (rules, notices, tracking)</li> <li>Multi-class European and American waterfalls with prioritization and clawbacks</li> <li>Class-specific workflow automation (approvals, reminders, escalations)</li> <li>Basic analytics by class (committed vs. deployed, portfolio breakdown)</li> <li>Fund accounting and NAV/P&amp;L at class and combined levels</li> <li>Portfolio tracking with class-based contributions and returns</li> <li>AI-assisted class-specific queries and drafting</li> </ul>"},{"location":"product/Phase1_PRD/#4-feature-requirements-phase-1","title":"4. Feature Requirements (Phase 1)","text":""},{"location":"product/Phase1_PRD/#41-platform-security","title":"4.1 Platform &amp; Security","text":"<ul> <li>Role-based access control (RBAC) with strict class segregation</li> <li>R3 Corda DLT integration for immutable audit trails</li> <li>Multi-tenant architecture supporting multiple funds</li> <li>Encryption at rest and in transit</li> <li>Compliance framework (GDPR, SOX, regional requirements)</li> </ul>"},{"location":"product/Phase1_PRD/#42-document-management","title":"4.2 Document Management","text":"<ul> <li>Upload, version, and categorize documents per class</li> <li>On-ledger metadata storage with hash verification</li> <li>Access controls ensuring LP class segregation</li> <li>Document templates and automated generation</li> <li>Full audit logs for document lifecycle events</li> </ul>"},{"location":"product/Phase1_PRD/#43-capital-calls","title":"4.3 Capital Calls","text":"<ul> <li>Class-specific capital call rules and thresholds</li> <li>Automated notice generation and distribution per class</li> <li>Payment tracking and reconciliation by class</li> <li>Default management and escalation workflows</li> <li>Integration with banking APIs for payment verification</li> </ul>"},{"location":"product/Phase1_PRD/#44-waterfall-calculations-multi-class","title":"4.4 Waterfall Calculations (Multi-Class)","text":"<ul> <li>European and American waterfall models</li> <li>Class-based priority and allocation rules</li> <li>Clawback provisions and carry calculations</li> <li>Real-time distribution modeling and simulation</li> <li>Support for preferred returns and catch-up provisions</li> </ul>"},{"location":"product/Phase1_PRD/#45-workflow-automation-per-class","title":"4.5 Workflow Automation (Per Class)","text":"<ul> <li>Class-specific approval workflows</li> <li>Automated reminders and escalations</li> <li>Task assignment and tracking per class</li> <li>SLA monitoring and reporting</li> <li>Integration with email and notification systems</li> </ul>"},{"location":"product/Phase1_PRD/#46-basic-analytics","title":"4.6 Basic Analytics","text":"<ul> <li>Class-based committed vs. deployed capital tracking</li> <li>Portfolio performance breakdown by class</li> <li>Cash flow projections per class</li> <li>Basic reporting and export functionality</li> <li>Real-time dashboard views segregated by class</li> </ul>"},{"location":"product/Phase1_PRD/#47-ai-integration-initial","title":"4.7 AI Integration (Initial)","text":"<ul> <li>AI-assisted document drafting with class-specific parameters</li> <li>Intelligent data extraction from uploaded documents</li> <li>Class-aware query processing and responses</li> <li>Automated categorization and tagging</li> <li>Compliance checking and risk flagging</li> </ul>"},{"location":"product/Phase1_PRD/#48-architecture-design","title":"4.8 Architecture Design","text":"<ul> <li>Microservices architecture with API-first approach</li> <li>Cloud-native deployment (AWS/Azure/GCP)</li> <li>Scalable data architecture supporting multi-class operations</li> <li>API gateway for integrations and external services</li> <li>Security model for strict class-based segregation and audit</li> </ul>"},{"location":"product/Phase1_PRD/#49-fund-accounting","title":"4.9 Fund Accounting","text":"<ul> <li>Multi-class general ledger</li> <li>NAV and P&amp;L per class and combined</li> </ul>"},{"location":"product/Phase1_PRD/#410-portfolio-tracking","title":"4.10 Portfolio Tracking","text":"<ul> <li>Company profiles with investment history split by class</li> <li>Performance metrics per class and consolidated views</li> </ul>"},{"location":"product/Phase1_PRD/#5-non-functional-requirements","title":"5. Non-Functional Requirements","text":"<ul> <li>Mobile-responsive web app</li> <li>High security: DLT auditability, encryption, RBAC with class segregation</li> <li>GDPR-ready and regional compliance placeholders</li> <li>Cloud deployment (AWS/Azure/GCP)</li> <li>API-first for integrations and modular scale</li> </ul>"},{"location":"product/Phase1_PRD/#6-acceptance-criteria-key","title":"6. Acceptance Criteria (Key)","text":"<ul> <li>Permissions: LPs see only their class; adjustable without contract redeploy</li> <li>Documents: Versioning works; access logs accurate; hash verification consistent</li> <li>Capital Calls: Issued per class rules; LP payment statuses update correctly</li> <li>Waterfalls: Distributions per class match test vectors; switching preserves class logic</li> <li>Workflows: Class A and B flows run concurrently without conflict; reminders as configured</li> <li>Analytics: Reports filterable by class; exports work</li> <li>AI: Filters/outputs adhere to class constraints; drafts match class parameters</li> <li>Accounting: NAV computed separately by class and combined</li> <li>Portfolio: Class-specific contributions and returns displayed</li> </ul>"},{"location":"product/Phase1_PRD/#7-success-metrics","title":"7. Success Metrics","text":"<ul> <li>Funds onboarded leveraging multi-class features</li> <li>Volume of class-specific capital calls and distributions</li> <li>Workflow automation throughput and SLA adherence</li> <li>Accuracy of waterfall outputs vs. expected vectors</li> <li>Frequency of AI-assisted actions</li> <li>Analytics/export usage by class</li> </ul>"},{"location":"product/Phase1_PRD/#8-risks-mitigation","title":"8. Risks &amp; Mitigation","text":"<ul> <li>Multi-class complexity: Test vectors and simulation harnesses</li> <li>Security/segregation: Pen testing, rigorous data access validation, on-ledger audit</li> <li>Scope creep: Phased deliveries with strict change control</li> <li>Compliance variance: Region placeholders and pilot validation</li> </ul>"},{"location":"product/Phase1_PRD/#9-timeline-sprint-breakdown","title":"9. Timeline (Sprint Breakdown)","text":""},{"location":"product/Phase1_PRD/#10-qa-documentation","title":"10. QA Documentation","text":"<p>Summary: Phase 1 delivers a secure, multi-class MVP across permissions, documents, capital calls, waterfalls, workflows, analytics, fund accounting, and portfolio tracking, with AI assist and an architecture ready for scale.</p>"},{"location":"qa/","title":"DealSphere QA &amp; Compliance Documentation","text":""},{"location":"qa/#overview","title":"Overview","text":"<p>This section contains all quality assurance and compliance documentation for the DealSphere platform, focusing on comprehensive testing strategies and business requirement validation.</p>"},{"location":"qa/#documentation-structure","title":"Documentation Structure","text":""},{"location":"qa/#functional-test-cases","title":"\ud83d\udccb Functional Test Cases","text":"<p>Official Phase 1 functional test cases covering all business scenarios including: - Platform &amp; Security (RBAC, encryption, Corda integration) - Document Management (storage, versioning, AI features) - Capital Calls (class-specific rules, payment tracking) - Waterfall Calculations (European/American models, distributions) - Workflow Automation (approval workflows, SLA enforcement) - Analytics &amp; Reporting (class-level analytics, exports) - AI Integration (class-filtered queries, document processing)</p>"},{"location":"qa/#prd-to-test-case-mapping","title":"\ud83d\uddfa\ufe0f PRD to Test Case Mapping","text":"<p>Traceability matrix connecting Product Requirements Document (PRD) items to specific test cases, ensuring complete coverage of business requirements.</p>"},{"location":"qa/#phase-1-functional-test-suite-technical-specification","title":"\ud83d\udd27 Phase 1 Functional Test Suite - Technical Specification","text":"<p>Comprehensive technical specification for implementing the complete functional test suite including: - Test-First Development Approach - All tests written upfront to guide development - Epic-to-Test Traceability - Direct mapping to Phase 1 Epics - 47 Test Scenarios - Complete coverage across 4 development epics - Implementation Standards - Templates, patterns, and best practices - Automated Reporting - Coverage tracking and requirement validation</p>"},{"location":"qa/#test-strategy-overview","title":"Test Strategy Overview","text":""},{"location":"qa/#test-driven-development-philosophy","title":"\ud83c\udfaf Test-Driven Development Philosophy","text":"<p>The DealSphere QA approach follows a functional test-first methodology:</p> <ol> <li>All functional tests written upfront before development begins</li> <li>Tests serve as executable specifications for the development team</li> <li>Epic traceability ensures every business requirement has test coverage</li> <li>Failing tests guide implementation - developers work to make tests pass</li> </ol>"},{"location":"qa/#coverage-metrics","title":"\ud83d\udcca Coverage Metrics","text":"Epic Development Weeks Test Count Business Focus Epic 1: Core Framework &amp; Auth 1-2 10 tests Authentication, RBAC, Security Epic 2: User Management &amp; Documents 3-4 12 tests User CRUD, Document Management, AI Epic 3: Capital Call &amp; Waterfall 5-6 20 tests Financial Operations, Calculations Epic 4: Workflow Automation &amp; AI 7-8 5 tests Process Automation, Integrations Total 8 weeks 47 tests 100% Phase 1 Coverage"},{"location":"qa/#for-development-teams","title":"For Development Teams","text":""},{"location":"qa/#using-tests-for-development","title":"\ud83d\udee0\ufe0f Using Tests for Development","text":"<p>The functional test suite is designed to guide development:</p> <ol> <li>Review Functional Test-Driven Development Guide</li> <li>Run epic-specific tests based on current development timeline</li> <li>Read test requirements embedded in test logs and comments</li> <li>Implement to make tests pass - tests define the correct behavior</li> <li>Use failing tests as specifications - they tell you exactly what to build</li> </ol>"},{"location":"qa/#test-implementation-structure","title":"\ud83d\udcc2 Test Implementation Structure","text":"<pre><code>cypress/e2e/\n\u251c\u2500\u2500 epic-1-core-auth/         # Weeks 1-2: Authentication &amp; RBAC\n\u251c\u2500\u2500 epic-2-users-documents/   # Weeks 3-4: User Management &amp; Documents\n\u251c\u2500\u2500 epic-3-capital-waterfall/ # Weeks 5-6: Capital Calls &amp; Waterfalls\n\u2514\u2500\u2500 epic-4-workflows-ai/      # Weeks 7-8: Workflows &amp; AI Integration\n</code></pre>"},{"location":"qa/#for-qa-teams","title":"For QA Teams","text":""},{"location":"qa/#test-implementation-process","title":"\ud83e\uddea Test Implementation Process","text":"<ol> <li>Follow Technical Specification for detailed implementation guidance</li> <li>Use epic traceability templates for consistent test structure</li> <li>Implement all 47 test scenarios with proper business requirement mapping</li> <li>Generate coverage reports to track implementation progress</li> <li>Validate requirement traceability against official documentation</li> </ol>"},{"location":"qa/#quality-metrics","title":"\ud83d\udcc8 Quality Metrics","text":"<ul> <li>Epic Coverage: 100% of Phase 1 epics covered</li> <li>Requirement Traceability: Every test maps to official business requirements</li> <li>Test Quality: Each test includes business context and acceptance criteria</li> <li>Documentation Integration: Official DealSphere requirements embedded in test logs</li> </ul>"},{"location":"qa/#for-product-teams","title":"For Product Teams","text":""},{"location":"qa/#business-requirement-validation","title":"\ud83d\udccb Business Requirement Validation","text":"<p>The QA documentation ensures complete validation of business requirements:</p> <ul> <li>Functional Test Cases - Detailed scenarios for each business requirement</li> <li>PRD Mapping - Traceability from product requirements to test validation</li> <li>Epic Integration - Tests directly validate Phase 1 Epic deliverables</li> </ul>"},{"location":"qa/#acceptance-criteria","title":"\u2705 Acceptance Criteria","text":"<p>Each test includes clear acceptance criteria that define when business requirements are successfully implemented:</p> <pre><code>it('should satisfy business requirement X.X.X', () =&gt; {\n  cy.log('\ud83e\uddea TESTING: Specific business scenario')\n  cy.log('\u2705 ACCEPTANCE CRITERIA: Clear success definition')\n  // Test implementation validates business outcome\n})\n</code></pre>"},{"location":"qa/#getting-started","title":"Getting Started","text":""},{"location":"qa/#for-developers","title":"For Developers","text":"<ol> <li>Read Functional Test-Driven Development Guide</li> <li>Run tests for your current development epic</li> <li>Use failing tests to guide implementation</li> </ol>"},{"location":"qa/#for-qa-engineers","title":"For QA Engineers","text":"<ol> <li>Review Technical Specification</li> <li>Implement test infrastructure and framework</li> <li>Create all 47 functional test scenarios</li> </ol>"},{"location":"qa/#for-product-owners","title":"For Product Owners","text":"<ol> <li>Review Functional Test Cases for requirement coverage</li> <li>Validate PRD Mapping for completeness</li> <li>Use test reports to track feature delivery progress</li> </ol>"},{"location":"qa/#related-documentation","title":"Related Documentation","text":"<ul> <li>Phase 1 Epics - Development epics and timelines</li> <li>Testing Strategy - Overall testing approach</li> <li>Cypress E2E Testing - Technical testing setup</li> </ul> <p>The DealSphere QA approach ensures every business requirement is thoroughly validated through comprehensive functional testing with complete epic traceability. \ud83c\udfaf</p>"},{"location":"qa/Phase1_Functional_Test_Cases/","title":"Phase 1 Functional Test Cases","text":""},{"location":"qa/Phase1_Functional_Test_Cases/#overview","title":"Overview","text":"<p>This document outlines the functional test cases for DealSphere Phase 1 (MVP) based on the requirements defined in Phase1_PRD.md. These test cases cover all core functional areas with class-specific multi-tenant functionality.</p> <p>Related Documents: - Phase1_PRD.md</p>"},{"location":"qa/Phase1_Functional_Test_Cases/#1-platform-security","title":"1. Platform &amp; Security","text":""},{"location":"qa/Phase1_Functional_Test_Cases/#11-role-based-access-control-rbac","title":"1.1 Role-Based Access Control (RBAC)","text":"<ul> <li>Test Case 1.1.1: Verify Admin users can access all fund classes and system configurations</li> <li>Test Case 1.1.2: Verify GP users can access all fund operations within their assigned funds</li> <li>Test Case 1.1.3: Verify LP Class A users can only access Class A-specific data and documents</li> <li>Test Case 1.1.4: Verify LP Class B users can only access Class B-specific data and documents</li> <li>Test Case 1.1.5: Verify Auditor users can access read-only views across all classes for audit purposes</li> <li>Test Case 1.1.6: Verify AI Assistant can access data according to class-specific permissions for automated tasks</li> <li>Test Case 1.1.7: Verify permission changes are enforced without contract redeployment</li> </ul>"},{"location":"qa/Phase1_Functional_Test_Cases/#12-security-encryption","title":"1.2 Security &amp; Encryption","text":"<ul> <li>Test Case 1.2.1: Verify all data is encrypted at rest using approved encryption standards</li> <li>Test Case 1.2.2: Verify all data transmission is encrypted in transit</li> <li>Test Case 1.2.3: Verify content hash verification works for document integrity</li> <li>Test Case 1.2.4: Verify secure node topology prevents unauthorized access</li> <li>Test Case 1.2.5: Verify API gateway enforces authentication and authorization</li> </ul>"},{"location":"qa/Phase1_Functional_Test_Cases/#13-r3-corda-integration","title":"1.3 R3 Corda Integration","text":"<ul> <li>Test Case 1.3.1: Verify on-ledger access control metadata is properly maintained</li> <li>Test Case 1.3.2: Verify Corda node handles multi-class transactions correctly</li> <li>Test Case 1.3.3: Verify ledger integrity and audit trail functionality</li> </ul>"},{"location":"qa/Phase1_Functional_Test_Cases/#2-document-management","title":"2. Document Management","text":""},{"location":"qa/Phase1_Functional_Test_Cases/#21-document-storage-metadata","title":"2.1 Document Storage &amp; Metadata","text":"<ul> <li>Test Case 2.1.1: Verify documents are stored with encrypted off-ledger storage</li> <li>Test Case 2.1.2: Verify on-ledger metadata is correctly maintained for all documents</li> <li>Test Case 2.1.3: Verify content hash verification detects document tampering</li> <li>Test Case 2.1.4: Verify class-specific document access restrictions</li> </ul>"},{"location":"qa/Phase1_Functional_Test_Cases/#22-version-control-audit-logging","title":"2.2 Version Control &amp; Audit Logging","text":"<ul> <li>Test Case 2.2.1: Verify document version control tracks all changes with timestamps</li> <li>Test Case 2.2.2: Verify audit logging captures all document access events</li> <li>Test Case 2.2.3: Verify access logs show user identity, timestamp, and action performed</li> <li>Test Case 2.2.4: Verify version history is maintained across document updates</li> </ul>"},{"location":"qa/Phase1_Functional_Test_Cases/#23-ai-enhanced-document-features","title":"2.3 AI-Enhanced Document Features","text":"<ul> <li>Test Case 2.3.1: Verify smart search returns relevant documents based on class permissions</li> <li>Test Case 2.3.2: Verify OCR-based document classification works accurately</li> <li>Test Case 2.3.3: Verify AI classification respects class-based document segregation</li> </ul>"},{"location":"qa/Phase1_Functional_Test_Cases/#3-capital-calls","title":"3. Capital Calls","text":""},{"location":"qa/Phase1_Functional_Test_Cases/#31-class-specific-capital-call-rules","title":"3.1 Class-Specific Capital Call Rules","text":"<ul> <li>Test Case 3.1.1: Verify capital call rules can be configured separately for each class</li> <li>Test Case 3.1.2: Verify capital call percentages are applied correctly per class</li> <li>Test Case 3.1.3: Verify capital call schedules work independently for different classes</li> <li>Test Case 3.1.4: Verify smart contract templates generate class-appropriate notices</li> </ul>"},{"location":"qa/Phase1_Functional_Test_Cases/#32-payment-tracking-status-updates","title":"3.2 Payment Tracking &amp; Status Updates","text":"<ul> <li>Test Case 3.2.1: Verify automated payment tracking works per LP and per class</li> <li>Test Case 3.2.2: Verify LP payment status updates are accurate and timely</li> <li>Test Case 3.2.3: Verify payment status is only visible to authorized class members</li> <li>Test Case 3.2.4: Verify automated reminders are sent according to class-specific schedules</li> </ul>"},{"location":"qa/Phase1_Functional_Test_Cases/#33-capital-call-lifecycle","title":"3.3 Capital Call Lifecycle","text":"<ul> <li>Test Case 3.3.1: Verify capital call notices are generated with correct class parameters</li> <li>Test Case 3.3.2: Verify enforcement mechanisms work per class rules</li> <li>Test Case 3.3.3: Verify escalation procedures follow class-specific SLAs</li> </ul>"},{"location":"qa/Phase1_Functional_Test_Cases/#4-waterfall-calculations","title":"4. Waterfall Calculations","text":""},{"location":"qa/Phase1_Functional_Test_Cases/#41-multi-class-european-waterfall","title":"4.1 Multi-Class European Waterfall","text":"<ul> <li>Test Case 4.1.1: Verify European waterfall calculates whole-of-fund distributions correctly</li> <li>Test Case 4.1.2: Verify class-specific preferred returns are applied accurately</li> <li>Test Case 4.1.3: Verify catch-up calculations work correctly for each class</li> <li>Test Case 4.1.4: Verify carry calculations are applied per class parameters</li> <li>Test Case 4.1.5: Verify inter-class priority is respected in distribution calculations</li> </ul>"},{"location":"qa/Phase1_Functional_Test_Cases/#42-multi-class-american-waterfall","title":"4.2 Multi-Class American Waterfall","text":"<ul> <li>Test Case 4.2.1: Verify American waterfall processes deal-by-deal distributions correctly</li> <li>Test Case 4.2.2: Verify class-specific clawback logic is applied appropriately</li> <li>Test Case 4.2.3: Verify deal-level distributions respect class-specific parameters</li> <li>Test Case 4.2.4: Verify clawback calculations are accurate per class rules</li> </ul>"},{"location":"qa/Phase1_Functional_Test_Cases/#43-waterfall-configuration-switching","title":"4.3 Waterfall Configuration &amp; Switching","text":"<ul> <li>Test Case 4.3.1: Verify waterfall model switching preserves class-specific logic</li> <li>Test Case 4.3.2: Verify configurable inter-class priority settings work correctly</li> <li>Test Case 4.3.3: Verify deterministic outputs match expected results for each class</li> <li>Test Case 4.3.4: Verify waterfall calculations can be validated against test vectors</li> </ul>"},{"location":"qa/Phase1_Functional_Test_Cases/#5-workflow-automation","title":"5. Workflow Automation","text":""},{"location":"qa/Phase1_Functional_Test_Cases/#51-class-specific-approval-workflows","title":"5.1 Class-Specific Approval Workflows","text":"<ul> <li>Test Case 5.1.1: Verify approval workflows for capital calls work per class</li> <li>Test Case 5.1.2: Verify distribution approval workflows respect class boundaries</li> <li>Test Case 5.1.3: Verify document approval workflows are class-segregated</li> <li>Test Case 5.1.4: Verify Class A and Class B workflows run concurrently without conflict</li> </ul>"},{"location":"qa/Phase1_Functional_Test_Cases/#52-slas-reminders-escalations","title":"5.2 SLAs, Reminders &amp; Escalations","text":"<ul> <li>Test Case 5.2.1: Verify class-specific SLAs are enforced correctly</li> <li>Test Case 5.2.2: Verify reminder schedules work according to class configuration</li> <li>Test Case 5.2.3: Verify escalation procedures follow class-specific rules</li> <li>Test Case 5.2.4: Verify reminders are sent as configured for each class</li> </ul>"},{"location":"qa/Phase1_Functional_Test_Cases/#53-ai-assisted-workflow-routing","title":"5.3 AI-Assisted Workflow Routing","text":"<ul> <li>Test Case 5.3.1: Verify AI-assisted routing reduces approval latency</li> <li>Test Case 5.3.2: Verify AI routing respects class-based permissions</li> <li>Test Case 5.3.3: Verify intelligent workflow optimization works across classes</li> </ul>"},{"location":"qa/Phase1_Functional_Test_Cases/#6-basic-analytics","title":"6. Basic Analytics","text":""},{"location":"qa/Phase1_Functional_Test_Cases/#61-class-level-capital-analytics","title":"6.1 Class-Level Capital Analytics","text":"<ul> <li>Test Case 6.1.1: Verify committed vs. deployed capital is tracked separately by class</li> <li>Test Case 6.1.2: Verify capital utilization reports are class-specific</li> <li>Test Case 6.1.3: Verify analytics data is only accessible to authorized class members</li> </ul>"},{"location":"qa/Phase1_Functional_Test_Cases/#62-portfolio-analytics","title":"6.2 Portfolio Analytics","text":"<ul> <li>Test Case 6.2.1: Verify portfolio breakdown shows class-specific contributions</li> <li>Test Case 6.2.2: Verify class-specific return calculations are accurate</li> <li>Test Case 6.2.3: Verify consolidated portfolio views work for authorized users</li> </ul>"},{"location":"qa/Phase1_Functional_Test_Cases/#63-reporting-export","title":"6.3 Reporting &amp; Export","text":"<ul> <li>Test Case 6.3.1: Verify reports are filterable by class</li> <li>Test Case 6.3.2: Verify PDF export functionality works for class-specific reports</li> <li>Test Case 6.3.3: Verify Excel export functionality works for class-specific data</li> <li>Test Case 6.3.4: Verify exported data maintains class-based security restrictions</li> </ul>"},{"location":"qa/Phase1_Functional_Test_Cases/#7-ai-integration","title":"7. AI Integration","text":""},{"location":"qa/Phase1_Functional_Test_Cases/#71-class-filtered-queries","title":"7.1 Class-Filtered Queries","text":"<ul> <li>Test Case 7.1.1: Verify AI queries respect class-based data access restrictions</li> <li>Test Case 7.1.2: Verify class-specific queries return accurate filtered results (e.g., \"Show returns for Class B LPs\")</li> <li>Test Case 7.1.3: Verify AI responses maintain class data segregation</li> </ul>"},{"location":"qa/Phase1_Functional_Test_Cases/#72-ai-assisted-drafting","title":"7.2 AI-Assisted Drafting","text":"<ul> <li>Test Case 7.2.1: Verify AI-assisted capital call drafting uses correct class parameters</li> <li>Test Case 7.2.2: Verify AI-generated documents respect class-specific requirements</li> <li>Test Case 7.2.3: Verify AI drafts match class-specific formatting and content rules</li> </ul>"},{"location":"qa/Phase1_Functional_Test_Cases/#73-ai-document-processing","title":"7.3 AI Document Processing","text":"<ul> <li>Test Case 7.3.1: Verify OCR + classification works with class awareness</li> <li>Test Case 7.3.2: Verify AI document processing respects class-based access controls</li> <li>Test Case 7.3.3: Verify automated classification assigns appropriate class tags</li> </ul>"},{"location":"qa/Phase1_Functional_Test_Cases/#8-architecture-design","title":"8. Architecture Design","text":""},{"location":"qa/Phase1_Functional_Test_Cases/#81-scalability-performance","title":"8.1 Scalability &amp; Performance","text":"<ul> <li>Test Case 8.1.1: Verify Corda node topology supports expected transaction volume</li> <li>Test Case 8.1.2: Verify API gateway handles concurrent multi-class requests</li> <li>Test Case 8.1.3: Verify system performance under multi-class load scenarios</li> </ul>"},{"location":"qa/Phase1_Functional_Test_Cases/#82-integration-security-model","title":"8.2 Integration &amp; Security Model","text":"<ul> <li>Test Case 8.2.1: Verify API gateway integrations work with external services</li> <li>Test Case 8.2.2: Verify strict class-based segregation is maintained across all components</li> <li>Test Case 8.2.3: Verify audit capabilities work across the distributed architecture</li> </ul>"},{"location":"qa/Phase1_Functional_Test_Cases/#9-fund-accounting","title":"9. Fund Accounting","text":""},{"location":"qa/Phase1_Functional_Test_Cases/#91-multi-class-general-ledger","title":"9.1 Multi-Class General Ledger","text":"<ul> <li>Test Case 9.1.1: Verify general ledger maintains separate accounting for each class</li> <li>Test Case 9.1.2: Verify cross-class transactions are properly recorded</li> <li>Test Case 9.1.3: Verify accounting entries are auditable and traceable by class</li> </ul>"},{"location":"qa/Phase1_Functional_Test_Cases/#92-nav-and-pl-calculations","title":"9.2 NAV and P&amp;L Calculations","text":"<ul> <li>Test Case 9.2.1: Verify NAV is calculated separately for each class</li> <li>Test Case 9.2.2: Verify combined NAV calculations are accurate</li> <li>Test Case 9.2.3: Verify P&amp;L calculations work correctly per class</li> <li>Test Case 9.2.4: Verify consolidated P&amp;L reports are accurate</li> </ul>"},{"location":"qa/Phase1_Functional_Test_Cases/#10-portfolio-tracking","title":"10. Portfolio Tracking","text":""},{"location":"qa/Phase1_Functional_Test_Cases/#101-class-based-investment-tracking","title":"10.1 Class-Based Investment Tracking","text":"<ul> <li>Test Case 10.1.1: Verify company profiles show investment history split by class</li> <li>Test Case 10.1.2: Verify class-specific contributions are tracked accurately</li> <li>Test Case 10.1.3: Verify class-based returns are calculated correctly</li> </ul>"},{"location":"qa/Phase1_Functional_Test_Cases/#102-performance-metrics","title":"10.2 Performance Metrics","text":"<ul> <li>Test Case 10.2.1: Verify performance metrics are calculated separately per class</li> <li>Test Case 10.2.2: Verify consolidated portfolio views work for authorized users</li> <li>Test Case 10.2.3: Verify class-specific performance reports are accurate</li> <li>Test Case 10.2.4: Verify portfolio tracking data respects class-based access controls</li> </ul>"},{"location":"qa/Phase1_Functional_Test_Cases/#test-execution-notes","title":"Test Execution Notes","text":""},{"location":"qa/Phase1_Functional_Test_Cases/#prerequisites","title":"Prerequisites","text":"<ul> <li>Multi-class test fund setup with Class A and Class B LPs</li> <li>Test users configured for each role (Admin, GP, LP Class A, LP Class B, Auditor, AI Assistant)</li> <li>Sample documents and transactions for each class</li> <li>Test vectors for waterfall calculations</li> </ul>"},{"location":"qa/Phase1_Functional_Test_Cases/#success-criteria","title":"Success Criteria","text":"<ul> <li>All functional areas maintain strict class-based segregation</li> <li>No cross-class data leakage in any scenario</li> <li>All automated processes respect class-specific configurations</li> <li>Performance meets specified requirements under multi-class load</li> <li>All audit trails and logging function correctly</li> </ul>"},{"location":"qa/Phase1_Functional_Test_Cases/#test-data-requirements","title":"Test Data Requirements","text":"<ul> <li>Multi-class fund structures</li> <li>Class-specific user permissions</li> <li>Sample capital calls for each class</li> <li>Test waterfall scenarios with expected outputs</li> <li>Sample documents with class-specific access requirements</li> </ul> <p>Last Updated: August 23, 2025 Version: 1.0 Related: Phase1_PRD.md</p>"},{"location":"qa/Phase1_PRD_to_TestCase_Mapping/","title":"DealSphere Phase 1: PRD to Functional Test Case Mapping","text":"<p>This artifact ensures traceability from every Product Requirement in the Phase 1 PRD to a corresponding Functional Test Case. For each PRD section, find links to mapped test cases\u2014and vice versa.</p>"},{"location":"qa/Phase1_PRD_to_TestCase_Mapping/#mapping-table","title":"Mapping Table","text":"PRD Feature/Requirement (Section) Mapped Functional Test Case(s) Platform &amp; Security Platform &amp; Security Document Management Document Management Capital Calls Capital Calls Waterfall Calculations Waterfall Calculations (Multi-Class) Workflow Automation Workflow Automation (Per Class) Basic Analytics Basic Analytics AI Integration AI Integration (Initial) Architecture Design Architecture Design Fund Accounting Fund Accounting Portfolio Tracking Portfolio Tracking"},{"location":"qa/Phase1_PRD_to_TestCase_Mapping/#detailed-bidirectional-mapping","title":"Detailed Bidirectional Mapping","text":""},{"location":"qa/Phase1_PRD_to_TestCase_Mapping/#platform-security","title":"Platform &amp; Security","text":"<p>Covers: R3 Corda access, encryption, API enforcement, dynamic access rights \u2192 Platform &amp; Security Tests</p>"},{"location":"qa/Phase1_PRD_to_TestCase_Mapping/#document-management","title":"Document Management","text":"<p>Covers: Metadata, off-ledger storage, versioning, hash checking, searchable OCR \u2192 Document Management Tests</p>"},{"location":"qa/Phase1_PRD_to_TestCase_Mapping/#capital-calls","title":"Capital Calls","text":"<p>Covers: Notice generation, LP/class-specific logic, payment tracking, reminders/escalations \u2192 Capital Calls Tests</p>"},{"location":"qa/Phase1_PRD_to_TestCase_Mapping/#waterfall-calculations-multi-class","title":"Waterfall Calculations (Multi-Class)","text":"<p>Covers: European/American models, class priorities, deterministic tests \u2192 Waterfall Calculations Tests</p>"},{"location":"qa/Phase1_PRD_to_TestCase_Mapping/#workflow-automation-per-class","title":"Workflow Automation (Per Class)","text":"<p>Covers: Approvals, escalations, SLAs, AI latency reduction \u2192 Workflow Automation Tests</p>"},{"location":"qa/Phase1_PRD_to_TestCase_Mapping/#basic-analytics","title":"Basic Analytics","text":"<p>Covers: Reports, export, capital/contribution breakdowns \u2192 Basic Analytics Tests</p>"},{"location":"qa/Phase1_PRD_to_TestCase_Mapping/#ai-integration-initial","title":"AI Integration (Initial)","text":"<p>Covers: Querying, document classification, capital call assistance \u2192 AI Integration Tests</p>"},{"location":"qa/Phase1_PRD_to_TestCase_Mapping/#architecture-design","title":"Architecture Design","text":"<p>Covers: Node deployment, API security, class segregation \u2192 Architecture Tests</p>"},{"location":"qa/Phase1_PRD_to_TestCase_Mapping/#fund-accounting","title":"Fund Accounting","text":"<p>Covers: Ledger, NAV/P&amp;L per class \u2192 Fund Accounting Tests</p>"},{"location":"qa/Phase1_PRD_to_TestCase_Mapping/#portfolio-tracking","title":"Portfolio Tracking","text":"<p>Covers: Company profiles, investment returns by class, performance \u2192 Portfolio Tracking Tests</p>"},{"location":"qa/phase1-functional-test-suite-tech-spec/","title":"DealSphere Phase 1 Functional Test Suite - Technical Specification","text":""},{"location":"qa/phase1-functional-test-suite-tech-spec/#document-information","title":"Document Information","text":"Field Value Title DealSphere Platform Phase 1 Functional Test Suite Technical Specification Version 1.0 Author DealSphere QA Team Date 2025-09-18 Status Draft Purpose Define comprehensive functional testing strategy with epic-to-test traceability"},{"location":"qa/phase1-functional-test-suite-tech-spec/#1-executive-summary","title":"1. Executive Summary","text":""},{"location":"qa/phase1-functional-test-suite-tech-spec/#11-objectives","title":"1.1 Objectives","text":"<p>This specification defines a comprehensive functional test suite for DealSphere Phase 1 development, implementing a test-first approach where all functional tests are written upfront to guide development.</p> <p>Primary Goals: - Create complete functional test suite before development begins - Establish direct epic-to-test traceability using official DealSphere documentation - Provide executable specifications for the development team - Ensure 100% coverage of Phase 1 business requirements - Enable development teams to use failing tests as implementation guides</p>"},{"location":"qa/phase1-functional-test-suite-tech-spec/#12-test-strategy","title":"1.2 Test Strategy","text":"<p>Test-First Development Approach: - \u2705 Write all functional tests upfront as development guides - \u2705 Epic mapping with direct traceability to official Phase 1 epics - \u2705 Business value focus validating real user scenarios and outcomes - \u2705 Documentation integration with official requirement text embedded in test logging - \u2705 Tests initially fail and serve as executable specifications</p>"},{"location":"qa/phase1-functional-test-suite-tech-spec/#2-architecture-framework","title":"2. Architecture &amp; Framework","text":""},{"location":"qa/phase1-functional-test-suite-tech-spec/#21-testing-stack","title":"2.1 Testing Stack","text":"Component Technology Purpose Framework Cypress (TypeScript) E2E functional testing Test Organization Epic-based structure Match official documentation Page Objects TypeScript classes Reusable UI interaction patterns Fixtures JSON/TypeScript Comprehensive test data management Reporting Custom Cypress plugins Epic traceability and coverage reports"},{"location":"qa/phase1-functional-test-suite-tech-spec/#22-test-structure","title":"2.2 Test Structure","text":"<pre><code>cypress/\n\u251c\u2500\u2500 e2e/\n\u2502   \u251c\u2500\u2500 epic-1-core-auth/         # Core Framework &amp; Auth (Weeks 1-2)\n\u2502   \u2502   \u251c\u2500\u2500 1.1.1-basic-login-authentication.cy.ts\n\u2502   \u2502   \u251c\u2500\u2500 1.1.2-logout-functionality.cy.ts\n\u2502   \u2502   \u251c\u2500\u2500 1.1.3-role-based-access-control.cy.ts\n\u2502   \u2502   \u251c\u2500\u2500 1.1.5-session-management.cy.ts\n\u2502   \u2502   \u251c\u2500\u2500 1.1.6-permission-enforcement.cy.ts\n\u2502   \u2502   \u251c\u2500\u2500 1.1.7-multi-role-scenarios.cy.ts\n\u2502   \u2502   \u251c\u2500\u2500 1.2.1-invalid-credentials.cy.ts\n\u2502   \u2502   \u251c\u2500\u2500 1.2.2-unauthorized-access.cy.ts\n\u2502   \u2502   \u251c\u2500\u2500 1.2.3-session-timeout.cy.ts\n\u2502   \u2502   \u2514\u2500\u2500 1.2.5-security-audit-trails.cy.ts\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 epic-2-users-documents/   # User Management &amp; Documents (Weeks 3-4)\n\u2502   \u2502   \u251c\u2500\u2500 2.1.1-document-upload-class-isolation.cy.ts\n\u2502   \u2502   \u251c\u2500\u2500 2.1.2-document-download-permissions.cy.ts\n\u2502   \u2502   \u251c\u2500\u2500 2.1.3-document-metadata-management.cy.ts\n\u2502   \u2502   \u251c\u2500\u2500 2.1.4-document-access-restrictions.cy.ts\n\u2502   \u2502   \u251c\u2500\u2500 2.2.1-document-versioning-workflows.cy.ts\n\u2502   \u2502   \u251c\u2500\u2500 2.2.2-version-control-permissions.cy.ts\n\u2502   \u2502   \u251c\u2500\u2500 2.2.3-document-history-tracking.cy.ts\n\u2502   \u2502   \u251c\u2500\u2500 2.2.4-version-rollback-scenarios.cy.ts\n\u2502   \u2502   \u251c\u2500\u2500 2.3.1-ai-document-categorization.cy.ts\n\u2502   \u2502   \u251c\u2500\u2500 2.3.2-ai-classification-accuracy.cy.ts\n\u2502   \u2502   \u251c\u2500\u2500 2.3.3-ai-metadata-extraction.cy.ts\n\u2502   \u2502   \u2514\u2500\u2500 1.3.2-user-management-crud.cy.ts\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 epic-3-capital-waterfall/ # Capital Call &amp; Waterfall (Weeks 5-6)\n\u2502   \u2502   \u251c\u2500\u2500 3.1.1-capital-call-creation.cy.ts\n\u2502   \u2502   \u251c\u2500\u2500 3.1.2-call-class-isolation.cy.ts\n\u2502   \u2502   \u251c\u2500\u2500 3.1.3-call-workflow-management.cy.ts\n\u2502   \u2502   \u251c\u2500\u2500 3.1.4-call-status-tracking.cy.ts\n\u2502   \u2502   \u251c\u2500\u2500 3.2.1-member-notifications.cy.ts\n\u2502   \u2502   \u251c\u2500\u2500 3.2.2-payment-tracking.cy.ts\n\u2502   \u2502   \u251c\u2500\u2500 3.2.3-automated-reminders.cy.ts\n\u2502   \u2502   \u251c\u2500\u2500 3.3.1-invalid-call-scenarios.cy.ts\n\u2502   \u2502   \u251c\u2500\u2500 3.3.2-payment-failures.cy.ts\n\u2502   \u2502   \u251c\u2500\u2500 3.3.3-notification-errors.cy.ts\n\u2502   \u2502   \u251c\u2500\u2500 4.1.1-european-waterfall-model.cy.ts\n\u2502   \u2502   \u251c\u2500\u2500 4.1.2-american-waterfall-model.cy.ts\n\u2502   \u2502   \u251c\u2500\u2500 4.1.3-waterfall-model-switching.cy.ts\n\u2502   \u2502   \u251c\u2500\u2500 4.2.1-waterfall-calculations.cy.ts\n\u2502   \u2502   \u251c\u2500\u2500 4.2.2-inter-class-distributions.cy.ts\n\u2502   \u2502   \u251c\u2500\u2500 4.2.3-preferred-return-calculations.cy.ts\n\u2502   \u2502   \u251c\u2500\u2500 4.2.4-calculation-error-handling.cy.ts\n\u2502   \u2502   \u251c\u2500\u2500 4.3.1-allocation-algorithms.cy.ts\n\u2502   \u2502   \u251c\u2500\u2500 4.3.2-distribution-timing.cy.ts\n\u2502   \u2502   \u251c\u2500\u2500 4.3.3-carry-calculations.cy.ts\n\u2502   \u2502   \u2514\u2500\u2500 4.3.4-fee-distributions.cy.ts\n\u2502   \u2502\n\u2502   \u2514\u2500\u2500 epic-4-workflows-ai/      # Workflow Automation &amp; AI (Weeks 7-8)\n\u2502       \u251c\u2500\u2500 workflow-approval-systems.cy.ts\n\u2502       \u251c\u2500\u2500 scheduling-automation.cy.ts\n\u2502       \u251c\u2500\u2500 ai-assisted-workflows.cy.ts\n\u2502       \u251c\u2500\u2500 integration-validations.cy.ts\n\u2502       \u2514\u2500\u2500 workflow-performance-testing.cy.ts\n\u2502\n\u251c\u2500\u2500 support/\n\u2502   \u251c\u2500\u2500 page-objects/\n\u2502   \u2502   \u251c\u2500\u2500 LoginPage.ts\n\u2502   \u2502   \u251c\u2500\u2500 DashboardPage.ts\n\u2502   \u2502   \u251c\u2500\u2500 DocumentsPage.ts\n\u2502   \u2502   \u251c\u2500\u2500 CapitalCallsPage.ts\n\u2502   \u2502   \u251c\u2500\u2500 WaterfallsPage.ts\n\u2502   \u2502   \u251c\u2500\u2500 UserManagementPage.ts\n\u2502   \u2502   \u2514\u2500\u2500 WorkflowsPage.ts\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 fixtures/\n\u2502   \u2502   \u251c\u2500\u2500 epic-mappings.json\n\u2502   \u2502   \u251c\u2500\u2500 users/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 admin-users.json\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 gp-users.json\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 lp-class-a-users.json\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 lp-class-b-users.json\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 auditor-users.json\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 manager-users.json\n\u2502   \u2502   \u251c\u2500\u2500 documents/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 sample-documents.json\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 document-metadata.json\n\u2502   \u2502   \u251c\u2500\u2500 capital-calls/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 call-scenarios.json\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 payment-data.json\n\u2502   \u2502   \u251c\u2500\u2500 waterfalls/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 european-model-data.json\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 american-model-data.json\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 calculation-vectors.json\n\u2502   \u2502   \u2514\u2500\u2500 workflows/\n\u2502   \u2502       \u251c\u2500\u2500 approval-scenarios.json\n\u2502   \u2502       \u2514\u2500\u2500 automation-rules.json\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 commands/\n\u2502   \u2502   \u251c\u2500\u2500 auth-commands.ts\n\u2502   \u2502   \u251c\u2500\u2500 epic-logging-commands.ts\n\u2502   \u2502   \u251c\u2500\u2500 class-context-commands.ts\n\u2502   \u2502   \u251c\u2500\u2500 document-commands.ts\n\u2502   \u2502   \u251c\u2500\u2500 capital-call-commands.ts\n\u2502   \u2502   \u2514\u2500\u2500 calculation-commands.ts\n\u2502   \u2502\n\u2502   \u2514\u2500\u2500 utils/\n\u2502       \u251c\u2500\u2500 epic-traceability.ts\n\u2502       \u251c\u2500\u2500 class-isolation-validators.ts\n\u2502       \u251c\u2500\u2500 calculation-validators.ts\n\u2502       \u251c\u2500\u2500 security-validators.ts\n\u2502       \u2514\u2500\u2500 performance-monitors.ts\n\u2502\n\u2514\u2500\u2500 reports/\n    \u251c\u2500\u2500 epic-traceability/\n    \u2502   \u251c\u2500\u2500 coverage-matrix.json\n    \u2502   \u2514\u2500\u2500 requirement-mapping.json\n    \u2514\u2500\u2500 coverage-reports/\n        \u251c\u2500\u2500 epic-1-coverage.html\n        \u251c\u2500\u2500 epic-2-coverage.html\n        \u251c\u2500\u2500 epic-3-coverage.html\n        \u2514\u2500\u2500 epic-4-coverage.html\n</code></pre>"},{"location":"qa/phase1-functional-test-suite-tech-spec/#3-epic-to-test-mapping","title":"3. Epic-to-Test Mapping","text":""},{"location":"qa/phase1-functional-test-suite-tech-spec/#31-epic-1-core-framework-auth-weeks-1-2","title":"3.1 Epic 1: Core Framework &amp; Auth (Weeks 1-2)","text":"<p>Official Requirements: Repository setup, CI pipeline, User authentication, Role/permission model</p> <p>Documentation Sources: - Epic: Phase 1 Epics - Tests: Phase 1 Functional Test Cases</p> <p>Test Case Coverage: <code>1.1.1, 1.1.2, 1.1.3, 1.1.5, 1.1.6, 1.1.7, 1.2.1, 1.2.2, 1.2.3, 1.2.5</code></p> <p>Critical Requirements: - \u2705 Multi-role authentication (Admin, GP, LP Class A/B, Auditor, Manager) - \u2705 Role-based access control validation - \u2705 Session management and security compliance - \u2705 Cross-class data isolation enforcement - \u2705 Security audit trail verification - \u2705 Authentication error handling and edge cases</p>"},{"location":"qa/phase1-functional-test-suite-tech-spec/#32-epic-2-user-management-documents-weeks-3-4","title":"3.2 Epic 2: User Management &amp; Documents (Weeks 3-4)","text":"<p>Official Requirements: User CRUD operations, Document upload/download, Metadata/versioning, AI categorization</p> <p>Test Case Coverage: <code>2.1.1-2.1.4, 2.2.1-2.2.4, 2.3.1-2.3.3, 1.3.2</code></p> <p>Critical Requirements: - \u2705 Class-specific document access and isolation - \u2705 Version control workflows with permissions - \u2705 AI document classification and metadata extraction - \u2705 Document sharing within class boundaries only - \u2705 User management CRUD operations - \u2705 Document security and access restrictions</p>"},{"location":"qa/phase1-functional-test-suite-tech-spec/#33-epic-3-capital-call-waterfall-weeks-5-6","title":"3.3 Epic 3: Capital Call &amp; Waterfall (Weeks 5-6)","text":"<p>Official Requirements: Capital call management, Notification integration, Waterfall models/calculations</p> <p>Test Case Coverage: <code>3.1.1-3.1.4, 3.2.1-3.2.3, 3.3.1-3.3.3, 4.1.1-4.1.3, 4.2.1-4.2.4, 4.3.1-4.3.4</code></p> <p>Critical Requirements: - \u2705 Capital call creation and class isolation - \u2705 Member notification and payment tracking systems - \u2705 European and American waterfall calculation models - \u2705 Inter-class distribution algorithms - \u2705 Financial calculation accuracy and audit trails - \u2705 Payment processing and error handling</p>"},{"location":"qa/phase1-functional-test-suite-tech-spec/#34-epic-4-workflow-automation-integrations-weeks-7-8","title":"3.4 Epic 4: Workflow Automation &amp; Integrations (Weeks 7-8)","text":"<p>Official Requirements: Approval systems, Scheduling automation, AI-assisted features</p> <p>Critical Requirements: - \u2705 Workflow approval systems with class boundaries - \u2705 AI-assisted workflow routing and automation - \u2705 Integration validation with external systems - \u2705 Performance testing under realistic loads - \u2705 Scheduling and SLA enforcement</p>"},{"location":"qa/phase1-functional-test-suite-tech-spec/#4-test-implementation-standards","title":"4. Test Implementation Standards","text":""},{"location":"qa/phase1-functional-test-suite-tech-spec/#41-test-file-template","title":"4.1 Test File Template","text":"<p>Every test file must follow this standardized template for epic traceability:</p> <pre><code>/**\n * DEALSPHERE PHASE 1 EPIC MAPPING\n *\n * Epic: [Epic Name from official documentation]\n * Official Test Case: [Test case number from epic mapping]\n * Business Requirements: [Requirements from functional test cases]\n * Development Timeline: [Week numbers from epic planning]\n *\n * Documentation Sources:\n * - Epic: https://dealsphere-inc.github.io/dealsphere-platform-docs/planning/phase1-epics/\n * - Tests: https://dealsphere-inc.github.io/dealsphere-platform-docs/qa/Phase1_Functional_Test_Cases/\n *\n * Implementation Status: [TO_BE_IMPLEMENTED | IN_PROGRESS | COMPLETED]\n * Priority: [HIGH | MEDIUM | LOW]\n */\n\ndescribe('Epic [X]: [Epic Name] - Test Case [X.X.X]', () =&gt; {\n  before(() =&gt; {\n    cy.log('='.repeat(80))\n    cy.log('DEALSPHERE PHASE 1 EPIC COVERAGE')\n    cy.log('='.repeat(80))\n\n    cy.logEpicRequirement(\n      'Epic Name',\n      'Test Case Number',\n      'Business Requirement Description',\n      'Priority Level'\n    )\n\n    cy.log('='.repeat(80))\n  })\n\n  beforeEach(() =&gt; {\n    // Setup for each test with proper class context\n    cy.setupClassContext('default-class')\n    cy.clearAuthState()\n  })\n\n  it(`should satisfy official requirement [X.X.X]: [Requirement Description]`, () =&gt; {\n    cy.log(`\ud83e\uddea TESTING: [Specific test scenario]`)\n    cy.log(`\u2705 ACCEPTANCE CRITERIA: [Success criteria]`)\n\n    // Test implementation with business value validation\n    // This test will initially fail and guide development\n  })\n\n  afterEach(() =&gt; {\n    // Cleanup to ensure test isolation\n    cy.cleanupTestData()\n  })\n})\n</code></pre>"},{"location":"qa/phase1-functional-test-suite-tech-spec/#42-custom-commands-for-epic-traceability","title":"4.2 Custom Commands for Epic Traceability","text":"<pre><code>// cypress/support/commands.ts additions\ndeclare global {\n  namespace Cypress {\n    interface Chainable {\n      /**\n       * Log epic requirement information for traceability\n       */\n      logEpicRequirement(epic: string, testCase: string, requirement: string, priority: string): Chainable&lt;void&gt;\n\n      /**\n       * Setup class context for multi-class testing\n       */\n      setupClassContext(classId: string): Chainable&lt;void&gt;\n\n      /**\n       * Clear authentication state between tests\n       */\n      clearAuthState(): Chainable&lt;void&gt;\n\n      /**\n       * Cleanup test data after each test\n       */\n      cleanupTestData(): Chainable&lt;void&gt;\n    }\n  }\n}\n\nCypress.Commands.add('logEpicRequirement', (epic: string, testCase: string, requirement: string, priority: string) =&gt; {\n  cy.log(`\ud83c\udfaf EPIC: ${epic}`)\n  cy.log(`\ud83d\udccb TEST CASE: ${testCase}`)\n  cy.log(`\ud83d\udcdd REQUIREMENT: ${requirement}`)\n  cy.log(`\u26a1 PRIORITY: ${priority}`)\n  cy.log(`\ud83d\udcc5 PHASE: Phase 1`)\n  cy.log(`\ud83d\udd17 EPIC SOURCE: /planning/phase1-epics/`)\n  cy.log(`\ud83d\udd17 TEST SOURCE: /qa/Phase1_Functional_Test_Cases/`)\n})\n\nCypress.Commands.add('setupClassContext', (classId: string) =&gt; {\n  // Implementation for setting up class context\n  cy.window().then((win) =&gt; {\n    win.localStorage.setItem('currentClassContext', classId)\n  })\n})\n\nCypress.Commands.add('clearAuthState', () =&gt; {\n  // Clear all authentication state\n  cy.clearLocalStorage()\n  cy.clearCookies()\n})\n\nCypress.Commands.add('cleanupTestData', () =&gt; {\n  // Cleanup any test data created during the test\n  cy.task('cleanupTestDatabase', { preserveStructure: true })\n})\n</code></pre>"},{"location":"qa/phase1-functional-test-suite-tech-spec/#5-test-data-management","title":"5. Test Data Management","text":""},{"location":"qa/phase1-functional-test-suite-tech-spec/#51-epic-based-fixtures","title":"5.1 Epic-Based Fixtures","text":"<pre><code>// cypress/fixtures/epic-mappings.json\n{\n  \"epic1\": {\n    \"name\": \"Core Framework &amp; Auth\",\n    \"weeks\": \"1-2\",\n    \"testCases\": [\n      \"1.1.1\", \"1.1.2\", \"1.1.3\", \"1.1.5\",\n      \"1.1.6\", \"1.1.7\", \"1.2.1\", \"1.2.2\",\n      \"1.2.3\", \"1.2.5\"\n    ],\n    \"requirements\": \"Repository setup, CI pipeline, User authentication, Role/permission model\",\n    \"priority\": \"HIGH\",\n    \"status\": \"TO_BE_IMPLEMENTED\"\n  },\n  \"epic2\": {\n    \"name\": \"User Management &amp; Documents\",\n    \"weeks\": \"3-4\",\n    \"testCases\": [\n      \"2.1.1\", \"2.1.2\", \"2.1.3\", \"2.1.4\",\n      \"2.2.1\", \"2.2.2\", \"2.2.3\", \"2.2.4\",\n      \"2.3.1\", \"2.3.2\", \"2.3.3\", \"1.3.2\"\n    ],\n    \"requirements\": \"User CRUD operations, Document upload/download, Metadata/versioning, AI categorization\",\n    \"priority\": \"HIGH\",\n    \"status\": \"TO_BE_IMPLEMENTED\"\n  },\n  \"epic3\": {\n    \"name\": \"Capital Call &amp; Waterfall\",\n    \"weeks\": \"5-6\",\n    \"testCases\": [\n      \"3.1.1\", \"3.1.2\", \"3.1.3\", \"3.1.4\",\n      \"3.2.1\", \"3.2.2\", \"3.2.3\",\n      \"3.3.1\", \"3.3.2\", \"3.3.3\",\n      \"4.1.1\", \"4.1.2\", \"4.1.3\",\n      \"4.2.1\", \"4.2.2\", \"4.2.3\", \"4.2.4\",\n      \"4.3.1\", \"4.3.2\", \"4.3.3\", \"4.3.4\"\n    ],\n    \"requirements\": \"Capital call management, Notification integration, Waterfall models/calculations\",\n    \"priority\": \"HIGH\",\n    \"status\": \"TO_BE_IMPLEMENTED\"\n  },\n  \"epic4\": {\n    \"name\": \"Workflow Automation &amp; Integrations\",\n    \"weeks\": \"7-8\",\n    \"testCases\": [\n      \"workflow-approval-systems\",\n      \"scheduling-automation\",\n      \"ai-assisted-workflows\",\n      \"integration-validations\",\n      \"workflow-performance-testing\"\n    ],\n    \"requirements\": \"Approval systems, Scheduling automation, AI-assisted features\",\n    \"priority\": \"MEDIUM\",\n    \"status\": \"TO_BE_IMPLEMENTED\"\n  }\n}\n</code></pre>"},{"location":"qa/phase1-functional-test-suite-tech-spec/#52-multi-class-test-environment","title":"5.2 Multi-Class Test Environment","text":"<pre><code>// cypress/fixtures/users/test-user-roles.json\n{\n  \"admin\": {\n    \"email\": \"admin@dealsphere.com\",\n    \"password\": \"SecureAdminPass123!\",\n    \"roles\": [\"ADMIN\"],\n    \"permissions\": [\"ALL\"],\n    \"classAccess\": [\"ALL_CLASSES\"],\n    \"description\": \"System administrator with full access\"\n  },\n  \"gp\": {\n    \"email\": \"gp@dealsphere.com\",\n    \"password\": \"SecureGPPass123!\",\n    \"roles\": [\"GP\"],\n    \"permissions\": [\"MANAGE_FUND\", \"CREATE_CAPITAL_CALLS\", \"VIEW_WATERFALLS\"],\n    \"classAccess\": [\"CLASS_A\", \"CLASS_B\"],\n    \"description\": \"General Partner with management permissions\"\n  },\n  \"lp_class_a\": {\n    \"email\": \"lp-a@dealsphere.com\",\n    \"password\": \"SecureLPAPass123!\",\n    \"roles\": [\"LP\"],\n    \"permissions\": [\"VIEW_DOCUMENTS\", \"RESPOND_CAPITAL_CALLS\"],\n    \"classAccess\": [\"CLASS_A\"],\n    \"description\": \"Limited Partner for Class A\"\n  },\n  \"lp_class_b\": {\n    \"email\": \"lp-b@dealsphere.com\",\n    \"password\": \"SecureLPBPass123!\",\n    \"roles\": [\"LP\"],\n    \"permissions\": [\"VIEW_DOCUMENTS\", \"RESPOND_CAPITAL_CALLS\"],\n    \"classAccess\": [\"CLASS_B\"],\n    \"description\": \"Limited Partner for Class B\"\n  },\n  \"auditor\": {\n    \"email\": \"auditor@dealsphere.com\",\n    \"password\": \"SecureAuditorPass123!\",\n    \"roles\": [\"AUDITOR\"],\n    \"permissions\": [\"READ_ONLY_ALL\"],\n    \"classAccess\": [\"CLASS_A\", \"CLASS_B\"],\n    \"description\": \"Auditor with read-only compliance access\"\n  },\n  \"manager\": {\n    \"email\": \"manager@dealsphere.com\",\n    \"password\": \"SecureManagerPass123!\",\n    \"roles\": [\"MANAGER\"],\n    \"permissions\": [\"MANAGE_USERS\", \"APPROVE_DOCUMENTS\"],\n    \"classAccess\": [\"CLASS_A\"],\n    \"description\": \"Manager with class-specific permissions\"\n  }\n}\n</code></pre>"},{"location":"qa/phase1-functional-test-suite-tech-spec/#6-reporting-traceability","title":"6. Reporting &amp; Traceability","text":""},{"location":"qa/phase1-functional-test-suite-tech-spec/#61-epic-coverage-reports","title":"6.1 Epic Coverage Reports","text":"<p>The test suite will generate comprehensive coverage reports showing:</p> <pre><code>// cypress/plugins/epic-traceability-reporter.ts\ninterface EpicCoverageReport {\n  totalEpics: number\n  totalTestCases: number\n  implementedTests: number\n  pendingTests: number\n  failingTests: number\n  passingTests: number\n  coveragePercentage: number\n  epicBreakdown: {\n    [epicName: string]: {\n      testCases: string[]\n      implemented: number\n      pending: number\n      failing: number\n      passing: number\n      coverage: number\n    }\n  }\n  requirementTraceability: {\n    [testCase: string]: {\n      epic: string\n      requirement: string\n      status: 'IMPLEMENTED' | 'PENDING' | 'FAILING' | 'PASSING'\n      lastRun: Date\n    }\n  }\n}\n\nconst generateEpicCoverageReport = (): EpicCoverageReport =&gt; {\n  // Implementation for generating comprehensive coverage report\n}\n</code></pre>"},{"location":"qa/phase1-functional-test-suite-tech-spec/#62-automated-traceability-matrix","title":"6.2 Automated Traceability Matrix","text":"<pre><code>// cypress/support/utils/traceability-matrix.ts\ninterface TraceabilityMatrix {\n  epic: string\n  testCase: string\n  requirement: string\n  testFile: string\n  implementationStatus: 'TO_BE_IMPLEMENTED' | 'IN_PROGRESS' | 'COMPLETED'\n  testStatus: 'NOT_RUN' | 'FAILING' | 'PASSING'\n  developmentWeek: string\n  priority: 'HIGH' | 'MEDIUM' | 'LOW'\n  businessValue: string\n  acceptanceCriteria: string[]\n}\n\nconst validateTraceabilityMatrix = (): TraceabilityMatrix[] =&gt; {\n  // Validate all tests have proper epic mapping\n  // Ensure no missing coverage\n  // Generate traceability reports\n}\n</code></pre>"},{"location":"qa/phase1-functional-test-suite-tech-spec/#7-implementation-timeline","title":"7. Implementation Timeline","text":""},{"location":"qa/phase1-functional-test-suite-tech-spec/#71-test-creation-schedule","title":"7.1 Test Creation Schedule","text":"Phase Epic Duration Test Count Status Phase 1 Epic 1: Core Framework &amp; Auth Week 0 10 tests TO_BE_IMPLEMENTED Phase 2 Epic 2: User Management &amp; Documents Week 0 12 tests TO_BE_IMPLEMENTED Phase 3 Epic 3: Capital Call &amp; Waterfall Week 0 20 tests TO_BE_IMPLEMENTED Phase 4 Epic 4: Workflow Automation &amp; AI Week 0 5 tests TO_BE_IMPLEMENTED <p>Total Test Suite: ~47 comprehensive functional test scenarios</p>"},{"location":"qa/phase1-functional-test-suite-tech-spec/#72-development-guidance-timeline","title":"7.2 Development Guidance Timeline","text":"Development Week Epic Focus Available Tests Development Guidance Weeks 1-2 Core Framework &amp; Auth 10 failing tests Authentication, RBAC, security Weeks 3-4 User Management &amp; Documents 12 failing tests User CRUD, document management, AI Weeks 5-6 Capital Call &amp; Waterfall 20 failing tests Financial operations, calculations Weeks 7-8 Workflow Automation 5 failing tests Process automation, integrations"},{"location":"qa/phase1-functional-test-suite-tech-spec/#8-success-criteria","title":"8. Success Criteria","text":""},{"location":"qa/phase1-functional-test-suite-tech-spec/#81-coverage-metrics","title":"8.1 Coverage Metrics","text":"<ul> <li>\u2705 100% Phase 1 epic coverage - All official epics have corresponding test scenarios</li> <li>\u2705 100% test case implementation - All official test cases from documentation are implemented</li> <li>\u2705 Complete requirement traceability - Every test maps to official business requirements</li> <li>\u2705 Executable specification quality - Tests clearly define expected behavior for developers</li> </ul>"},{"location":"qa/phase1-functional-test-suite-tech-spec/#82-quality-standards","title":"8.2 Quality Standards","text":"<ul> <li>\u2705 Tests fail initially - All tests will fail until features are implemented (TDD approach)</li> <li>\u2705 Clear business value validation - Each test validates real user scenarios and outcomes</li> <li>\u2705 Comprehensive error scenario coverage - Edge cases and error conditions are thoroughly tested</li> <li>\u2705 Performance and security validation - Non-functional requirements are tested alongside functional ones</li> </ul>"},{"location":"qa/phase1-functional-test-suite-tech-spec/#83-traceability-requirements","title":"8.3 Traceability Requirements","text":"<ul> <li>\u2705 Epic-to-test mapping - Direct traceability from epics to test implementations</li> <li>\u2705 Official documentation integration - Test logs include official requirement text</li> <li>\u2705 Coverage reporting - Real-time visibility into requirement coverage</li> <li>\u2705 Development guidance - Failing tests provide clear implementation direction</li> </ul>"},{"location":"qa/phase1-functional-test-suite-tech-spec/#9-risk-mitigation","title":"9. Risk Mitigation","text":""},{"location":"qa/phase1-functional-test-suite-tech-spec/#91-test-maintenance-risks","title":"9.1 Test Maintenance Risks","text":"Risk Impact Mitigation Strategy Epic changes High Automated traceability validation, sync with official docs Test data drift Medium Centralized fixture management, data validation Flaky tests High Robust test isolation, proper cleanup, retry mechanisms Development coupling Medium Clear test boundaries, proper abstraction layers"},{"location":"qa/phase1-functional-test-suite-tech-spec/#92-coverage-risks","title":"9.2 Coverage Risks","text":"Risk Impact Mitigation Strategy Missing requirements High Regular sync with official documentation Test case gaps Medium Comprehensive traceability matrix validation Edge case coverage Medium Systematic error scenario identification Performance blind spots Medium Load testing integration, monitoring"},{"location":"qa/phase1-functional-test-suite-tech-spec/#10-deliverables","title":"10. Deliverables","text":""},{"location":"qa/phase1-functional-test-suite-tech-spec/#101-test-artifacts","title":"10.1 Test Artifacts","text":"<ol> <li>Complete Test Suite (~47 comprehensive test scenarios)</li> <li>Epic 1: 10 authentication and security tests</li> <li>Epic 2: 12 user management and document tests</li> <li>Epic 3: 20 capital call and waterfall tests</li> <li> <p>Epic 4: 5 workflow automation and AI tests</p> </li> <li> <p>Epic Traceability Matrix (automated mapping)</p> </li> <li>Direct epic-to-test relationships</li> <li>Official documentation references</li> <li> <p>Implementation status tracking</p> </li> <li> <p>Test Infrastructure (page objects, utilities, fixtures)</p> </li> <li>Reusable page object models</li> <li>Comprehensive test data fixtures</li> <li> <p>Custom Cypress commands for DealSphere workflows</p> </li> <li> <p>Documentation Integration (official requirement embedding)</p> </li> <li>Test logs with official DealSphere requirement text</li> <li>Epic source references in every test</li> <li> <p>Business value validation descriptions</p> </li> <li> <p>Coverage Reports (real-time progress tracking)</p> </li> <li>Epic coverage percentages</li> <li>Test implementation status</li> <li> <p>Requirement fulfillment tracking</p> </li> <li> <p>Development Guides (failing tests as specifications)</p> </li> <li>Clear acceptance criteria in test descriptions</li> <li>Business value explanations</li> <li>Implementation guidance through test failures</li> </ol>"},{"location":"qa/phase1-functional-test-suite-tech-spec/#102-documentation-updates","title":"10.2 Documentation Updates","text":"<ul> <li>mkdocs.yml - Add technical specification to QA navigation</li> <li>Development guides - Link test suite to development workflow</li> <li>Epic documentation - Cross-reference test implementations</li> <li>QA process - Integration with existing QA workflows</li> </ul>"},{"location":"qa/phase1-functional-test-suite-tech-spec/#11-conclusion","title":"11. Conclusion","text":"<p>This technical specification defines a comprehensive, test-first approach to DealSphere Phase 1 development. By writing all functional tests upfront with direct epic traceability, we ensure that:</p> <ol> <li>Development is guided by executable specifications - Failing tests provide clear implementation direction</li> <li>100% requirement coverage - Every business requirement has corresponding test validation</li> <li>Traceability is maintained - Direct mapping between official epics and test implementations</li> <li>Quality is built-in - Comprehensive testing from day one of development</li> <li>Documentation is living - Tests serve as executable specifications and documentation</li> </ol> <p>The test suite will initially have 47 failing tests that serve as the development roadmap. As development progresses, these tests will begin passing, providing confidence that business requirements are being met correctly.</p> <p>Next Steps: 1. Review and approve this technical specification 2. Implement the test infrastructure and framework 3. Create all 47 functional test scenarios 4. Integrate with development workflow 5. Begin development guided by failing tests</p> <p>Approval Required: QA Team Lead, Development Team Lead, Product Owner</p>"},{"location":"tech/tech-landscape/","title":"Minimal Tech Landscape for DealSphere MVP","text":""},{"location":"tech/tech-landscape/#1-architectural-pattern","title":"1. Architectural Pattern","text":"<p>Monolithic Application</p> <ul> <li>Fast to develop and deploy for small teams and frequent iteration.</li> <li>Simplifies testing, transactions, and deployments.</li> <li>Ideal when domain boundaries are not fully volatile or discovered.</li> <li>All core modules (UI, business logic, data handling, integrations) live in a single deployable app.</li> <li>Use layered separation (Controller/Service/Repository) for maintainability and future migration to microservices, if needed.</li> </ul>"},{"location":"tech/tech-landscape/#2-core-tech-stack-choices","title":"2. Core Tech Stack Choices","text":"Layer Minimal Option (Best-fit) Web Frontend React (with Vite/CRA for speed, optional MUI/AntD for quick UI) Backend API/Logic Spring Boot (Java) or Node.js (Express) Database PostgreSQL (transactional &amp; mature; easy migration) File/Blob Storage S3-compatible service (e.g., AWS S3, MinIO local for MVP/dev) AuthN &amp; AuthZ JWT-based auth with Spring Security/Express middleware Document Management Local doc store + hash tracking in DB; integrate with S3 for scale AI Integration API-based calls to OpenAI/Claude (proxy for future custom models) R3 Corda As separate service; interface via HTTP/REST with mock for MVP Infra/CI Docker Compose (for local, simple), GitHub Actions for builds/tests"},{"location":"tech/tech-landscape/#3-optionalpluggable","title":"3. Optional/Pluggable","text":"<ul> <li>Admin UI built into main React app with feature flags.</li> <li>Basic monitoring: logs + health check endpoint.</li> <li>Email: SMTP or 3rd-party service (SendGrid/Mailgun) from backend.</li> </ul>"},{"location":"tech/tech-landscape/#4-fit-with-adrs","title":"4. Fit with ADRs","text":"<ul> <li>Stack above is aligned with accepted ADRs:<ul> <li>Layered separation (ADR: Modular boundaries)</li> <li>S3 or compatible (ADR: Object store)</li> <li>AI as external/sidecar (ADR: Cloud LLM API call)</li> <li>RBAC as API middleware (ADR: Simple Auth Middleware)</li> <li>Corda as remote or integrated API (ADR: Corda data plane)</li> <li>Single DB, pluggable storage (ADR: DB/storage split)</li> </ul> </li> </ul>"},{"location":"tech/tech-landscape/#5-migration-path","title":"5. Migration Path","text":"<ul> <li>Partition logic/services internally for easy \u201clift-and-split\u201d to microservices as needed.</li> <li>Wrap integrations/external calls in adapters/interfaces.</li> </ul>"},{"location":"tech/tech-landscape/#6-monolithic-viability","title":"6. Monolithic Viability","text":"<ul> <li>Monolithic application is strongly recommended for MVP:<ul> <li>PRD scope fits: user management, documents, workflows, analytics, integrations.</li> <li>Evolve to microservices if required for scale/organization.</li> </ul> </li> </ul>"},{"location":"tech/tech-landscape/#7-tech-landscape-diagram-text","title":"7. Tech Landscape Diagram (Text)","text":"<p>[React Frontend]          |   [Rest API (SpringBoot/Node)]          |    </p> <p>|     |     |      |    |    |   DB  S3/Blob Email  AI  Corda           (Postgres) (S3)   (SMTP) (API)</p>"}]}